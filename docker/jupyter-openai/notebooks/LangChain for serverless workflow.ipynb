{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61553956",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# update or install the necessary libraries\n",
    "!pip install python-dotenv openai langchain unstructured chromadb tiktoken github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4103e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai  # for calling the OpenAI API\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load your API key from an environment variable or secret management service\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# for LangChain\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e2f6143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0db413a1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Serverless Workflow Specification\\n\\nTable of Contents\\n\\nAbstract\\n\\nStatus of this document\\n\\nOverview\\n\\nWhy we need a specification?\\n\\nFocus on standards\\n\\nProject Components\\n\\nSpecification Details\\n\\nCore Concepts\\n\\nWorkflow Definition\\n\\nWorkflow Instance\\n\\nWorkflow Model\\n\\nWorkflow Data\\nWorkflow Data Input\\nInformation Passing Between States\\nWorkflow data output\\nState data filters\\nAction data filters\\nEvent data filters\\nUsing multiple data filters\\nData Merging\\n\\nWorkflow Functions\\nUsing Functions for RESTful Service Invocations\\nUsing Functions for Async API Service Invocations\\nUsing Functions for RPC Service Invocations\\nUsing Functions for GraphQL Service Invocations\\nInvoking a GraphQL Query\\nInvoking a GraphQL Mutation\\nUsing Functions for OData Service Invocations\\nCreating an OData Function Definition\\nInvoking an OData Function Definition\\nUsing Functions for Expression Evaluation\\nDefining custom function types\\n\\nWorkflow Expressions\\n\\nWorkflow Definition Structure\\nWorkflow States\\nEvent State\\nOperation State\\nSwitch State\\nSleep State\\nParallel State\\nInject State\\nForEach State\\nCallback State\\nRelated State Definitions\\nFunction Definition\\nEvent Definition\\nAuth Definition\\nBasic Properties Definition\\nBearer Properties Definition\\nOAuth2 Properties Definition\\n\\n\\nCorrelation Definition\\nOnEvents Definition\\nAction Definition\\nSubflow Action\\nFunctionRef Definition\\nEventRef Definition\\nSubFlowRef Definition\\nError Definition\\nRetry Definition\\nTransition Definition\\nSwitch State Data Conditions\\nSwitch State Event Conditions\\nParallel State Branch\\nParallel State Handling Exceptions\\nStart Definition\\nSchedule Definition\\nCron Definition\\nEnd Definition\\nProducedEvent Definition\\nTransitions\\nAdditional Properties\\n\\nWorkflow Error Handling\\nDefining Errors\\n\\nAction retries\\nRetry actions on known errors\\nAutomatic retries on known and unknown errors\\n\\nWorkflow Timeouts\\nWorkflow Timeout Definition\\nWorkflowExecTimeout Definition\\nStates Timeout Definition\\nBranch Timeout Definition\\nEvent Timeout Definition\\n\\nWorkflow Compensation\\nDefining Compensation\\nTriggering Compensation\\nCompensation Execution Details\\nCompensation and Active States\\nUnrecoverable errors during compensation\\n\\nContinuing as a new Execution\\nContinueAs in sub workflows\\n\\nWorkflow Versioning\\n\\nWorkflow Constants\\n\\nWorkflow Secrets\\n\\nWorkflow Metadata\\n\\nWorkflow Context\\n\\nExtensions\\n\\nUse Cases\\n\\nExamples\\n\\nComparison to other workflow languages\\n\\nReferences\\n\\nLicense\\n\\nAbstract\\n\\nThe Serverless Workflow project defines a vendor-neutral and declarative workflow language,\\ntargeting the Serverless computing technology domain.\\n\\nStatus of this document\\n\\nThis document represents the current state of the specification.\\nIt includes all features so far released\\nas well as all features planned to be added in the next release.\\n\\nYou can find all specification releases here.\\nYou can find the specification roadmap here.\\n\\nOverview\\n\\nWorkflows allow us to capture and organize business requirements in a unified manner.\\nThey can bridge the gap between how we express and model business logic.\\n\\nA key component of workflows is the domain-specific language (DSL) we use to model our\\nbusiness logic and solutions. Selecting the appropriate workflow language for our business and technology domains is\\na very important decision to be considered.\\n\\nServerless Workflow focuses on defining a vendor-neutral, platform-independent, and declarative workflow\\nlanguage that targets the serverless computing technology domain.\\nIt can be used to significantly bridge the gap between your unique business domain and the target technology domain.\\n\\nWhy we need a specification?\\n\\nThe lack of a common way to define and model workflows means that we must constantly re-learn\\nhow to write them. This also limits the potential for common libraries, tooling and\\ninfrastructure to aid workflow modeling and execution across different platforms.\\nPortability as well as productivity that can be achieved from workflow orchestration is hindered overall.\\n\\nServerless Workflow addresses the need for a community-driven, vendor-neutral and a platform-independent\\nworkflow language specification that targets the serverless computing technology domain.\\n\\nHaving and using a specification-based workflow language allows us to model our workflows once and deploy them\\nonto many different container/cloud platforms, expecting the same execution results.\\n\\nFor more information on the history, development and design rationale behind the specification, see the Serverless Workflow Wiki.\\n\\nFocus on standards\\n\\nServerless Workflow language takes advantage of well-established and known standards such as CloudEvents, OpenAPI specifications,\\ngRPC and GraphQL.\\n\\nProject Components\\n\\nThe specification has multiple components:\\n\\nDefinitions of the workflow language. This is defined via the Workflow JSON Schema. You can use both\\n  JSON and YAML formats to model your workflows.\\n\\nSoftware Development Kits (SDKs) for Go, Java, .NET, Typescript and Python, and we plan to add them for more languages in the future.\\n\\nSet of Workflow Extensions which\\n  allow users to define additional, non-execution-related workflow information. This information can be used to improve\\n  workflow performance.\\n  Some example workflow extensions include Key Performance Indicators (KPIs), Rate Limiting, Simulation, Tracing, etc.\\n\\nTechnology Compatibility Kit (TCK) to be used as a specification conformance tool for runtime implementations.\\n\\nSpecification Details\\n\\nFollowing sections provide detailed descriptions of all parts of the Serverless Workflow language.\\n\\nCore Concepts\\n\\nThis section describes some of the core Serverless Workflow concepts:\\n\\nWorkflow Definition\\n\\nA workflow definition is a JSON or YAML file that conforms to the Serverless Workflow specification DSL. \\nIt consists of the core Workflow Definition Structure\\nand the Workflow Model It defines a blueprint used by runtimes for its execution.\\n\\nA business solution can be composed of any number of related workflow definitions.\\nTheir relationships are explicitly modeled with the Serverless Workflow language (for example\\nby using SubFlowRef Definition in actions).\\n\\nRuntimes can initialize workflow definitions for some particular set of data inputs or events.\\n\\nWorkflow Instance\\n\\nA workflow instance represents a single workflow execution corresponding to the instructions provided by a\\nworkflow definition. A workflow instance can be short or long-running. A single workflow instance\\nshould be isolated, meaning it should not share state and data with other workflow instances.\\nWorkflow instances should be able to communicate with each other via events.\\n\\nDepending on their workflow definition, workflow instances can be short-lived or\\ncan execute for days, weeks, or years.\\n\\nEach workflow instances should have its unique identifier, which should remain\\nunchanged throughout its execution.\\n\\nWorkflow instances can be started providing some data input. This is described in detail in the \\nworkflow data input section.\\nWorkflow instances can also wait for examples to start their execution, which is the case\\nwhere a workflow definition contains a EventState starting workflow state.\\n\\nThe workflow definition also explicitly defines when a workflow instance should be completed. \\nBy default, instances should be completed once there are no active workflow paths (all active\\npaths reach a state containing the default end definition),\\nor if the defined workflowExecTimeout time is reached.\\nOther ways, such as using the terminate property of the end definition to terminate instance execution,\\nor defining an workflowExecTimeout property are also possible.\\n\\nFor long-running workflow-executions, you can utilize the keepActive workflow property which \\nprovides more control as to when exactly to terminate workflow execution. In cases where a\\nworkflow execution should be continued as a new one, the DSL also provides the continueAs property which is described\\nin detail in the Continuing a new Execution section.\\n\\nWorkflow Model\\n\\nThe Serverless Workflow language is composed of:\\n\\nFunction definitions -  Reusable functions that can declare services that need to be invoked, or expressions to be evaluated.\\n\\nEvent definitions - Reusable declarations of events that need to be consumed to start or continue workflow instances, trigger function/service execution, or be produced during workflow execution.\\n\\nRetry definitions - Reusable retry definitions. Can specify retry strategies for service invocations during workflow execution.\\n\\nTimeout definitions - Reusable timeout definitions. Can specify default workflow execution timeout, as well as workflow state, action, and branch execution timeouts.\\n\\nErrors definition - Reusable error definitions. Provide domain-specific error definitions which can be referenced in workflow states error handling.\\n\\nState definitions - Definition of states, the building blocks of workflow control flow logic. States can reference the reusable function, event and retry definitions.\\n\\nWorkflow Data\\n\\nServerless Workflow data is represented in JSON format.\\nData flow and execution logic go hand in hand, meaning as workflow execution follows the workflow definition\\nlogic, so does the workflow data:\\n\\nThe initial Workflow data input is passed to the workflow starting state as its data input.\\nWhen a state finishes its execution, its data output is passed as data input to the next state that should be executed.\\n\\nWhen workflow execution ends, the last executed workflow state\\'s data output becomes the final Workflow data output.\\n\\nStates can filter their data inputs and outputs using State Data filters.\\n\\nStates can also consume events as well as invoke services. These event payloads and service invocation results\\ncan be filtered using Event data filters and Action data filters.\\n\\nData filters use workflow expressions for selecting and manipulating state data\\ninput and output, action inputs and results, and event payloads.\\n\\nMultiple filters can be combined to gain high level of control of your workflow state data. You can find an example of that in\\nthis section.\\n\\nData from consumed events,and action execution results are added/merged\\nto state data. Reference the data merging section to learn about the merging rules that should be applied.\\n\\nWorkflow Data Input\\n\\nThe initial data input into a workflow instance. Must be a valid JSON object.\\nIf no input is provided, the default data input should be an empty JSON object:\\n\\njson\\n{ }\\n\\nWorkflow data input is passed to the workflow starting state as its data input.\\n\\nInformation Passing Between States\\n\\nStates in a workflow can receive data (data input) and produce a data result (data output). The state\\'s data input is typically the previous state\\'s data output.\\nWhen a state completes its execution, its data output is passed to the state\\'s data input it transitions to.\\nThere are two rules to consider here:\\n\\nIf the state is the workflow starting state, its data input is the workflow data input.\\n\\nWhen workflow execution ends, the data output of the last executed state becomes the workflow data output.\\n\\nWorkflow data output\\n\\nEach workflow execution should produce a data output.\\nThe workflow data output is the data output of the last executed workflow state.\\n\\nState data filters\\n\\n| Parameter | Description | Type | Required |\\n| --- | --- | --- | --- |\\n| input | Workflow expression to filter the states data input | string | no |\\n| output | Workflow expression that filters the states data output | string | no |\\n\\n```json\\n{\\n    \"stateDataFilter\": {\\n      \"input\": \"${ .orders }\",\\n      \"output\": \"${ .provisionedOrders }\"\\n    }\\n}\\n```\\n\\n```yaml\\nstateDataFilter:\\n  input: \"${ .orders }\"\\n  output: \"${ .provisionedOrders }\"\\n```\\n\\nState data filters can be used to filter the state\\'s data input and output.\\n\\nThe state data filters input property expression is applied when the workflow transitions to the current state and receives its data input.\\nIt can be used to select only data that is needed and disregard what is not needed.\\nIf input is not defined or does not select any parts of the state\\'s data input, its data input is not filtered.\\n\\nThe state data filter output property expression is applied right before the state transitions to the next state defined.\\nIt filters the state\\'s data output to be passed as data input to the transitioning state.\\nIf the current state is the workflow end state, the filtered state\\'s data output becomes the workflow data output.\\nIf output is not defined or does not select any parts of the state\\'s data output, its data output is not filtered.\\n\\nResults of the input expression should become the state data input.\\nResults of the output expression should become the state data output.\\n\\nFor more information on this you can reference the data merging section.\\n\\nLet\\'s take a look at some examples of state filters. For our examples let\\'s say the data input to our state is as follows:\\n\\njson\\n{\\n  \"fruits\": [ \"apple\", \"orange\", \"pear\" ],\\n  \"vegetables\": [\\n    {\\n      \"veggieName\": \"potato\",\\n      \"veggieLike\": true\\n    },\\n    {\\n      \"veggieName\": \"broccoli\",\\n      \"veggieLike\": false\\n    }\\n  ]\\n}\\n\\nFor the first example, our state only cares about fruits data, and we want to disregard the vegetables. To do this\\nwe can define a state filter:\\n\\njson\\n{\\n  \"stateDataFilter\": {\\n    \"input\": \"${ {fruits: .fruits} }\"\\n  }\\n}\\n\\nThe state data output then would include only the fruits data:\\n\\njson\\n{\\n  \"fruits\": [ \"apple\", \"orange\", \"pear\"]\\n}\\n\\nFor our second example, let\\'s say that we are interested in the only vegetable \"veggie-like\".\\nHere we have two ways of filtering our data, depending on if actions within our state need access to all vegetables, or\\nonly the ones that are \"veggie-like\".\\n\\nThe first way would be to use both \"input\", and \"output\":\\n\\njson\\n{\\n  \"stateDataFilter\": {\\n    \"input\": \"${ {vegetables: .vegetables} }\",\\n    \"output\": \"${ {vegetables: [.vegetables[] | select(.veggieLike == true)]} }\"\\n  }\\n}\\n\\nThe states data input filter selects all the vegetables from the main data input. Once all actions have performed, before the state transition\\nor workflow execution completion (if this is an end state), the \"output\" of the state filter selects only the vegetables which are \"veggie like\".\\n\\nThe second way would be to directly filter only the \"veggie like\" vegetables with just the data input path:\\n\\njson\\n{\\n  \"stateDataFilter\": {\\n    \"input\": \"${ {vegetables: [.vegetables[] | select(.veggieLike == true)]} }\"\\n  }\\n}\\n\\nAction data filters\\n\\n| Parameter | Description | Type | Required |\\n| --- | --- | --- | --- |\\n| fromStateData | Workflow expression that filters state data that can be used by the action | string | no |\\n| useResults | If set to false, action data results are not added/merged to state data. In this case \\'results\\' and \\'toStateData\\' should be ignored. Default is true.  | boolean | no |\\n| results | Workflow expression that filters the actions data results | string | no |\\n| toStateData | Workflow expression that selects a state data element to which the action results should be added/merged into. If not specified denotes the top-level state data element | string | no |\\n\\n```json\\n{\\n  \"actionDataFilter\": {\\n    \"fromStateData\": \"${ .language }\",\\n    \"results\": \"${ .results.greeting }\",\\n    \"toStateData\": \"${ .finalgreeting }\"\\n  }\\n}\\n```\\n\\n```yaml\\nactionDataFilter:\\n  fromStateData: \"${ .language }\"\\n  results: \"${ .results.greeting }\"\\n  toStateData: \"${ .finalgreeting }\"\\n```\\n\\nAction data filters can be used inside Action definitions.\\nEach action can define this filter which can:\\n\\nFilter the state data to select only the data that can be used within function definition arguments using its fromStateData property.\\n\\nFilter the action results to select only the result data that should be added/merged back into the state data\\n  using its results property.\\n\\nSelect the part of state data which the action data results should be added/merged to\\n  using the toStateData property.\\n\\nTo give an example, let\\'s say we have an action which returns a list of breads and pasta types.\\nFor our workflow, we are only interested into breads and not the pasta.\\n\\nAction results:\\n\\njson\\n{\\n  \"breads\": [\"baguette\", \"brioche\", \"rye\"],\\n  \"pasta\": [ \"penne\",  \"spaghetti\", \"ravioli\"]\\n}\\n\\nWe can use an action data filter to filter only the breads data:\\n\\njson\\n{\\n\"actions\":[\\n    {\\n       \"functionRef\": \"breadAndPastaTypesFunction\",\\n       \"actionDataFilter\": {\\n          \"results\": \"${ {breads: .breads} }\"\\n       }\\n    }\\n ]\\n}\\n\\nThe results will filter the action results, which would then be:\\n\\njson\\n{\\n  \"breads\": [\\n    \"baguette\",\\n    \"brioche\",\\n    \"rye\"\\n  ]\\n}\\n\\nNow let\\'s take a look at a similar example (same expected action results) and assume our current state data is:\\n\\njson\\n{\\n  \"itemsToBuyAtStore\": [\\n  ]\\n}\\n\\nand have the following action definition:\\n\\njson\\n{\\n\"actions\":[\\n    {\\n       \"functionRef\": \"breadAndPastaTypesFunction\",\\n       \"actionDataFilter\": {\\n          \"results\": \"${ [ .breads[0], .pasta[1] ] }\",\\n          \"toStateData\": \"${ .itemsToBuyAtStore }\"\\n       }\\n    }\\n ]\\n}\\n\\nIn this case, our results select the first bread and the second element of the pasta array.\\nThe toStateData expression then selects the itemsToBuyAtStore array of the state data to add/merge these results\\ninto. With this, after our action executes the state data would be:\\n\\njson\\n{\\n  \"itemsToBuyAtStore\": [\\n    \"baguette\",\\n    \"spaghetti\"\\n  ]\\n}\\n\\nEvent data filters\\n\\n| Parameter | Description | Type | Required |\\n| --- | --- | --- | --- |\\n| useData | If set to false, event payload is not added/merged to state data. In this case \\'data\\' and \\'toStateData\\' should be ignored. Default is true. | boolean | no |\\n| data | Workflow expression that filters the event data (payload) | string | no |\\n| toStateData | Workflow expression that selects a state data element to which the action results should be added/merged into. If not specified denotes the top-level state data element | string | no |\\n\\n```json\\n{\\n    \"eventDataFilter\": {\\n       \"data\": \"${ .data.results }\"\\n    }\\n}\\n```\\n\\n```yaml\\neventDataFilter:\\n  data: \"${ .data.results }\"\\n```\\n\\nEvent data filters can be used to filter consumed event payloads.\\nThey can be used to:\\n\\nFilter the event payload to select only the data that should be added/merged into the state data\\n  using its data property.\\n\\nSelect the part of state data into which the event payload should be added/merged into\\n  using the toStateData property.\\n\\nAllows event data to be filtered and added to or merged with the state data. All events have to be in the CloudEvents format\\nand event data filters can filter both context attributes and the event payload (data) using the data property.\\n\\nHere is an example using an event filter:\\n\\nNote that the data input to the Event data filters depends on the dataOnly property of the associated Event definition.\\nIf this property is not defined (has default value of true), Event data filter expressions are evaluated against the event payload (the CloudEvents data attribute only). If it is set to\\nfalse, the expressions should be evaluated against the entire CloudEvent (including its context attributes).\\n\\nUsing multiple data filters\\n\\nAs Event states can take advantage of all defined data filters. In the example below, we define\\na workflow with a single event state and show how data filters can be combined.\\n\\njson\\n{\\n    \"id\": \"GreetCustomersWorkflow\",\\n    \"name\": \"Greet Customers when they arrive\",\\n    \"version\": \"1.0.0\",\\n    \"specVersion\": \"0.8\",\\n    \"start\": \"WaitForCustomerToArrive\",\\n    \"states\":[\\n         {\\n            \"name\": \"WaitForCustomerToArrive\",\\n            \"type\": \"event\",\\n            \"onEvents\": [{\\n                \"eventRefs\": [\"CustomerArrivesEvent\"],\\n                \"eventDataFilter\": {\\n                    \"data\": \"${ .customer }\",\\n                    \"toStateData\": \"${ .customerInfo }\"\\n                },\\n                \"actions\":[\\n                    {\\n                        \"functionRef\": {\\n                            \"refName\": \"greetingFunction\",\\n                            \"arguments\": {\\n                                \"greeting\": \"${ .hello.spanish } \",\\n                                \"customerName\": \"${ .customerInfo.name } \"\\n                            }\\n                        },\\n                        \"actionDataFilter\": {\\n                            \"fromStateData\": \"${ { hello, customerInfo } }\",\\n                            \"results\": \"${ .greetingMessageResult }\",\\n                            \"toStateData\": \"${ .finalCustomerGreeting }\"\\n                        }\\n                    }\\n                ]\\n            }],\\n            \"stateDataFilter\": {\\n                \"input\": \"${ .greetings } \",\\n                \"output\": \"${ { finalCustomerGreeting } }\"\\n            },\\n            \"end\": true\\n        }\\n    ],\\n    \"events\": [{\\n        \"name\": \"CustomerArrivesEvent\",\\n        \"type\": \"customer-arrival-type\",\\n        \"source\": \"customer-arrival-event-source\"\\n     }],\\n    \"functions\": [{\\n        \"name\": \"greetingFunction\",\\n        \"operation\": \"http://my.api.org/myapi.json#greeting\"\\n    }]\\n}\\n\\nThe workflow data input when starting workflow execution is assumed to include greetings in different languages:\\n\\njson\\n{\\n  \"greetings\": {\\n      \"hello\": {\\n        \"english\": \"Hello\",\\n        \"spanish\": \"Hola\",\\n        \"german\": \"Hallo\",\\n        \"russian\": \"Здравствуйте\"\\n      },\\n      \"goodbye\": {\\n        \"english\": \"Goodbye\",\\n        \"spanish\": \"Adiós\",\\n        \"german\": \"Auf Wiedersehen\",\\n        \"russian\": \"Прощай\"\\n      }\\n  }\\n}\\n\\nThe workflow data input then becomes the data input of the starting workflow state.\\n\\nWe also assume for this example that the CloudEvent that our event state consumes include the data (payload):\\n\\njson\\n{\\n \"customer\": {\\n   \"name\": \"John Michaels\",\\n   \"address\": \"111 Some Street, SomeCity, SomeCountry\",\\n   \"age\": 40\\n }\\n}\\n\\nHere is a sample diagram showing our workflow, each numbered step on this diagram shows a certain defined point during\\nworkflow execution at which data filters are invoked and correspond to the numbered items below.\\n\\n(1) Workflow execution starts: Workflow data is passed to our \"WaitForCustomerToArrive\" event state as data input.\\nWorkflow executes its starting state, namely the \"WaitForCustomerToArrive\" event state.\\n\\nThe event state stateDataFilter is invoked to filter its data input. The filters \"input\" expression is evaluated and\\nselects only the \"greetings\" data. The rest of the state data input should be disregarded.\\n\\nAt this point our state data should be:\\n\\njson\\n{\\n  \"hello\": {\\n    \"english\": \"Hello\",\\n    \"spanish\": \"Hola\",\\n    \"german\": \"Hallo\",\\n    \"russian\": \"Здравствуйте\"\\n  },\\n  \"goodbye\": {\\n    \"english\": \"Goodbye\",\\n    \"spanish\": \"Adiós\",\\n    \"german\": \"Auf Wiedersehen\",\\n    \"russian\": \"Прощай\"\\n  }\\n}\\n\\n(2) CloudEvent of type \"customer-arrival-type\" is consumed: Once the event is consumed, the \"eventDataFilter\" is triggered.\\nIts \"data\" expression selects the \"customer\" object from the events data. The \"toStateData\" expression\\nsays that we should add/merge this selected event data to the state data in its \"customerInfo\" property. If this property\\nexists it should be merged, if it does not exist, one should be created.\\n\\nAt this point our state data contains:\\n\\njson\\n{\\n    \"hello\": {\\n      \"english\": \"Hello\",\\n      \"spanish\": \"Hola\",\\n      \"german\": \"Hallo\",\\n      \"russian\": \"Здравствуйте\"\\n    },\\n    \"goodbye\": {\\n      \"english\": \"Goodbye\",\\n      \"spanish\": \"Adiós\",\\n      \"german\": \"Auf Wiedersehen\",\\n      \"russian\": \"Прощай\"\\n    },\\n    \"customerInfo\": {\\n       \"name\": \"John Michaels\",\\n       \"address\": \"111 Some Street, SomeCity, SomeCountry\",\\n       \"age\": 40\\n     }\\n}\\n\\n(3) Event state performs its actions:\\nBefore the first action is executed, its actionDataFilter is invoked. Its \"fromStateData\" expression filters\\nthe current state data to select from its data that should be available to action arguments. In this example\\nit selects the \"hello\" and \"customerInfo\" properties from the current state data.\\nAt this point the action is executed.\\nWe assume that for this example \"greetingFunction\" returns:\\n\\njson\\n{\\n   \"execInfo\": {\\n     \"execTime\": \"10ms\",\\n     \"failures\": false\\n   },\\n   \"greetingMessageResult\": \"Hola John Michaels!\"\\n}\\n\\nAfter the action is executed, the actionDataFilter \"results\" expression is evaluated to filter the results returned from the action execution. In this case, we select only the \"greetingMessageResult\" element from the results.\\n\\nThe action filters \"toStateData\" expression then defines that we want to add/merge this action result to\\nstate data under the \"finalCustomerGreeting\" element.\\n\\nAt this point, our state data contains:\\n\\njson\\n{\\n  \"hello\": {\\n      \"english\": \"Hello\",\\n      \"spanish\": \"Hola\",\\n      \"german\": \"Hallo\",\\n      \"russian\": \"Здравствуйте\"\\n    },\\n    \"goodbye\": {\\n      \"english\": \"Goodbye\",\\n      \"spanish\": \"Adiós\",\\n      \"german\": \"Auf Wiedersehen\",\\n      \"russian\": \"Прощай\"\\n    },\\n    \"customerInfo\": {\\n       \"name\": \"John Michaels\",\\n       \"address\": \"111 Some Street, SomeCity, SomeCountry\",\\n       \"age\": 40\\n     },\\n     \"finalCustomerGreeting\": \"Hola John Michaels!\"\\n}\\n\\n(4) Event State Completes  Execution:\\n\\nWhen our event state finishes its execution, the states \"stateDataFilter\" \"output\" filter expression is executed\\nto filter the state data to create the final state data output.\\n\\nBecause our event state is also an end state, its data output becomes the final workflow data output. Namely:\\n\\njson\\n{\\n   \"finalCustomerGreeting\": \"Hola John Michaels!\"\\n}\\n\\nData Merging\\n\\nConsumed event data (payload) and action execution results should be merged into the state data.\\nEvent and action data filters can be used to give more details about this operation.\\n\\nBy default, with no data filters specified, when an event is consumed, its entire data section (payload) should be merged\\nto the state data. Merging should be applied to the entire state data JSON element.\\n\\nIn case of event and action filters, their \"toStateData\" property can be defined to select a specific element\\nof the state data with which merging should be done against. If this element does not exist, a new one should\\nbe created first.\\n\\nWhen merging, the state data element and the data (payload)/action result should have the same type, meaning\\nthat you should not merge arrays with objects or objects with arrays etc.\\n\\nWhen merging elements of type object should be done by inserting all the key-value pairs from both objects into\\na single combined object. If both objects contain a value for the same key, the object of the event data/action results\\nshould \"win\". To give an example, let\\'s say we have the following state data:\\n\\njson\\n{\\n    \"customer\": {\\n        \"name\": \"John\",\\n        \"address\": \"1234 street\",\\n        \"zip\": \"12345\"\\n    }\\n}\\n\\nand we have the following event payload that needs to be merged into the state data:\\n\\njson\\n{\\n    \"customer\": {\\n        \"name\": \"John\",\\n        \"zip\": \"54321\"\\n    }\\n}\\n\\nAfter merging the state data should be:\\n\\njson\\n{\\n  \"customer\": {\\n    \"name\": \"John\",\\n    \"address\": \"1234 street\",\\n    \"zip\": \"54321\"\\n  }\\n}\\n\\nMerging array types should be done by concatenating them into a larger array including unique elements of both arrays.\\nTo give an example, merging:\\n\\njson\\n{\\n    \"customers\": [\\n      {\\n        \"name\": \"John\",\\n        \"address\": \"1234 street\",\\n        \"zip\": \"12345\"\\n      },\\n      {\\n        \"name\": \"Jane\",\\n        \"address\": \"4321 street\",\\n        \"zip\": \"54321\"\\n      }\\n    ]\\n}\\n\\ninto state data:\\n\\njson\\n{\\n    \"customers\": [\\n      {\\n        \"name\": \"Michael\",\\n        \"address\": \"6789 street\",\\n        \"zip\": \"6789\"\\n      }\\n    ]\\n}\\n\\nshould produce state data:\\n\\njson\\n{\\n    \"customers\": [\\n      {\\n        \"name\": \"Michael\",\\n        \"address\": \"6789 street\",\\n        \"zip\": \"6789\"\\n      },\\n      {\\n        \"name\": \"John\",\\n        \"address\": \"1234 street\",\\n        \"zip\": \"12345\"\\n      },\\n      {\\n        \"name\": \"Jane\",\\n        \"address\": \"4321 street\",\\n        \"zip\": \"54321\"\\n      }\\n    ]\\n}\\n\\nMerging number types should be done by overwriting the data from events data/action results into the merging element of the state data.\\nFor example merging action results:\\n\\njson\\n{\\n    \"age\": 30\\n}\\n\\ninto state data:\\n\\njson\\n{\\n    \"age\": 20\\n}\\n\\nwould produce state data:\\n\\njson\\n{\\n    \"age\": 30\\n}\\n\\nMerging string types should be done by overwriting the data from events data/action results into the merging element of the state data.\\n\\nWorkflow Functions\\n\\nWorkflow functions are reusable definitions for service invocations and/or expression evaluation.\\nThey can be referenced by their domain-specific names inside workflow states.\\n\\nReference the following sections to learn more about workflow functions:\\n\\nUsing functions for RESTful service invocations\\n\\nUsing Functions for Async API Service Invocations\\n\\nUsing functions for gRPC service invocation\\n\\nUsing functions for GraphQL service invocation\\n\\nUsing Functions for OData Service Invocations\\n\\nUsing functions for expression evaluations\\n\\nDefining custom function types\\n\\nWe can define if functions are invoked sync or async. Reference\\nthe functionRef to learn more on how to do this.\\n\\nUsing Functions for RESTful Service Invocations\\n\\nFunctions can be used to describe services and their operations that need to be invoked during\\nworkflow execution. They can be referenced by states action definitions to clearly\\ndefine when the service operations should be invoked during workflow execution, as well as the data parameters\\npassed to them if needed.\\n\\nNote that with Serverless Workflow, we can also define invocation of services which are triggered via an event.\\nTo learn more about that, please reference the event definitions section,\\nas well as the actions definitions eventRef property.\\n\\nBecause of an overall lack of a common way to describe different services and their operations,\\nmany workflow languages typically chose to define custom function definitions.\\nThis approach, however, often runs into issues such as lack of portability, limited capabilities, as well as\\nforcing non-workflow-specific information, such as service authentication, to be added inside the workflow language.\\n\\nTo avoid these issues, the Serverless Workflow specification mandates that details about\\nRESTful services and their operations be described using the OpenAPI Specification.\\nOpenAPI is a language-agnostic standard that describes discovery of RESTful services.\\nThis allows Serverless Workflow language to describe RESTful services in a portable\\nway, as well as workflow runtimes to utilize OpenAPI tooling and APIs to invoke service operations.\\n\\nHere is an example function definition for a RESTful service operation.\\n\\njson\\n{\\n\"functions\": [\\n  {\\n    \"name\": \"sendOrderConfirmation\",\\n    \"operation\": \"file://confirmationapi.json#sendOrderConfirmation\"\\n  }\\n]\\n}\\n\\nIt can, as previously mentioned be referenced during workflow execution when the invocation of this service is desired.\\nFor example:\\n\\njson\\n{\\n\"states\": [\\n  {\\n      \"name\":\"SendConfirmState\",\\n      \"type\":\"operation\",\\n      \"actions\":[\\n       {\\n       \"functionRef\": \"sendOrderConfirmation\"\\n      }],\\n      \"end\": true\\n  }]\\n}\\n\\nNote that the referenced function definition type in this case must be rest (default type).\\n\\nFor more information about functions, reference the Functions definitions section.\\n\\nUsing Functions for Async API Service Invocations\\n\\nFunctions can be used to invoke PUBLISH and SUBSCRIBE operations on a message broker documented by the Async API Specification.\\nAsync API operations are bound to a channel which describes the technology, security mechanisms, input and validation to be used for their execution.\\n\\nLet\\'s take a look at a hypothetical Async API document (assumed its stored locally with the file name streetlightsapi.yaml) and define a single publish operation:\\n\\nyaml\\nasyncapi: 2.1.0\\ninfo:\\n  title: Streetlights API\\n  version: 1.0.0\\n  description: |\\n    The Smartylighting Streetlights API allows you\\n    to remotely manage the city lights.\\n  license:\\n    name: Apache 2.0\\n    url: https://www.apache.org/licenses/LICENSE-2.0\\nservers:\\n  mosquitto:\\n    url: mqtt://test.mosquitto.org\\n    protocol: mqtt\\nchannels:\\n  light/measured:\\n    publish:\\n      summary: Inform about environmental lighting conditions for a particular streetlight.\\n      operationId: onLightMeasured\\n      message:\\n        name: LightMeasured\\n        payload:\\n          type: object\\n          properties:\\n            id:\\n              type: integer\\n              minimum: 0\\n              description: Id of the streetlight.\\n            lumens:\\n              type: integer\\n              minimum: 0\\n              description: Light intensity measured in lumens.\\n            sentAt:\\n              type: string\\n              format: date-time\\n              description: Date and time when the message was sent.\\n\\nTo define a workflow action invocation, we can then use the following workflow Function Definition and set the operation to onLightMeasured:\\n\\njson\\n{\\n  \"functions\": [\\n  {\\n    \"name\": \"publishLightMeasurements\",\\n    \"operation\": \"file://streetlightsapi.yaml#onLightMeasured\",\\n    \"type\": \"asyncapi\"\\n  }]\\n}\\n\\nNote that the Function Definition\\'s operation property must have the following format:\\n\\ntext\\n<URI_to_asyncapi_file>#<OperationId>\\n\\nAlso note that the referenced function definition type in this case must have the value asyncapi.\\n\\nOur defined function definition can then we referenced in a workflow action, for example:\\n\\njson\\n{\\n  \"name\": \"Publish Measurements\",\\n  \"type\": \"operation\",\\n  \"actions\":[\\n    {\\n      \"name\": \"Publish Light Measurements\",\\n      \"functionRef\":{\\n        \"refName\": \"publishLightMeasurements\",\\n        \"arguments\":{\\n          \"id\": \"${ .currentLight.id }\",\\n          \"lumens\": \"${ .currentLight.lumens }\",\\n          \"sentAt\": \"${ now }\"\\n        }\\n      }\\n    }\\n  ]\\n}\\n\\nUsing Functions for RPC Service Invocations\\n\\nSimilar to defining invocations of operations on RESTful services, you can also use the workflow\\nfunctions definitions that follow the remote procedure call (RPC) protocol.\\nFor RPC invocations, the Serverless Workflow specification mandates that they are described using gRPC,\\na widely used RPC system.\\ngRPC uses Protocol Buffers to define messages, services,\\nand the methods on those services that can be invoked.\\n\\nLet\\'s look at an example of invoking a service method using RPC. For this example let\\'s say we have the following\\ngRPC protocol buffer definition in a myuserservice.proto file:\\n\\ntext\\nservice UserService {\\n    rpc AddUser(User) returns (google.protobuf.Empty) {\\n        option (google.api.http) = {\\n            post: \"/api/v1/users\"\\n            body: \"*\"\\n        };\\n    }\\n    rpc ListUsers(ListUsersRequest) returns (stream User) {\\n        option (google.api.http) = {\\n            get: \"/api/v1/users\"\\n        };\\n    }\\n    rpc ListUsersByRole(UserRole) returns (stream User) {\\n        option (google.api.http) = {\\n            get: \"/api/v1/users/role\"\\n        };\\n    }\\n    rpc UpdateUser(UpdateUserRequest) returns (User) {\\n        option (google.api.http) = {\\n            patch: \"/api/v1/users/{user.id}\"\\n            body: \"*\"\\n        };\\n    }\\n}\\n\\nIn our workflow definition, we can then use function definitions:\\n\\njson\\n{\\n\"functions\": [\\n  {\\n    \"name\": \"listUsers\",\\n    \"operation\": \"file://myuserservice.proto#UserService#ListUsers\",\\n    \"type\": \"rpc\"\\n  }\\n]\\n}\\n\\nNote that the operation property has the following format:\\n\\ntext\\n<URI_to_proto_file>#<Service_Name>#<Service_Method_Name>\\n\\nNote that the referenced function definition type in this case must be rpc.\\n\\nFor more information about functions, reference the Functions definitions section.\\n\\nUsing Functions for GraphQL Service Invocations\\n\\nIf you want to use GraphQL services, you can also invoke them using a similar syntax to the above methods.\\n\\nWe\\'ll use the following GraphQL schema definition to show how that would work with both a query and a mutation:\\n\\n```graphql\\ntype Query {\\n    pets: [Pet]\\n    pet(id: Int!): Pet\\n}\\n\\ntype Mutation {\\n    createPet(pet: PetInput!): Pet\\n}\\n\\ntype Treat {\\n    id: Int!\\n}\\n\\ntype Pet {\\n    id: Int!\\n    name: String!\\n    favoriteTreat: Treat\\n}\\n\\ninput PetInput {\\n    id: Int!\\n    name: String!\\n    favoriteTreatId: Int\\n}\\n```\\n\\nInvoking a GraphQL Query\\n\\nIn our workflow definition, we can then use a function definition for the pet query field as such:\\n\\njson\\n{\\n  \"functions\": [\\n    {\\n      \"name\": \"getOnePet\",\\n      \"operation\": \"https://example.com/pets/graphql#query#pet\",\\n      \"type\": \"graphql\"\\n    }\\n  ]\\n}\\n\\nNote that the operation property has the following format for the graphql type:\\n\\ntext\\n<url_to_graphql_endpoint>#<literal \"mutation\" or \"query\">#<mutation_or_query_field>\\n\\nIn order to invoke this query, we would use the following functionRef parameters:\\n\\njson\\n{\\n  \"refName\": \"getOnePet\",\\n  \"arguments\": {\\n    \"id\": 42\\n  },\\n  \"selectionSet\": \"{ id, name, favoriteTreat { id } }\"\\n}\\n\\nWhich would return the following result:\\n\\njson\\n{\\n  \"pet\": {\\n    \"id\": 42,\\n    \"name\": \"Snuffles\",\\n    \"favoriteTreat\": {\\n      \"id\": 9001\\n    }\\n  }\\n}\\n\\nInvoking a GraphQL Mutation\\n\\nLikewise, we would use the following function definition:\\n\\njson\\n{\\n  \"functions\": [\\n    {\\n      \"name\": \"createPet\",\\n      \"operation\": \"https://example.com/pets/graphql#mutation#createPet\",\\n      \"type\": \"graphql\"\\n    }\\n  ]\\n}\\n\\nWith the parameters for the functionRef:\\n\\njson\\n{\\n  \"refName\": \"createPet\",\\n  \"arguments\": {\\n    \"pet\": {\\n      \"id\": 43,\\n      \"name\":\"Sadaharu\",\\n      \"favoriteTreatId\": 9001\\n    }\\n  },\\n  \"selectionSet\": \"{ id, name, favoriteTreat { id } }\"\\n}\\n\\nWhich would execute the mutation, creating the object and returning the following data:\\n\\njson\\n{\\n  \"pet\": {\\n    \"id\": 43,\\n    \"name\": \"Sadaharu\",\\n    \"favoriteTreat\": {\\n      \"id\": 9001\\n    }\\n  }\\n}\\n\\nNote you can include expressions in both arguments and selectionSet:\\n\\njson\\n{\\n  \"refName\": \"getOnePet\",\\n  \"arguments\": {\\n    \"id\": \"${ .petId }\"\\n  },\\n  \"selectionSet\": \"{ id, name, age(useDogYears: ${ .isPetADog }) { dateOfBirth, years } }\"\\n}\\n\\nExpressions must be evaluated before executing the operation.\\n\\nNote that GraphQL Subscriptions are not supported at this time.\\n\\nFor more information about functions, reference the Functions definitions section.\\n\\nUsing Functions for OData Service Invocations\\n\\nSimilar to defining invocations of operations on GraphQL services, you can also use workflow\\nFunctions Definitions to execute complex queries on an OData service.\\n\\nCreating an OData Function Definition\\n\\nWe start off by creating a workflow Functions Definitions. For example:\\n\\njson\\n{\\n\"functions\": [\\n  {\\n    \"name\": \"queryPersons\",\\n    \"operation\": \"https://services.odata.org/V3/OData/OData.svc#Persons\",\\n    \"type\": \"odata\"\\n  }\\n]\\n}\\n\\nNote that the operation property must follow the following format:\\n\\ntext\\n<URI_to_odata_service>#<Entity_Set_Name>\\n\\nInvoking an OData Function Definition\\n\\nIn order to invoke the defined OData function, \\nsimply reference it in a workflow Action Definition and set its  function arguments. For example:\\n\\njson\\n{\\n  \"refName\": \"queryPersons\",\\n  \"arguments\": {\\n    \"queryOptions\":{\\n      \"expand\": \"PersonDetail/Person\",\\n      \"select\": \"Id, PersonDetail/Person/Name\",\\n      \"top\": 5,\\n      \"orderby\": \"PersonDetail/Person/Name\"\\n    }\\n  }\\n}\\n\\nIn order to ensure compatibility of OData support across runtimes, \\nthearguments property of an OData function reference \\nshould follow the Serverless Workflow OData Json schema\\n\\nUsing Functions for Expression Evaluation\\n\\nIn addition to defining RESTful, AsyncAPI, RPC, GraphQL and OData services and their operations, workflow functions definitions\\ncan also be used to define expressions that should be evaluated during workflow execution.\\n\\nDefining expressions as part of function definitions has the benefit of being able to reference\\nthem by their logical name through workflow states where expression evaluation is required.\\n\\nExpression functions must declare their type parameter to be expression.\\n\\nLet\\'s take a look at an example of such definitions:\\n\\njson\\n{\\n\"functions\": [\\n  {\\n    \"name\": \"isAdult\",\\n    \"operation\": \".applicant | .age >= 18\",\\n    \"type\": \"expression\"\\n  },\\n  {\\n    \"name\": \"isMinor\",\\n    \"operation\": \".applicant | .age < 18\",\\n    \"type\": \"expression\"\\n  }\\n]\\n}\\n\\nHere we define two reusable expression functions. Expressions in Serverless Workflow\\ncan be evaluated against the workflow, or workflow state data. Note that different data filters play a big role as to which parts of the\\nworkflow data are being evaluated by the expressions. Reference the\\nState Data Filters section for more information on this.\\n\\nOur expression function definitions can now be referenced by workflow states when they need to be evaluated. For example:\\n\\njson\\n{\\n\"states\":[\\n  {\\n     \"name\":\"CheckApplicant\",\\n     \"type\":\"switch\",\\n     \"dataConditions\": [\\n        {\\n          \"name\": \"Applicant is adult\",\\n          \"condition\": \"${ fn:isAdult }\",\\n          \"transition\": \"ApproveApplication\"\\n        },\\n        {\\n          \"name\": \"Applicant is minor\",\\n          \"condition\": \"${ fn:isMinor }\",\\n          \"transition\": \"RejectApplication\"\\n        }\\n     ],\\n     \"defaultCondition\": {\\n        \"transition\": \"RejectApplication\"\\n     }\\n  }\\n]\\n}\\n\\nOur expression functions can also be referenced and executed as part of state action execution.\\nLet\\'s say we have the following workflow definition:\\n\\njson\\n{\\n    \"name\": \"simpleadd\",\\n    \"functions\": [\\n        {\\n            \"name\": \"Increment Count Function\",\\n            \"type\": \"expression\",\\n            \"operation\": \".count += 1 | .count\"\\n        }\\n    ],\\n    \"start\": \"Initialize Count\",\\n    \"states\": [\\n        {\\n            \"name\": \"Initialize Count\",\\n            \"type\": \"inject\",\\n            \"data\": {\\n                \"count\": 0\\n            },\\n            \"transition\": \"Increment Count\"\\n        },\\n        {\\n            \"name\": \"Increment Count\",\\n            \"type\": \"operation\",\\n            \"actions\": [\\n                {\\n                    \"functionRef\": \"Increment Count Function\",\\n                    \"actionDataFilter\": {\\n                        \"toStateData\": \"${ .count }\"\\n                    }\\n                }\\n            ],\\n            \"end\": true\\n        }\\n    ]\\n}\\n\\nThe starting inject state \"Initialize Count\" injects the count element into our state data,\\nwhich then becomes the state data input of our \"Increment Count\" operation state.\\nThis state defines an invocation of the \"Increment Count Function\" expression function defined in our workflow definition.\\n\\nThis triggers the evaluation of the defined expression. The input of this expression is by default the current state data.\\nJust like with \"rest\", and \"rpc\" type functions, expression functions also produce a result. In this case\\nthe result of the expression is just the number 1.\\nThe actions filter then assigns this result to the state data element \"count\" and the state data becomes:\\n\\njson\\n{\\n    \"count\": 1\\n}\\n\\nNote that the used function definition type in this case must be expression.\\n\\nFor more information about functions, reference the Functions definitions section.\\n\\nFor more information about workflow expressions, reference the Workflow Expressions section.\\n\\nDefining custom function types\\n\\nFunction definitions type property defines a list of function types that are set by\\nthe specification.\\n\\nSome runtime implementations might support additional function types that extend the ones\\ndefined in the specification. In those cases you can define a custom function type with for example:\\n\\njson\\n{\\n\"functions\": [\\n  {\\n    \"name\": \"sendOrderConfirmation\",\\n    \"operation\": \"/path/to/my/script/order.ts#myFunction\",\\n    \"type\": \"custom\"\\n  }\\n]\\n}\\n\\nIn this example we define a custom function type that is meant to execute an external TypeScript script.\\n\\nWhen a custom function type is specified, the operation property value has a custom format, meaning that\\nits format is controlled by the runtime which provides the custom function type.\\n\\nLater, the function should be able to be used in an action as any other function supported by the specification:\\n\\njson\\n[{\\n  \"states\": [{\\n      \"name\": \"handleOrder\",\\n      \"type\": \"operation\",\\n      \"actions\": [\\n        {\\n          \"name\": \"sendOrderConfirmation\",\\n          \"functionRef\": {\\n            \"refName\": \"sendOrderConfirmation\",\\n            \"arguments\": {\\n              \"order\": \"${ .order }\"\\n            }\\n          }\\n        }\\n      ],\\n      \"transition\": \"emailCustomer\"\\n  }]\\n}]\\n\\nNote that custom function types are not portable across runtimes.\\n\\nWorkflow Expressions\\n\\nWorkflow model parameters can use expressions to select/manipulate workflow and/or state data.\\n\\nNote that different data filters play a big role as to which parts of the states data are to be used when the expression is\\nevaluated. Reference the\\nState Data Filtering section for more information about state data filters.\\n\\nBy default, all workflow expressions should be defined using the jq version 1.6 syntax.\\nYou can find more information on jq in its manual.\\n\\nServerless Workflow does not mandate the use of jq and it\\'s possible to use an expression language\\nof your choice with the restriction that a single one must be used for all expressions\\nin a workflow definition. If a different expression language needs to be used, make sure to set the workflow\\nexpressionLang property to identify it to runtime implementations.\\n\\nNote that using a non-default expression language could lower the portability of your workflow definitions\\nacross multiple container/cloud platforms.\\n\\nAll workflow expressions in this document, specification examples as well as comparisons examples\\nare written using the default jq syntax.\\n\\nWorkflow expressions have the following format:\\n\\ntext\\n${ expression }\\n\\nWhere expression can be either an in-line expression, or a reference to a\\ndefined expression function definition.\\n\\nTo reference a defined expression function definition\\nthe expression must have the following format, for example:\\n\\ntext\\n${ fn:myExprFuncName }\\n\\nWhere fn is the namespace of the defined expression functions and\\nmyExprName is the unique expression function name.\\n\\nTo show some expression examples, let\\'s say we have the following state data:\\n\\njson\\n{\\n  \"applicant\": {\\n    \"name\": \"John Doe\",\\n    \"age\"      : 26,\\n    \"email\": \"johndoe@something.com\",\\n    \"address\"  : {\\n      \"streetAddress\": \"Naist street\",\\n      \"city\"         : \"Nara\",\\n      \"postalCode\"   : \"630-0192\"\\n    },\\n    \"phoneNumbers\": [\\n      {\\n        \"type\"  : \"iPhone\",\\n        \"number\": \"0123-4567-8888\"\\n      },\\n      {\\n        \"type\"  : \"home\",\\n        \"number\": \"0123-4567-8910\"\\n      }\\n    ]\\n  }\\n}\\n\\nIn our workflow model we can define our reusable expression function:\\n\\njson\\n{\\n\"functions\": [\\n  {\\n    \"name\": \"IsAdultApplicant\",\\n    \"operation\": \".applicant | .age > 18\",\\n    \"type\": \"expression\"\\n  }\\n]\\n}\\n\\nWe will get back to this function definition in just a bit, but now let\\'s take a look at using\\nan inline expression that sets an input parameter inside an action for example:\\n\\njson\\n{\\n\"actions\": [\\n    {\\n        \"functionRef\": {\\n            \"refName\": \"confirmApplicant\",\\n            \"arguments\": {\\n                \"applicantName\": \"${ .applicant.name }\"\\n            }\\n        }\\n    }\\n]\\n}\\n\\nIn this case our input parameter applicantName would be set to \"John Doe\".\\n\\nExpressions can also be used to select and manipulate state data, this is in particularly useful for\\nstate data filters.\\n\\nFor example let\\'s use another inline expression:\\n\\njson\\n{\\n   \"stateDataFilter\": {\\n       \"output\": \"${ .applicant | {applicant: .name, contactInfo: { email: .email, phone: .phoneNumbers }} }\"\\n   }\\n}\\n\\nThis would set the data output of the particular state to:\\n\\njson\\n{\\n  \"applicant\": \"John Doe\",\\n  \"contactInfo\": {\\n    \"email\": \"johndoe@something.com\",\\n    \"phone\": [\\n      {\\n        \"type\": \"iPhone\",\\n        \"number\": \"0123-4567-8888\"\\n      },\\n      {\\n        \"type\": \"home\",\\n        \"number\": \"0123-4567-8910\"\\n      }\\n    ]\\n  }\\n}\\n\\nSwitch state conditions require for expressions to be resolved to a boolean value (true/false).\\n\\nWe can now get back to our previously defined \"IsAdultApplicant\" expression function and reference it:\\n\\njson\\n{\\n  \"dataConditions\": [ {\\n    \"condition\": \"${ fn:IsAdultApplicant }\",\\n    \"transition\": \"StartApplication\"\\n  }]\\n}\\n\\nAs previously mentioned, expressions are evaluated against certain subsets of data. For example\\nthe parameters param of the functionRef definition can evaluate expressions\\nonly against the data that is available to the action it belongs to.\\nOne thing to note here are the top-level workflow definition parameters. Expressions defined\\nin them can only be evaluated against the initial workflow data input.\\n\\nFor example let\\'s say that we have a workflow data input of:\\n\\njson\\n{\\n   \"inputVersion\" : \"1.0.0\"\\n}\\n\\nwe can use this expression in the workflow \"version\" parameter:\\n\\njson\\n{\\n   \"id\": \"MySampleWorkflow\",\\n   \"name\": \"Sample Workflow\",\\n   \"version\": \"${ .inputVersion }\",\\n   \"specVersion\": \"0.8\"\\n}\\n\\nwhich would set the workflow version to \"1.0.0\".\\nNote that the workflow \"id\" property value is not allowed to use an expression. The workflow\\ndefinition \"id\" must be a constant value.\\n\\nWorkflow Definition Structure\\n\\nsemantic versioning format | string | no |\\n| annotations | List of helpful terms describing the workflows intended purpose, subject areas, or other important qualities | array | no |\\n| dataInputSchema | Used to validate the workflow data input against a defined JSON Schema| string or object | no |\\n|\\n\\nconstants | Workflow constants | string or object | no |\\n|\\n\\nsecrets | Workflow secrets | string or array | no |\\n|\\n\\nstart | Workflow start definition | string or object | no |\\n| specVersion | Serverless Workflow specification release version | string | yes |\\n| expressionLang | Identifies the expression language used for workflow expressions. Default value is \"jq\" | string | no |\\n|\\n\\ntimeouts | Defines the workflow default timeout settings | string or object | no |\\n|\\n\\nerrors | Defines checked errors that can be explicitly handled during workflow execution | string or array | no |\\n| keepActive | If\\n\\nauth | Workflow authentication definitions | array or string | no |\\n|\\n\\nevents | Workflow event definitions.  | array or string | no |\\n|\\n\\nfunctions | Workflow function definitions. Can be either inline function definitions (if array) or URI pointing to a resource containing json/yaml function definitions (if string) | array or string| no |\\n| autoRetries | If set to\\n\\nactions should automatically be retried on unchecked errors. Default is\\n\\nretries | Workflow retries definitions. Can be either inline retries definitions (if array) or URI pointing to a resource containing json/yaml retry definitions (if string) | array or string| no |\\n|\\n\\nstates | Workflow states | array | yes |\\n|\\n\\nextensions | Workflow extensions definitions | array or string | no |\\n|\\n\\nmetadata | Metadata information | object | no |\\n\\n```json\\n{\\n   \"id\": \"sampleWorkflow\",\\n   \"version\": \"1.0.0\",\\n   \"specVersion\": \"0.8\",\\n   \"name\": \"Sample Workflow\",\\n   \"description\": \"Sample Workflow\",\\n   \"start\": \"MyStartingState\",\\n   \"states\": [],\\n   \"functions\": [],\\n   \"events\": [],\\n   \"errors\": [],\\n   \"retries\":[]\\n}\\n```\\n\\n```yaml\\nid: sampleWorkflow\\nversion: \\'1.0.0\\'\\nspecVersion: \\'0.8\\'\\nname: Sample Workflow\\ndescription: Sample Workflow\\nstart: MyStartingState\\nstates: []\\nfunctions: []\\nevents: []\\nerrors: []\\nretries: []\\n```\\n\\nDefines the top-level structure of a serverless workflow model.\\nFollowing figure describes the main workflow definition blocks.\\n\\nThe id property defines the unique, domain-specific workflow identifier, for example \"orders\", \"payment\", etc.\\n\\nThe key property defines the unique, domain-specific workflow identifier.\\nIt can be used when the id property is auto-generated by a content-management system for example.\\nIn these cases, you can specify the key property to be the domain-specific identifier of the workflow definition.\\nThe id and key properties are mutually exclusive, meaning you cannot define both.\\n\\nThe name property is the workflow logical name.\\n\\nThe description property can be used to give further information about the workflow.\\n\\nThe version property can be used to provide a specific workflow version. It must use the semantic versioning format.\\n\\nThe annotations property defines a list of helpful terms describing the workflows intended purpose, subject areas, or other important qualities,\\nfor example \"machine learning\", \"monitoring\", \"networking\", etc\\n\\nThe dataInputSchema property can be used to validate the workflow data input against a defined JSON Schema.\\nThis check should be done before any states are executed. dataInputSchema can have two different types.\\nIf it is an object type it has the following definition:\\n\\njson\\n\"dataInputSchema\": {\\n   \"schema\": \"URL_to_json_schema\",\\n   \"failOnValidationErrors\": false\\n}\\n\\nIt\\'s schema property can be an URI, which points to the JSON schema used to validate the workflow data input, or it can be the JSON schema object.\\nIf it\\'s a JSON schema object, it has the following definition:\\n\\n```json\\n\"dataInputSchema\": {\\n   \"schema\": {\\n     \"title\": \"MyJSONSchema\",\\n     \"properties\":{\\n       \"firstName\":{\\n         \"type\": \"string\"\\n       },\\n       \"lastName\":{\\n         \"type\": \"string\"\\n       }\\n     }\\n   },\\n   \"failOnValidationErrors\": false\\n}\\n\\n``\\nIt\\'failOnValidationErrorsproperty  determines if workflow execution should continue in case of validation\\nerrors. The default value offailOnValidationErrorsistrue.\\nIfdataInputSchema` has the string type, it has the following definition:\\n\\njson\\n\"dataInputSchema\": \"URL_to_json_schema\"\\n\\nIn this case the failOnValidationErrors default value of true is assumed.\\n\\nThe dataInputSchema property validates the workflow data input. In case of\\na starting Event state, it is not used to validate its event payloads.\\n\\nThe secrets property allows you to use sensitive information such as passwords, OAuth tokens, ssh keys, etc. inside your\\nWorkflow expressions.\\n\\nIt has two possible types, string or array.\\nIf string type, it is an URI pointing to a JSON or YAML document\\nwhich contains an array of names of the secrets, for example:\\n\\njson\\n\"secrets\": \"file://workflowsecrets.json\"\\n\\nIf array type, it defines an array (of string types) which contains the names of the secrets, for example:\\n\\njson\\n\"secrets\": [\"MY_PASSWORD\", \"MY_STORAGE_KEY\", \"MY_ACCOUNT\"]\\n\\nFor more information about Workflow secrets, reference the Workflow Secrets section.\\n\\nThe constants property can be used to define Workflow constants values\\nwhich are accessible in Workflow Expressions.\\n\\nIt has two possible types, string or object.\\nIf string type, it is an URI pointing to a JSON or YAML document\\nwhich contains an object of global definitions, for example:\\n\\njson\\n\"constants\": \"file://workflowconstants.json\"\\n\\nIf object type, it defines a JSON object which contains the constants definitions, for example:\\n\\njson\\n{\\n  \"AGE\": {\\n    \"MIN_ADULT\": 18\\n  }\\n}\\n\\nFor more information see the Workflow Constants section.\\n\\nThe start property defines the workflow starting information. For more information see the start definition section.\\nThis property is not required. If not defined, the workflow starting state has to be \\nthe very first state defined in the workflow states array.\\n\\nThe specVersion property is used to set the Serverless Workflow specification release version\\nthe workflow markup adheres to.\\nIt has to follow the specification release versions (excluding the leading \"v\"), meaning that for\\nthe release version v0.8\\nits value should be set to \"0.8\".\\n\\nThe expressionLang property can be used to identify the expression language used for all expressions in\\nthe workflow definition. The default value of this property is \"jq\".\\nYou should set this property if you chose to define workflow expressions\\nwith an expression language / syntax other than the default.\\n\\nThe timeouts property is used to define the default workflow timeouts for workflow, state, action, and branch\\nexecution. For more information about timeouts and its use cases see the Workflow Timeouts section.\\n\\nThe error property is used to define checked errors that can be explicitly handled during workflow execution.\\nFor more information about workflow error handling see this section.\\n\\nauth definition array, or a URI reference to\\na resource containing an array of\\n\\nauth definitions.\\nIf defined in a separate resource file (Json or Yaml),\\n\\nfunction definitions.\\nIf we have the following function definition:\\n\\njson\\n{\\n   \"functions\": [\\n      {\\n         \"name\": \"HelloWorldFunction\",\\n         \"operation\": \"https://secure.resources.com/myapi.json#helloWorld\",\\n         \"authRef\": \"My Basic Auth\"\\n      }\\n   ]\\n}\\n\\nThe authRef property is used to reference an authentication definition in\\nthe auth property and should be applied when invoking the helloWorld function. An AuthRef object can alternatively be used to configure the authentication definition to use when accessing the function\\'s resource and/or when invoking the function.\\n\\nThe functions property can be either an in-line function definition array, or an URI reference to\\na resource containing an array of functions definition.\\nReferenced resource can be used by multiple workflow definitions.\\n\\nHere is an example of using external resource for function definitions:\\n\\nWorkflow definition:\\n\\njson\\n{\\n   \"id\": \"sampleWorkflow\",\\n   \"version\": \"1.0.0\",\\n   \"specVersion\": \"0.8\",\\n   \"name\": \"Sample Workflow\",\\n   \"description\": \"Sample Workflow\",\\n   \"start\": \"MyStartingState\",\\n   \"functions\": \"http://myhost:8080/functiondefs.json\",\\n   \"states\":[\\n     ...\\n   ]\\n}\\n\\nFunction definitions resource:\\n\\njson\\n{\\n   \"functions\": [\\n      {\\n         \"name\":\"HelloWorldFunction\",\\n         \"operation\":\"file://myapi.json#helloWorld\"\\n      }\\n   ]\\n}\\n\\nReferenced resource must conform to the specifications Workflow Functions JSON Schema.\\n\\nThe events property can be either an in-line event definition array, or an URI reference to\\na resource containing an array of event definition. Referenced resource can be used by multiple workflow definitions.\\n\\nHere is an example of using external resource for event definitions:\\n\\nWorkflow definition:\\n\\njson\\n{\\n   \"id\": \"sampleWorkflow\",\\n   \"version\": \"1.0.0\",\\n   \"specVersion\": \"0.8\",\\n   \"name\": \"Sample Workflow\",\\n   \"description\": \"Sample Workflow\",\\n   \"start\": \"MyStartingState\",\\n   \"events\": \"http://myhost:8080/eventsdefs.json\",\\n   \"states\":[\\n     ...\\n   ]\\n}\\n\\nEvent definitions resource:\\n\\njson\\n{\\n   \"events\": [\\n      {\\n         \"name\": \"ApplicantInfo\",\\n         \"type\": \"org.application.info\",\\n         \"source\": \"applicationssource\",\\n         \"correlation\": [\\n          {\\n            \"contextAttributeName\": \"applicantId\"\\n          }\\n         ]\\n      }\\n   ]\\n}\\n\\nReferenced resource must conform to the specifications Workflow Events JSON Schema.\\n\\nThe retries property can be either an in-line retry definition array, or an URI reference to\\na resource containing an array of retry definition.\\nReferenced resource can be used by multiple workflow definitions. For more information about\\nusing and referencing retry definitions see the Workflow Error Handling section.\\n\\nThe keepActive property allows you to change the default behavior of workflow instances.\\nBy default, as described in the Core Concepts section, a workflow instance is terminated once there are no more\\nactive execution paths, one of its active paths ends in a \"terminate\" end definition, or when\\nits workflowExecTimeout time is reached.\\n\\nSetting the keepActive property to true allows you to change this default behavior in that a workflow instance\\ncreated from this workflow definition can only be terminated if one of its active paths ends in a \"terminate\" end definition, or when\\nits workflowExecTimeout time is reached.\\nThis allows you to explicitly model workflows where an instance should be kept alive, to collect (event) data for example.\\n\\nYou can reference the specification examples to see the keepActive property in action.\\n\\nThe extensions property can be used to define extensions for this workflow definition.\\nYou can learn more about workflow extensions in the Extensions section.\\nSample extensions property definition could look like this for example:\\n\\njson\\n{\\n  \"extensions\": [\\n    {\\n      \"extensionId\": \"workflow-ratelimiting-extension\",\\n      \"path\": \"file://myextensions/ratelimiting.yml\"\\n    },\\n    {\\n      \"extensionId\": \"workflow-kpi-extension\",\\n      \"path\": \"file://myextensions/kpi.yml\"\\n    }\\n  ]\\n}\\n\\nHere we define two workflow extensions, namely the rate limiting and kpi extensions for our workflow definition.\\n\\nWorkflow States\\n\\nWorkflow states define building blocks of the workflow execution instructions. They define the\\ncontrol flow logic instructions on what the workflow is supposed to do.\\nServerless Workflow defines the following Workflow States:\\n\\nEvent\\n\\nOperation\\n\\nSwitch\\n\\nSleep\\n\\nParallel\\n\\nInject\\n\\nForEach\\n\\nCallback\\n\\nEvent State\\n\\nonEvents | Define the events to be consumed and optional actions to be performed | array | yes |\\n|\\n\\ntimeouts | State specific timeout settings | object | no |\\n|\\n\\nstateDataFilter | State data filter definition| object | no |\\n|\\n\\ntransition | Next transition of the workflow after all the actions have been performed | string or object | yes (if\\n\\nonErrors | States error handling definitions | array | no |\\n|\\n\\nend | Is this state an end state | boolean or object | yes (if\\n\\ncompensatedBy | Unique name of a workflow state which is responsible for compensation of this state | string | no |\\n|\\n\\nmetadata | Metadata information| object | no |\\n\\n```json\\n{\\n\"name\": \"MonitorVitals\",\\n\"type\": \"event\",\\n\"exclusive\": true,\\n\"onEvents\": [{\\n        \"eventRefs\": [\"HighBodyTemperature\"],\\n        \"actions\": [{\\n            \"functionRef\": {\\n                \"refName\": \"sendTylenolOrder\",\\n                \"arguments\": {\\n                    \"patientid\": \"${ .patientId }\"\\n                }\\n            }\\n        }]\\n    },\\n    {\\n        \"eventRefs\": [\"HighBloodPressure\"],\\n        \"actions\": [{\\n            \"functionRef\": {\\n                \"refName\": \"callNurse\",\\n                \"arguments\": {\\n                    \"patientid\": \"${ .patientId }\"\\n                }\\n            }\\n        }]\\n    },\\n    {\\n        \"eventRefs\": [\"HighRespirationRate\"],\\n        \"actions\": [{\\n            \"functionRef\": {\\n                \"refName\": \"callPulmonologist\",\\n                \"arguments\": {\\n                    \"patientid\": \"${ .patientId }\"\\n                }\\n            }\\n        }]\\n    }\\n],\\n\"end\": {\\n    \"terminate\": true\\n}\\n}\\n```\\n\\n```yaml\\nname: MonitorVitals\\ntype: event\\nexclusive: true\\nonEvents:\\n- eventRefs:\\n  - HighBodyTemperature\\n  actions:\\n  - functionRef:\\n      refName: sendTylenolOrder\\n      arguments:\\n        patientid: \"${ .patientId }\"\\n- eventRefs:\\n  - HighBloodPressure\\n  actions:\\n  - functionRef:\\n      refName: callNurse\\n      arguments:\\n        patientid: \"${ .patientId }\"\\n- eventRefs:\\n  - HighRespirationRate\\n  actions:\\n  - functionRef:\\n      refName: callPulmonologist\\n      arguments:\\n        patientid: \"${ .patientId }\"\\nend:\\n  terminate: true\\n```\\n\\nEvent states await one or more events and perform actions when they are received.\\nIf defined as the workflow starting state, the event state definition controls when the workflow\\ninstances should be created.\\n\\nThe exclusive property determines if the state should wait for any of the defined events in the onEvents array, or\\nif all defined events must be present for their associated actions to be performed.\\n\\nFollowing two figures illustrate the exclusive property:\\n\\nIf the Event state in this case is a workflow starting state, the occurrence of any of the defined events would start a new workflow instance.\\n\\nIf the Event state in this case is a workflow starting state, the occurrence of all defined events would start a new\\nworkflow instance.\\n\\nIn order to consider only events that are related to each other, we need to set the correlation property in the workflow\\nevents definitions. This allows us to set up event correlation rules against the events\\nextension context attributes.\\n\\nIf the Event state is not a workflow starting state, the timeout property can be used to define the time duration from the\\ninvocation of the event state. If the defined event, or events have not been received during this time,\\nthe state should transition to the next state or can end the workflow execution (if it is an end state).\\n\\nthis section.\\nFor more information about workflow timeouts reference the\\n\\nWorkflow Timeouts section.\\n\\nNote that transition and end properties are mutually exclusive, meaning that you cannot define both of them at the same time.\\n\\nOperation State\\n\\nactions | Actions to be performed | array | yes |\\n|\\n\\ntimeouts | State specific timeout settings | object | no |\\n|\\n\\nstateDataFilter | State data filter | object | no |\\n|\\n\\nonErrors | States error handling and retries definitions | array | no |\\n|\\n\\ntransition | Next transition of the workflow after all the actions have been performed | string or object | yes (if\\n\\ncompensatedBy | Unique name of a workflow state which is responsible for compensation of this state | string | no |\\n|\\n\\nusedForCompensation | If\\n\\nmetadata | Metadata information| object | no |\\n|\\n\\nend | Is this state an end state | boolean or object | yes (if\\n\\n```json\\n{\\n    \"name\": \"RejectApplication\",\\n    \"type\": \"operation\",\\n    \"actionMode\": \"sequential\",\\n    \"actions\": [\\n        {\\n            \"functionRef\": {\\n                \"refName\": \"sendRejectionEmailFunction\",\\n                \"arguments\": {\\n                    \"customer\": \"${ .customer }\"\\n                }\\n            }\\n        }\\n    ],\\n    \"end\": true\\n}\\n```\\n\\n```yaml\\nname: RejectApplication\\ntype: operation\\nactionMode: sequential\\nactions:\\n- functionRef:\\n    refName: sendRejectionEmailFunction\\n    arguments:\\n      customer: \"${ .customer }\"\\nend: true\\n```\\n\\nOperation state defines a set of actions to be performed in sequence or in parallel.\\nOnce all actions have been performed, a transition to another state can occur.\\n\\nThe timeouts property can be used to define state specific timeout settings. Operation states can define\\nthe stateExecTimeout and actionExecTimeout settings. For more information on Workflow timeouts reference\\nthe Workflow Timeouts section.\\n\\nSwitch State\\n\\ndataConditions | Defined if the Switch state evaluates conditions and transitions based on state data. | array | yes (if\\n\\neventConditions | Defined if the Switch state evaluates conditions and transitions based on arrival of events. | array | yes (if\\n\\nstateDataFilter | State data filter | object | no |\\n|\\n\\nonErrors | States error handling and retries definitions | array | no |\\n|\\n\\ntimeouts | State specific timeout settings | object | no |\\n| defaultCondition | Default transition of the workflow if there is no matching data conditions or event timeout is reached. Can be a transition or end definition | object | yes |\\n|\\n\\ncompensatedBy | Unique name of a workflow state which is responsible for compensation of this state | string | no |\\n|\\n\\nusedForCompensation | If\\n\\nmetadata | Metadata information| object | no |\\n\\n```json\\n{\\n     \"name\":\"CheckVisaStatus\",\\n     \"type\":\"switch\",\\n     \"eventConditions\": [\\n        {\\n          \"eventRef\": \"visaApprovedEvent\",\\n          \"transition\": \"HandleApprovedVisa\"\\n        },\\n        {\\n          \"eventRef\": \"visaRejectedEvent\",\\n          \"transition\": \"HandleRejectedVisa\"\\n        }\\n     ],\\n     \"timeouts\": {\\n       \"eventTimeout\": \"PT1H\"\\n     },\\n     \"defaultCondition\": {\\n        \"transition\": \"HandleNoVisaDecision\"\\n     }\\n}\\n```\\n\\n```yaml\\nname: CheckVisaStatus\\ntype: switch\\neventConditions:\\n- eventRef: visaApprovedEvent\\n  transition: HandleApprovedVisa\\n- eventRef: visaRejectedEvent\\n  transition: HandleRejectedVisa\\ntimeouts:\\n  eventTimeout: PT1H\\ndefaultCondition:\\n  transition: HandleNoVisaDecision\\n```\\n\\nSwitch states can be viewed as workflow gateways: they can direct transitions of a workflow based on certain conditions.\\nThere are two types of conditions for switch states:\\n\\nData-based conditions\\n\\nEvent-based conditions\\n\\nThese are exclusive, meaning that a switch state can define one or the other condition type, but not both.\\n\\nAt times multiple defined conditions can be evaluated to true by runtime implementations.\\nConditions defined first take precedence over conditions defined later. This is backed by the fact that arrays/sequences\\nare ordered in both JSON and YAML. For example, let\\'s say there are two true conditions: A and B, defined in that order.\\nBecause A was defined first, its transition will be executed, not B\\'s.\\n\\nIn case of data-based conditions definition, switch state controls workflow transitions based on the states data.\\nIf no defined conditions can be matched, the state transitions is taken based on the defaultCondition property.\\nThis property can be either a transition to another workflow state, or an end definition meaning a workflow end.\\n\\nFor event-based conditions, a switch state acts as a workflow wait state. It halts workflow execution\\nuntil one of the referenced events arrive, then making a transition depending on that event definition.\\nIf events defined in event-based conditions do not arrive before the states eventTimeout property expires,\\nstate transitions are based on the defined defaultCondition property.\\n\\nThe timeouts property can be used to define state specific timeout settings. Switch states can define the\\nstateExecTimeout setting. If eventConditions is defined, the switch state can also define the\\neventTimeout property. For more information on workflow timeouts reference the Workflow Timeouts section.\\n\\nSleep State\\n\\n| Parameter | Description | Type | Required |\\n| --- | --- | --- | --- |\\n| name | Unique State name | string | yes |\\n| type | State type | string | yes |\\n| duration | Duration (ISO 8601 duration format) to sleep. For example: \"PT15M\" (sleep 15 minutes), or \"P2DT3H4M\" (sleep 2 days, 3 hours and 4 minutes) | string | yes |\\n| transition | Next transition of the workflow after the sleep | string or object | yes (if end is not defined) |\\n| end | Is this state an end state | boolean or object | yes (if transition is not defined) |\\n\\n```json\\n{\\n      \"name\": \"SleepFiveSeconds\",\\n      \"type\": \"sleep\",\\n      \"duration\": \"PT5S\",\\n      \"transition\": \"GetJobStatus\"\\n}\\n```\\n\\n```yaml\\nname: SleepFiveSeconds\\ntype: sleep\\nduration: PT5S\\ntransition: GetJobStatus\\n```\\n\\nSleep state \\nsuspends workflow execution for a given time duration. The delay is defined in its duration property using the ISO 8601 \\nduration format.\\n\\nNote that transition and end properties are mutually exclusive, meaning that you cannot define both of them at the same time.\\n\\nParallel State\\n\\nbranches | List of branches for this parallel state| array | yes |\\n| completionType | Option types on how to complete branch execution. Default is \"allOf\" | enum | no |\\n| numCompleted | Used when branchCompletionType is set to\\n\\ntimeouts | State specific timeout settings | object | no |\\n|\\n\\nstateDataFilter | State data filter | object | no |\\n|\\n\\nonErrors | States error handling and retries definitions | array | no |\\n|\\n\\ntransition | Next transition of the workflow after all branches have completed execution | string or object | yes (if\\n\\ncompensatedBy | Unique name of a workflow state which is responsible for compensation of this state | string | no |\\n|\\n\\nusedForCompensation | If\\n\\nmetadata | Metadata information| object | no |\\n|\\n\\nend | Is this state an end state | boolean or object | yes (if\\n\\n```json\\n {\\n     \"name\":\"ParallelExec\",\\n     \"type\":\"parallel\",\\n     \"completionType\": \"allOf\",\\n     \"branches\": [\\n        {\\n          \"name\": \"Branch1\",\\n          \"actions\": [\\n            {\\n                \"functionRef\": {\\n                    \"refName\": \"functionNameOne\",\\n                    \"arguments\": {\\n                        \"order\": \"${ .someParam }\"\\n                    }\\n                }\\n            }\\n        ]\\n        },\\n        {\\n          \"name\": \"Branch2\",\\n          \"actions\": [\\n              {\\n                  \"functionRef\": {\\n                      \"refName\": \"functionNameTwo\",\\n                      \"arguments\": {\\n                          \"order\": \"${ .someParam }\"\\n                      }\\n                  }\\n              }\\n          ]\\n        }\\n     ],\\n     \"end\": true\\n}\\n```\\n\\n```yaml\\nname: ParallelExec\\ntype: parallel\\ncompletionType: allOf\\nbranches:\\n- name: Branch1\\n  actions:\\n  - functionRef:\\n      refName: functionNameOne\\n      arguments:\\n        order: \"${ .someParam }\"\\n- name: Branch2\\n  actions:\\n  - functionRef:\\n      refName: functionNameTwo\\n      arguments:\\n        order: \"${ .someParam }\"\\nend: true\\n```\\n\\nParallel state defines a collection of branches that are executed in parallel.\\nA parallel state can be seen a state which splits up the current workflow instance execution path\\ninto multiple ones, one for each branch. These execution paths are performed in parallel\\nand are joined back into the current execution path depending on the defined completionType parameter value.\\n\\nThe \"completionType\" enum specifies the different ways of completing branch execution:\\n\\nallOf: All branches must complete execution before the state can transition/end. This is the default value in case this parameter is not defined in the parallel state definition.\\n\\natLeast: State can transition/end once at least the specified number of branches have completed execution. In this case you must also\\n  specify the numCompleted property to define this number.\\n\\nExceptions may occur during execution of branches of the Parallel state, this is described in detail in this section.\\n\\nThe timeouts property can be used to set state specific timeout settings. Parallel states can define the\\nstateExecTimeout and branchExecTimeout timeout settings. For more information on workflow timeouts\\nreference the Workflow Timeouts section.\\n\\nNote that transition and end properties are mutually exclusive, meaning that you cannot define both of them at the same time.\\n\\nInject State\\n\\nstateDataFilter | State data filter | object | no |\\n|\\n\\ntransition | Next transition of the workflow after injection has completed | string or object | yes (if\\n\\ncompensatedBy | Unique name of a workflow state which is responsible for compensation of this state | string | no |\\n|\\n\\nusedForCompensation | If\\n\\nmetadata | Metadata information| object | no |\\n|\\n\\nend | Is this state an end state | boolean or object | yes (if\\n\\n```json\\n{\\n     \"name\":\"Hello\",\\n     \"type\":\"inject\",\\n     \"data\": {\\n        \"result\": \"Hello\"\\n     },\\n     \"transition\": \"World\"\\n}\\n```\\n\\n```yaml\\nname: Hello\\ntype: inject\\ndata:\\n  result: Hello\\ntransition: World\\n```\\n\\nInject state can be used to inject static data into state data input. Inject state does not perform any actions.\\nIt is very useful for debugging, for example, as you can test/simulate workflow execution with pre-set data that would typically\\nbe dynamic in nature (e.g., function calls, events).\\n\\nThe inject state data property allows you to statically define a JSON object which gets added to the states data input.\\nYou can use the filter property to control the states data output to the transition state.\\n\\nHere is a typical example of how to use the inject state to add static data into its states data input, which then is passed\\nas data output to the transition state:\\n\\n```json\\n  {\\n   \"name\":\"SimpleInjectState\",\\n   \"type\":\"inject\",\\n   \"data\": {\\n      \"person\": {\\n        \"fname\": \"John\",\\n        \"lname\": \"Doe\",\\n        \"address\": \"1234 SomeStreet\",\\n        \"age\": 40\\n      }\\n   },\\n   \"transition\": \"GreetPersonState\"\\n  }\\n  ```\\n\\n```yaml\\n  name: SimpleInjectState\\n  type: inject\\n  data:\\n    person:\\n      fname: John\\n      lname: Doe\\n      address: 1234 SomeStreet\\n      age: 40\\n  transition: GreetPersonState\\n```\\n\\nThe data output of the \"SimpleInjectState\" which then is passed as input to the transition state would be:\\n\\n```json\\n{\\n \"person\": {\\n      \"fname\": \"John\",\\n      \"lname\": \"Doe\",\\n      \"address\": \"1234 SomeStreet\",\\n      \"age\": 40\\n }\\n}\\n\\n```\\n\\nIf the inject state already receives a data input from the previous transition state, the inject data should be merged\\nwith its data input.\\n\\nYou can also use the filter property to filter the state data after data is injected. Let\\'s say we have:\\n\\n```json\\n  {\\n     \"name\":\"SimpleInjectState\",\\n     \"type\":\"inject\",\\n     \"data\": {\\n        \"people\": [\\n          {\\n             \"fname\": \"John\",\\n             \"lname\": \"Doe\",\\n             \"address\": \"1234 SomeStreet\",\\n             \"age\": 40\\n          },\\n          {\\n             \"fname\": \"Marry\",\\n             \"lname\": \"Allice\",\\n             \"address\": \"1234 SomeStreet\",\\n             \"age\": 25\\n          },\\n          {\\n             \"fname\": \"Kelly\",\\n             \"lname\": \"Mill\",\\n             \"address\": \"1234 SomeStreet\",\\n             \"age\": 30\\n          }\\n        ]\\n     },\\n     \"stateDataFilter\": {\\n        \"output\": \"${ {people: [.people[] | select(.age < 40)]} }\"\\n     },\\n     \"transition\": \"GreetPersonState\"\\n    }\\n```\\n\\n```yaml\\n  name: SimpleInjectState\\n  type: inject\\n  data:\\n    people:\\n    - fname: John\\n      lname: Doe\\n      address: 1234 SomeStreet\\n      age: 40\\n    - fname: Marry\\n      lname: Allice\\n      address: 1234 SomeStreet\\n      age: 25\\n    - fname: Kelly\\n      lname: Mill\\n      address: 1234 SomeStreet\\n      age: 30\\n  stateDataFilter:\\n    output: \"${ {people: [.people[] | select(.age < 40)]} }\"\\n  transition: GreetPersonState\\n```\\n\\nIn which case the states data output would include only people whose age is less than 40:\\n\\njson\\n{\\n  \"people\": [\\n    {\\n      \"fname\": \"Marry\",\\n      \"lname\": \"Allice\",\\n      \"address\": \"1234 SomeStreet\",\\n      \"age\": 25\\n    },\\n    {\\n      \"fname\": \"Kelly\",\\n      \"lname\": \"Mill\",\\n      \"address\": \"1234 SomeStreet\",\\n      \"age\": 30\\n    }\\n  ]\\n}\\n\\nYou can change your output path easily during testing, for example change the expression to:\\n\\ntext\\n${ {people: [.people[] | select(.age >= 40)]} }\\n\\nThis allows you to test if your workflow behaves properly for cases when there are people whose age is greater or equal 40.\\n\\nNote that transition and end properties are mutually exclusive, meaning that you cannot define both of them at the same time.\\n\\nForEach State\\n\\nactions | Actions to be executed for each of the elements of inputCollection | array | yes |\\n|\\n\\ntimeouts | State specific timeout settings | object | no |\\n|\\n\\nstateDataFilter | State data filter definition | object | no |\\n|\\n\\nonErrors | States error handling and retries definitions | array | no |\\n|\\n\\ntransition | Next transition of the workflow after state has completed | string or object | yes (if\\n\\ncompensatedBy | Unique name of a workflow state which is responsible for compensation of this state | string | no |\\n|\\n\\nusedForCompensation | If\\n\\nmetadata | Metadata information| object | no |\\n|\\n\\nend | Is this state an end state | boolean or object | yes (if\\n\\n```json\\n{\\n    \"name\": \"ProvisionOrdersState\",\\n    \"type\": \"foreach\",\\n    \"inputCollection\": \"${ .orders }\",\\n    \"iterationParam\": \"singleorder\",\\n    \"outputCollection\": \"${ .provisionresults }\",\\n    \"actions\": [\\n        {\\n            \"functionRef\": {\\n                \"refName\": \"provisionOrderFunction\",\\n                \"arguments\": {\\n                    \"order\": \"${ $singleorder }\"\\n                }\\n            }\\n        }\\n    ]\\n}\\n```\\n\\n```yaml\\nname: ProvisionOrdersState\\ntype: foreach\\ninputCollection: \"${ .orders }\"\\niterationParam: \"singleorder\"\\noutputCollection: \"${ .provisionresults }\"\\nactions:\\n- functionRef:\\n    refName: provisionOrderFunction\\n    arguments:\\n      order: \"${ $singleorder }\"\\n```\\n\\nForEach states can be used to execute actions for each element of a data set.\\n\\nEach iteration of the ForEach state is by default executed in parallel by default.\\nHowever, executing iterations sequentially is also possible by setting the value of the mode property to\\nsequential.\\n\\nThe mode property defines if iterations should be done sequentially or in parallel. By default,\\nif mode is not specified, iterations should be done in parallel.\\n\\nIf the default parallel iteration mode is used, the batchSize property to the number of iterations (batch) \\nthat can be executed at a time. To give an example, if the number of iterations is 55 and batchSize\\nis set to 10, 10 iterations are to be executed at a time, meaning that the state would execute 10 iterations in parallel,\\nthen execute the next batch of 10 iterations. After 5 such executions, the remaining 5 iterations are to be executed in the last batch.\\nThe batch size value must be greater than 1. If not specified, its value should be the size of the inputCollection (all iterations).\\n\\nThe inputCollection property is a workflow expression which selects an array in the states data. All iterations\\nare performed against data elements of this array. If this array does not exist, the runtime should throw\\nan error. This error can be handled inside the states onErrors definition.\\n\\nThe outputCollection property is a workflow expression which selects an array in the state data where the results\\nof each iteration should be added to. If this array does not exist, it should be created.\\n\\nThe iterationParam property defines the name of the iteration parameter passed to each iteration of the ForEach state.\\nIt should contain the unique element of the inputCollection array and made available to actions of the ForEach state.\\niterationParam can be accessed as an expression variable. In JQ, expression variables are prefixed by $. \\nIf iterationParam is not explicitly defined, runtimes should create one and populate it with the value of the unique \\niteration parameter for each iteration of the ForEach state.\\n\\nThe actions property defines actions to be executed in each state iteration.\\n\\nLet\\'s take a look at an example:\\n\\nIn this example the data input to our workflow is an array of orders:\\n\\njson\\n{\\n    \"orders\": [\\n        {\\n            \"orderNumber\": \"1234\",\\n            \"completed\": true,\\n            \"email\": \"firstBuyer@buyer.com\"\\n        },\\n        {\\n            \"orderNumber\": \"5678\",\\n            \"completed\": true,\\n            \"email\": \"secondBuyer@buyer.com\"\\n        },\\n        {\\n            \"orderNumber\": \"9910\",\\n            \"completed\": false,\\n            \"email\": \"thirdBuyer@buyer.com\"\\n        }\\n    ]\\n}\\n\\nand our workflow is defined as:\\n\\n```json\\n{\\n  \"id\": \"sendConfirmWorkflow\",\\n  \"name\": \"SendConfirmationForCompletedOrders\",\\n  \"version\": \"1.0.0\",\\n  \"specVersion\": \"0.8\",\\n  \"start\": \"SendConfirmState\",\\n  \"functions\": [\\n  {\\n    \"name\": \"sendConfirmationFunction\",\\n    \"operation\": \"file://confirmationapi.json#sendOrderConfirmation\"\\n  }\\n  ],\\n  \"states\": [\\n  {\\n      \"name\":\"SendConfirmState\",\\n      \"type\":\"foreach\",\\n      \"inputCollection\": \"${ [.orders[] | select(.completed == true)] }\",\\n      \"iterationParam\": \"completedorder\",\\n      \"outputCollection\": \"${ .confirmationresults }\",\\n      \"actions\":[\\n      {\\n       \"functionRef\": {\\n         \"refName\": \"sendConfirmationFunction\",\\n         \"arguments\": {\\n           \"orderNumber\": \"${ $completedorder.orderNumber }\",\\n           \"email\": \"${ $completedorder.email }\"\\n         }\\n       }\\n      }],\\n      \"end\": true\\n  }]\\n}\\n```\\n\\n```yaml\\nid: sendConfirmWorkflow\\nname: SendConfirmationForCompletedOrders\\nversion: \\'1.0.0\\'\\nspecVersion: \\'0.8\\'\\nstart: SendConfirmState\\nfunctions:\\n- name: sendConfirmationFunction\\n  operation: file://confirmationapi.json#sendOrderConfirmation\\nstates:\\n- name: SendConfirmState\\n  type: foreach\\n  inputCollection: \"${ [.orders[] | select(.completed == true)] }\"\\n  iterationParam: completedorder\\n  outputCollection: \"${ .confirmationresults }\"\\n  actions:\\n  - functionRef:\\n      refName: sendConfirmationFunction\\n      arguments:\\n        orderNumber: \"${ $completedorder.orderNumber }\"\\n        email: \"${ $completedorder.email }\"\\n  end: true\\n```\\n\\nThe workflow data input containing order information is passed to the SendConfirmState ForEach state.\\nThe ForEach state defines an inputCollection property which selects all orders that have the completed property set to true.\\n\\nFor each element of the array selected by inputCollection a JSON object defined by iterationParam should be\\ncreated containing an unique element of inputCollection and passed as the data input to the parallel executed actions.\\n\\nSo for this example, we would have two parallel executions of the sendConfirmationFunction, the first one having data:\\n\\njson\\n{\\n    \"completedorder\": {\\n        \"orderNumber\": \"1234\",\\n        \"completed\": true,\\n        \"email\": \"firstBuyer@buyer.com\"\\n    }\\n}\\n\\nand the second:\\n\\njson\\n{\\n    \"completedorder\": {\\n        \"orderNumber\": \"5678\",\\n        \"completed\": true,\\n        \"email\": \"secondBuyer@buyer.com\"\\n    }\\n}\\n\\nThe results of each parallel action execution are stored as elements in the state data array defined by the outputCollection property.\\n\\nThe timeouts property can be used to set state specific timeout settings. ForEach states can define the\\nstateExecTimeout and actionExecTimeout settings. For more information on workflow timeouts reference the Workflow Timeouts\\nsection.\\n\\nNote that transition and end properties are mutually exclusive, meaning that you cannot define both of them at the same time.\\n\\nCallback State\\n\\naction | Defines the action to be executed | object | yes |\\n| eventRef | References an unique callback event name in the defined workflow\\n\\nevents | string | yes |\\n|\\n\\ntimeouts | State specific timeout settings | object | no |\\n|\\n\\neventDataFilter | Callback event data filter definition | object | no |\\n|\\n\\nstateDataFilter | State data filter definition | object | no |\\n|\\n\\nonErrors | States error handling and retries definitions | array | no |\\n|\\n\\ntransition | Next transition of the workflow after callback event has been received | string or object | yes (if\\n\\nend | Is this state an end state | boolean or object | yes (if\\n\\ncompensatedBy | Uniaue name of a workflow state which is responsible for compensation of this state | string | no |\\n|\\n\\nusedForCompensation | If\\n\\nmetadata | Metadata information| object | no |\\n\\n```json\\n{\\n        \"name\": \"CheckCredit\",\\n        \"type\": \"callback\",\\n        \"action\": {\\n            \"functionRef\": {\\n                \"refName\": \"callCreditCheckMicroservice\",\\n                \"arguments\": {\\n                    \"customer\": \"${ .customer }\"\\n                }\\n            }\\n        },\\n        \"eventRef\": \"CreditCheckCompletedEvent\",\\n        \"timeouts\": {\\n          \"stateExecTimeout\": \"PT15M\"\\n        },\\n        \"transition\": \"EvaluateDecision\"\\n}\\n```\\n\\n```yaml\\nname: CheckCredit\\ntype: callback\\naction:\\n  functionRef:\\n    refName: callCreditCheckMicroservice\\n    arguments:\\n      customer: \"${ .customer }\"\\neventRef: CreditCheckCompletedEvent\\ntimeouts:\\n  stateExecTimeout: PT15M\\ntransition: EvaluateDecision\\n```\\n\\nServerless orchestration can at times require manual steps/decisions to be made. While some work performed\\nin a serverless workflow can be executed automatically, some decisions must involve manual steps (e.g., human decisions).\\nThe Callback state allows you to explicitly model manual decision steps during workflow execution.\\n\\nThe action property defines a function call that triggers an external activity/service. Once the action executes,\\nthe callback state will wait for a CloudEvent (defined via the eventRef property), which indicates the completion\\nof the manual decision by the called service.\\n\\nNote that the called decision service is responsible for emitting the callback CloudEvent indicating the completion of the\\ndecision and including the decision results as part of the event payload. This event must be correlated to the\\nworkflow instance using the callback events context attribute defined in the correlation property of the\\nreferenced Event Definition.\\n\\nOnce the completion (callback) event is received, the Callback state completes its execution and transitions to the next\\ndefined workflow state or completes workflow execution in case it is an end state.\\n\\nThe callback event payload is merged with the Callback state data and can be filtered via the \"eventDataFilter\" definition.\\n\\nIf the defined callback event has not been received during this time period, the state should transition to the next state or end workflow execution if it is an end state.\\n\\nThe timeouts property defines state specific timeout settings. Callback states can define the\\nstateExecTimeout, actionExecTimeout, and eventTimeout properties.\\nFor more information on workflow timeouts reference the Workflow Timeouts\\nsection.\\n\\nNote that transition and end properties are mutually exclusive, meaning that you cannot define both of them at the same time.\\n\\nRelated State Definitions\\n\\nFunction Definition\\n\\n| Parameter | Description | Type | Required |\\n| --- | --- | --- | --- |\\n| name | Unique function name | string | yes |\\n| operation | If type is rest, #. If type is asyncapi, #. If type is rpc, ##. If type is graphql, ##. If type is odata, #. If type is expression, defines the workflow expression. | string | yes |\\n| type | Defines the function type. Can be either rest, asyncapi, rpc, graphql, odata, expression, or custom. Default is rest | enum | no |\\n| authRef | References an auth definition name to be used to access to resource defined in the operation parameter | string | no |\\n| metadata | Metadata information. Can be used to define custom function information | object | no |\\n\\n```json\\n{\\n   \"name\": \"HelloWorldFunction\",\\n   \"operation\": \"https://hellworldservice.api.com/api.json#helloWorld\"\\n}\\n```\\n\\n```yaml\\nname: HelloWorldFunction\\noperation: https://hellworldservice.api.com/api.json#helloWorld\\n```\\n\\nThe name property defines an unique name of the function definition.\\n\\nThe type property defines the function type. Its value can be either rest or expression. Default value is rest.\\n\\nDepending on the function type, the operation property can be:\\n\\nIf type is rest, a combination of the function/service OpenAPI definition document URI and the particular service operation that needs to be invoked, separated by a \\'#\\'.\\n  For example https://petstore.swagger.io/v2/swagger.json#getPetById.\\n\\nIf type is asyncapi, a combination of the AsyncApi definition document URI and the particular service operation that needs to be invoked, separated by a \\'#\\'.\\n  For example file://streetlightsapi.yaml#onLightMeasured.\\n\\nIf type is rpc, a combination of the gRPC proto document URI and the particular service name and service method name that needs to be invoked, separated by a \\'#\\'.\\n  For example file://myuserservice.proto#UserService#ListUsers.\\n\\nIf type is graphql, a combination of the GraphQL schema definition URI and the particular service name and service method name that needs to be invoked, separated by a \\'#\\'.\\n  For example file://myuserservice.proto#UserService#ListUsers.\\n\\nIf type is odata, a combination of the GraphQL schema definition URI and the particular service name and service method name that needs to be invoked, separated by a \\'#\\'.\\n  For example https://services.odata.org/V3/OData/OData.svc#Products.\\n\\nIf type is expression, defines the expression syntax. Take a look at the workflow expressions section for more information on this.\\n\\nDefining custom function types is possible, for more information on that refer to the Defining custom function types section.\\n\\nThe authRef property references a name of a defined workflow auth definition.\\nIt is used to provide authentication info to access the resource defined in the operation property and/or to invoke the function.\\n\\nThe metadata property allows users to define custom information to function definitions.\\nThis allows you for example to define functions that describe of a command executions on a Docker image:\\n\\nyaml\\nfunctions:\\n- name: whalesayimage\\n  metadata:\\n    image: docker/whalesay\\n    command: cowsay\\n\\nNote that using metadata for cases such as above heavily reduces the portability of your workflow markup.\\n\\nFunction definitions themselves do not define data input parameters. Parameters can be\\ndefined via the parameters property in function definitions inside actions.\\n\\nAuthRef Definition\\n\\n| Parameter | Description | Type | Required |\\n| --- | --- | --- | --- |\\n| resource | References an auth definition to be used to access the resource defined in the operation parameter | string | yes |\\n| invocation | References an auth definition to be used to invoke the operation | string | no |\\n\\nThe authRef property references a name of a defined workflow auth definition. It can be a string or an object.\\n\\nIf it\\'s a string, the referenced auth definition is used solely for the function\\'s invocation.\\n\\nIf it\\'s an object, it is possible to specify an auth definition to use for the function\\'s resource retrieval (as defined by the operation property) and another for its invocation.\\n\\nExample of a function definition configured to use an auth definition called \"My Basic Auth\" upon invocation:\\n\\nyaml\\nfunctions:\\n- name: SecuredFunctionInvocation\\n  operation: https://test.com/swagger.json#HelloWorld\\n  authRef: My Basic Auth\\n\\nExample of a function definition configured to use an auth definition called \"My Basic Auth\" to retrieve the resource defined by the operation property, and an auth definition called \"My OIDC Auth\" upon invocation:\\n\\nyaml\\nfunctions:\\n- name: SecuredFunctionInvocation\\n  operation: https://test.com/swagger.json#HelloWorld\\n  authRef:\\n    resource: My Basic Auth\\n    invocation: My OIDC Auth\\n\\nNote that if multiple functions share the same operation path (which is the first component of the operation value, located before the first \\'#\\' character), and if one of them defines an auth definition for resource access, then it should always be used to access said resource.\\nIn other words, when retrieving the resource of the function \"MySecuredFunction2\" defined in the following example, the \"My Api Key Auth\" auth definition should be used, because the \"MySecuredFunction1\" has defined it for resource access. \\nThis is done to avoid unnecessary repetitions of auth definition configuration when using the same resource for multiple defined functions.\\n\\nyaml\\nfunctions:\\n  - name: MySecuredFunction1\\n    operation: https://secure.resources.com/myapi.json#helloWorld\\n    authRef:\\n      resource: My ApiKey Auth \\n  - name: MySecuredFunction2\\n    operation: https://secure.resources.com/myapi.json#holaMundo\\n\\nIt\\'s worth noting that if an auth definition has been defined for an OpenAPI function which\\'s resource declare an authentication mechanism, the later should be used instead, thus ignoring entirely the auth definition.\\n\\nEvent Definition\\n\\nCloudEvent spec constraints)| string | yes (if\\n\\ncorrelation | Define event correlation rules for this event. Only used for consumed events | array | no |\\n| dataOnly | If\\n\\nmetadata | Metadata information | object | no |\\n\\n```json\\n{\\n   \"name\": \"ApplicantInfo\",\\n   \"type\": \"org.application.info\",\\n   \"source\": \"applicationssource\",\\n   \"kind\": \"consumed\",\\n   \"correlation\": [\\n    {\\n      \"contextAttributeName\": \"applicantId\"\\n    }\\n   ]\\n}\\n```\\n\\n```yaml\\nname: ApplicantInfo\\ntype: org.application.info\\nsource: applicationssource\\nkind: consumed\\ncorrelation:\\n- contextAttributeName: applicantId\\n```\\n\\nUsed to define events and their correlations. These events can be either consumed or produced during workflow execution as well\\nas can be used to trigger function/service invocations.\\n\\nThe Serverless Workflow specification mandates that all events conform to the CloudEvents specification.\\nThis is to assure consistency and portability of the events format used.\\n\\nThe name property defines a single name of the event that is unique inside the workflow definition. This event name can be\\nthen referenced within function and state definitions.\\n\\nThe source property matches this event definition with the source\\nproperty of the CloudEvent required attributes.\\n\\nThe type property matches this event definition with the type property of the CloudEvent required attributes.\\n\\nEvent correlation plays a big role in large event-driven applications. Correlating one or more events with a particular workflow instance\\ncan be done by defining the event correlation rules within the correlation property.\\nThis property is an array of correlation definitions.\\nThe CloudEvents specification allows users to add Extension Context Attributes\\nand the correlation definitions can use these attributes to define clear matching event correlation rules.\\nExtension context attributes are not part of the event payload, so they are serialized the same way as other standard required attributes.\\nThis means that the event payload does not have to be inspected by implementations in order to read and evaluate the defined correlation rules.\\n\\nLet\\'s take a look at an example. Here we have two events that have an extension context attribute called \"patientId\" (as well as \"department\", which\\nwill be used in further examples below):\\n\\njson\\n{\\n    \"specversion\" : \"1.0\",\\n    \"type\" : \"com.hospital.patient.heartRateMonitor\",\\n    \"source\" : \"hospitalMonitorSystem\",\\n    \"subject\" : \"HeartRateReading\",\\n    \"id\" : \"A234-1234-1234\",\\n    \"time\" : \"2020-01-05T17:31:00Z\",\\n    \"patientId\" : \"PID-12345\",\\n    \"department\": \"UrgentCare\",\\n    \"data\" : {\\n      \"value\": \"80bpm\"\\n    }\\n}\\n\\nand\\n\\njson\\n{\\n    \"specversion\" : \"1.0\",\\n    \"type\" : \"com.hospital.patient.bloodPressureMonitor\",\\n    \"source\" : \"hospitalMonitorSystem\",\\n    \"subject\" : \"BloodPressureReading\",\\n    \"id\" : \"B234-1234-1234\",\\n    \"time\" : \"2020-02-05T17:31:00Z\",\\n    \"patientId\" : \"PID-12345\",\\n    \"department\": \"UrgentCare\",\\n    \"data\" : {\\n      \"value\": \"110/70\"\\n    }\\n}\\n\\nWe can then define a correlation rule, through which all consumed events with the \"hospitalMonitorSystem\", and the \"com.hospital.patient.heartRateMonitor\"\\ntype that have the same value of the patientId property to be correlated to the created workflow instance:\\n\\njson\\n{\\n\"events\": [\\n {\\n  \"name\": \"HeartRateReadingEvent\",\\n  \"source\": \"hospitalMonitorSystem\",\\n  \"type\": \"com.hospital.patient.heartRateMonitor\",\\n  \"kind\": \"consumed\",\\n  \"correlation\": [\\n    {\\n      \"contextAttributeName\": \"patientId\"\\n    }\\n  ]\\n }\\n]\\n}\\n\\nIf a workflow instance is created (e.g., via Event state) by consuming a \"HeartRateReadingEvent\" event, all other consumed events\\nfrom the defined source and with the defined type that have the same \"patientId\" as the event that triggered the workflow instance\\nshould then also be associated with the same instance.\\n\\nYou can also correlate multiple events together. In the following example, we assume that the workflow consumes two different event types,\\nand we want to make sure that both are correlated, as in the above example, with the same \"patientId\":\\n\\njson\\n{\\n\"events\": [\\n {\\n  \"name\": \"HeartRateReadingEvent\",\\n  \"source\": \"hospitalMonitorSystem\",\\n  \"type\": \"com.hospital.patient.heartRateMonitor\",\\n  \"kind\": \"consumed\",\\n  \"correlation\": [\\n    {\\n      \"contextAttributeName\": \"patientId\"\\n    }\\n  ]\\n },\\n {\\n   \"name\": \"BloodPressureReadingEvent\",\\n   \"source\": \"hospitalMonitorSystem\",\\n   \"type\": \"com.hospital.patient.bloodPressureMonitor\",\\n   \"kind\": \"consumed\",\\n   \"correlation\": [\\n       {\\n         \"contextAttributeName\": \"patientId\"\\n       }\\n     ]\\n  }\\n]\\n}\\n\\nEvent correlation can be based on equality (values of the defined \"contextAttributeName\" must be equal), but it can also be based\\non comparing it to custom defined values (string, or expression). For example:\\n\\njson\\n{\\n\"events\": [\\n {\\n  \"name\": \"HeartRateReadingEvent\",\\n  \"source\": \"hospitalMonitorSystem\",\\n  \"type\": \"com.hospital.patient.heartRateMonitor\",\\n  \"kind\": \"consumed\",\\n  \"correlation\": [\\n    {\\n      \"contextAttributeName\": \"patientId\"\\n    },\\n    {\\n      \"contextAttributeName\": \"department\",\\n      \"contextAttributeValue\" : \"UrgentCare\"\\n    }\\n  ]\\n }\\n]\\n}\\n\\nIn this example, we have two correlation rules defined: The first one is on the \"patientId\" CloudEvent context attribute, meaning again that\\nall consumed events from this source and type must have the same \"patientId\" to be considered. The second rule\\nsays that these events must all have a context attribute named \"department\" with the value of \"UrgentCare\".\\n\\nThis allows developers to write orchestration workflows that are specifically targeted to patients that are in the hospital urgent care unit,\\nfor example.\\n\\nThe dataOnly property deals with what Event data is accessible by the consuming Workflow states.\\nIf its value is true (default value), only the Event payload is accessible to consuming Workflow states.\\nIf false, both Event payload and context attributes should be accessible.\\n\\nAuth Definition\\n\\nAuth definitions can be used to define authentication information that should be applied to function definitions.\\nIt can be used for both the retrieval of the function\\'s resource (as defined by the operation property) and for the function\\'s invocation.\\n\\n| Parameter | Description | Type | Required |\\n| --- | --- | --- | --- |\\n| name | Unique auth definition name | string | yes |\\n| scheme | Auth scheme, can be \"basic\", \"bearer\", or \"oauth2\". Default is \"basic\" | enum | no |\\n| properties | Auth scheme properties. Can be one of \"Basic properties definition\", \"Bearer properties definition\", or \"OAuth2 properties definition\" | object | yes |\\n\\n\"Basic properties definition\",\\n\\n\"Bearer properties definition\", or\\n\\n\"OAuth2 properties definition\"\\n\\nBasic Properties Definition\\n\\nSee here for more information about Basic Authentication scheme.\\n\\nThe Basic properties definition can have two types, either string or object. \\nIf string type, it defines a workflow expression that contains all needed Basic auth information.\\nIf object type, it has the following properties:\\n\\n| Parameter | Description | Type | Required |\\n| --- | --- | --- | --- |\\n| username | String or a workflow expression. Contains the user name | string | yes |\\n| password | String or a workflow expression. Contains the user password | string | yes |\\n| metadata | Metadata information| object | no |\\n\\nBearer Properties Definition\\n\\nSee here for more information about Bearer Authentication scheme.\\n\\n| Parameter | Description | Type | Required |\\n| --- | --- | --- | --- |\\n| token | String or a workflow expression. Contains the token information | string | yes |\\n| metadata | Metadata information| object | no |\\n\\nOAuth2 Properties Definition\\n\\nSee here for more information about OAuth2 Authentication scheme.\\n\\n| Parameter | Description | Type | Required |\\n| --- | --- | --- | --- |\\n| authority | String or a workflow expression. Contains the authority information | string | no |\\n| grantType | Defines the grant type. Can be \"password\", \"clientCredentials\", or \"tokenExchange\" | enum | yes |\\n| clientId | String or a workflow expression. Contains the client identifier | string | yes |\\n| clientSecret | Workflow secret or a workflow expression. Contains the client secret | string | no |\\n| scopes | Array containing strings or workflow expressions. Contains the OAuth2 scopes | array | no |\\n| username | String or a workflow expression. Contains the user name. Used only if grantType is \\'resourceOwner\\' | string | no |\\n| password | String or a workflow expression. Contains the user password. Used only if grantType is \\'resourceOwner\\' | string | no |\\n| audiences | Array containing strings or workflow expressions. Contains the OAuth2 audiences | array | no |\\n| subjectToken | String or a workflow expression. Contains the subject token | string | no |\\n| requestedSubject | String or a workflow expression. Contains the requested subject | string | no |\\n| requestedIssuer | String or a workflow expression. Contains the requested issuer | string | no |\\n| metadata | Metadata information| object | no |\\n\\nCorrelation Definition\\n\\n| Parameter | Description | Type | Required |\\n| --- | --- | --- | --- |\\n| contextAttributeName | CloudEvent Extension Context Attribute name | string | yes |\\n| contextAttributeValue | CloudEvent Extension Context Attribute value | string  | no |\\n\\n```json\\n{\\n   \"correlation\": [\\n       {\\n         \"contextAttributeName\": \"patientId\"\\n       },\\n       {\\n         \"contextAttributeName\": \"department\",\\n         \"contextAttributeValue\" : \"UrgentCare\"\\n       }\\n     ]\\n}\\n```\\n\\n```yaml\\ncorrelation:\\n- contextAttributeName: patientId\\n- contextAttributeName: department\\n  contextAttributeValue: UrgentCare\\n```\\n\\nUsed to define event correlation rules. Only usable for consumed event definitions.\\n\\nThe contextAttributeName property defines the name of the CloudEvent extension context attribute.\\nThe contextAttributeValue property defines the value of the defined CloudEvent extension context attribute.\\n\\nOnEvents Definition\\n\\n| Parameter | Description | Type | Required |\\n| --- | --- | --- | --- |\\n| eventRefs | References one or more unique event names in the defined workflow events | array | yes |\\n| actionMode | Specifies how actions are to be performed (in sequence or in parallel). Default is sequential | enum | no |\\n| actions | Actions to be performed | array | no |\\n| eventDataFilter | Event data filter definition | object | no |\\n\\n```json\\n{\\n    \"eventRefs\": [\"HighBodyTemperature\"],\\n    \"actions\": [{\\n        \"functionRef\": {\\n            \"refName\": \"sendTylenolOrder\",\\n            \"arguments\": {\\n                \"patientid\": \"${ .patientId }\"\\n            }\\n        }\\n    }]\\n}\\n```\\n\\n```yaml\\neventRefs:\\n- HighBodyTemperature\\nactions:\\n- functionRef:\\n    refName: sendTylenolOrder\\n    arguments:\\n      patientid: \"${ .patientId }\"\\n```\\n\\nOnEvent definition allow you to define which actions are to be performed\\nfor the one or more events definitions defined in the eventRefs array.\\nNote that the values of eventRefs array must be unique.\\n\\nThe actionMode property defines if the defined actions need to be performed sequentially or in parallel.\\n\\nThe actions property defines a list of actions to be performed.\\n\\nWhen specifying the onEvents definition it is important to consider the Event states exclusive property,\\nbecause it determines how \\'onEvents\\' is interpreted.\\nLet\\'s look at the following JSON definition of \\'onEvents\\' to show this:\\n\\njson\\n{\\n    \"onEvents\": [{\\n        \"eventRefs\": [\"HighBodyTemperature\", \"HighBloodPressure\"],\\n        \"actions\": [{\\n                \"functionRef\": {\\n                    \"refName\": \"SendTylenolOrder\",\\n                    \"arguments\": {\\n                        \"patient\": \"${ .patientId }\"\\n                    }\\n                }\\n            },\\n            {\\n                \"functionRef\": {\\n                    \"refName\": \"CallNurse\",\\n                    \"arguments\": {\\n                        \"patient\": \"${ .patientId }\"\\n                    }\\n                }\\n            }\\n        ]\\n    }]\\n}\\n\\nDepending on the value of the Event states exclusive property, this definition can mean two different things:\\n\\nIf exclusive is set to true, the consumption of either the HighBodyTemperature or HighBloodPressure events will trigger action execution.\\n\\nIf exclusive is set to false, the consumption of both the HighBodyTemperature and HighBloodPressure events will trigger action execution.\\n\\nThis is visualized in the diagram below:\\n\\nAction Definition\\n\\nfunctionRef | References a reusable function definition | object or string | yes (if\\n\\neventRef | References a\\n\\nsubFlowRef | References a workflow to be invoked | object or string | yes (if\\n\\nretryRef | References a defined workflow retry definition. If not defined uses the default runtime retry definition | string | no |\\n| nonRetryableErrors | List of references to defined\\n\\nworkflow errors for which the action should not be retried. Used only when\\n\\nworkflow errors for which the action should be retried. Used only when\\n\\nactionDataFilter | Action data filter definition | object | no |\\n| sleep | Defines time periods workflow execution should sleep before / after function execution | object | no |\\n|\\n\\ncondition | Expression, if defined, must evaluate to\\n\\n```json\\n{\\n    \"name\": \"Finalize Application Action\",\\n    \"functionRef\": {\\n        \"refName\": \"finalizeApplicationFunction\",\\n        \"arguments\": {\\n            \"applicantid\": \"${ .applicantId }\"\\n        }\\n    }\\n}\\n```\\n\\n```yaml\\nname: Finalize Application Action\\nfunctionRef:\\n  refName: finalizeApplicationFunction\\n  arguments:\\n    applicantid: \"${ .applicantId }\"\\n```\\n\\nActions specify invocations of services or other workflows during workflow execution.\\nService invocation can be done in three different ways:\\n\\nReference functions definitions by its unique name using the functionRef property.\\n\\nReference a produced and consumed event definitions via the eventRef property.\\n\\nReference a sub-workflow invocation via the subFlowRef property.\\n\\nNote that functionRef, eventRef, and subFlowRef are mutually exclusive, meaning that only one of them can be\\nspecified in a single action definition.\\n\\nThe name property specifies the action name.\\nThe id property specifies the unique action id.\\n\\nIn the event-based scenario a service, or a set of services we want to invoke\\nare not exposed via a specific resource URI for example, but can only be invoked via an event.\\nThe eventRef property defines the\\nreferenced produced event via its produceEventRef property and a consumed event via its consumeEventRef property.\\n\\nThe sleep property can be used to define time periods that workflow execution should sleep\\nbefore and/or after function execution. It can have two properties:\\n* before - defines the amount of time (ISO 8601 duration format) to sleep before function invocation.\\n* after - defines the amount of time (ISO 8601 duration format) to sleep after function invocation.\\n\\nFunction invocation timeouts should be handled via the states timeouts definition.\\n\\nThe retryRef property references one of the defined workflow retries by it\\'s unique name. If not set, the action \\nshould be retried according to the default retry policy of the runtime implementation. For more information about workflow\\nretries reference this section.\\n\\nThe nonRetryableErrors property is a list that references one or more unique names of workflow error definitions. \\nThis is the list of known errors for which the action should not be retried for. \\nIt should be used only when the workflow top-level autoRetries property is set to true.\\n\\nThe retryableErrors property is a list that references one or more unique names of workflow error definitions.\\nThis is the list of known errors for which the action should be retried for.\\nIt should be used only when the workflow top-level autoRetries property is set to false.\\n\\nThe condition property is a workflow expression. If defined, it must evaluate to true\\nfor this action to be performed. If it evaluates to false the action is skipped. \\nIf the condition property is not defined, the action is always performed.\\n\\nSubflow Action\\n\\nOften you want to group your workflows into small logical units that solve a particular business problem and can be reused in\\nmultiple other workflow definitions.\\n\\nReusable workflows are referenced by their id property via the SubFlow action workflowId parameter.\\n\\nFor the simple case, subFlowRef can be a string containing the id of the sub-workflow to invoke.\\nIf you want to specify other parameters then a subFlowRef should be provided instead.\\n\\nEach referenced workflow receives the SubFlow actions data as workflow data input.\\n\\nReferenced sub-workflows must declare their own function and event definitions.\\n\\nFunctionRef Definition\\n\\nFunctionRef definition can have two types, either string or object.\\nIf string type, it defines the name of the referenced function.\\nThis can be used as a short-cut definition when you don\\'t need to define any other parameters, for example:\\n\\njson\\n\"functionRef\": \"myFunction\"\\n\\nNote that if used with string type, the invocation of the function is synchronous.\\n\\nIf you need to define parameters in your functionRef definition, you can define\\nit with its object type which has the following properties:\\n\\nfunction | string | yes |\\n| arguments | Arguments (inputs) to be passed to the referenced function | object | yes (if function type is\\n\\nselection set | string | yes (if function type is\\n\\n```json\\n{\\n    \"refName\": \"finalizeApplicationFunction\",\\n    \"arguments\": {\\n        \"applicantid\": \"${ .applicantId }\"\\n    }\\n}\\n```\\n\\n```yaml\\nrefName: finalizeApplicationFunction\\narguments:\\n  applicantid: \"${ .applicantId }\"\\n```\\n\\nThe refName property is the name of the referenced function.\\n\\nThe arguments property defines the arguments that are to be passed to the referenced function.\\nHere is an example of using the arguments property:\\n\\njson\\n{\\n   \"refName\": \"checkFundsAvailabe\",\\n   \"arguments\": {\\n     \"account\": {\\n       \"id\": \"${ .accountId }\"\\n     },\\n     \"forAmount\": \"${ .payment.amount }\",\\n     \"insufficientMessage\": \"The requested amount is not available.\"\\n   }\\n}\\n\\nThe invoke property defines how the function is invoked (sync or async). Default value of this property is\\nsync, meaning that workflow execution should wait until the function completes. \\nIf set to async, workflow execution should just invoke the function and should not wait until its completion.\\nNote that in this case the action does not produce any results and the associated actions actionDataFilter as well as \\nits retry definition, if defined, should be ignored.\\nIn addition, functions that are invoked async do not propagate their errors to the associated action definition and the \\nworkflow state, meaning that any errors that happen during their execution cannot be handled in the workflow states \\nonErrors definition. Note that errors raised during functions that are invoked async should not fail workflow execution.\\n\\nEventRef Definition\\n\\nAllows defining invocation of a function via event.\\n\\nproduceEventRef | Reference to the unique name of a\\n\\nconsumeEventRef | Reference to the unique name of a\\n\\nactionExecutionTimeout | string | no |\\n| data | If string type, an expression which selects parts of the states data output to become the data (payload) of the event referenced by\\n\\n```json\\n{\\n   \"eventRef\": {\\n      \"produceEventRef\": \"MakeVetAppointment\",\\n      \"data\": \"${ .patientInfo }\",\\n      \"consumeEventRef\":  \"VetAppointmentInfo\"\\n   }\\n}\\n```\\n\\n```yaml\\neventRef:\\n  produceEventRef: MakeVetAppointment\\n  data: \"${ .patientInfo }\"\\n  consumeEventRef: VetAppointmentInfo\\n```\\n\\nReferences a produced and consumed event definitions via the produceEventRef and consumeEventRef properties, respectively.\\n\\nThe data property can have two types: string or object. If it is of string type, it is an expression that can select parts of state data\\nto be used as payload of the event referenced by produceEventRef. If it is of object type, you can define a custom object to be the event payload.\\n\\nThe contextAttributes property allows you to add one or more extension context attributes\\nto the trigger/produced event.\\n\\nactionExecutionTimeout.\\nIf the event defined by the\\n\\nThe invoke property defines how the function is invoked (sync or async). Default value of this property is\\nsync, meaning that workflow execution should wait until the function completes (the result event is received).\\nIf set to async, workflow execution should just produce the trigger event and should not wait for the result event.\\nNote that in this case the action does not produce any results (payload of the result event) and the associated actions eventDataFilter as well as\\nits retry definition, if defined, should be ignored.\\nFunctions that are invoked via events (sync or async) do not propagate their errors to the associated action definition and the\\nworkflow state, meaning that any errors that happen during their execution cannot be handled in the workflow states\\nonErrors definition. Note that errors raised during functions that are invoked sync or async in this case\\nshould not fail workflow execution.\\n\\nSubFlowRef Definition\\n\\nSubFlowRef definition can have two types, namely string or object.\\n\\nIf string type, it defines the unique id of the sub-workflow to be invoked.\\nThis short-hand definition can be used if sub-workflow lookup is done only by its id\\nproperty and not its version property.\\n\\njson\\n\"subFlowRef\": \"mySubFlowId\"\\n\\nIf you need to define the version properties, you can use its object type:\\n\\n```json\\n{\\n    \"workflowId\": \"handleApprovedVisaWorkflowID\",\\n    \"version\": \"2.0.0\"\\n}\\n```\\n\\n```yaml\\nworkflowId: handleApprovedVisaWorkflowID\\nversion: \\'2.0.0\\'\\n```\\n\\nThe workflowId property define the unique ID of the sub-workflow to be invoked.\\nUsually, the workflow id should not be the same id of the workflow where the action is defined. Otherwise, it may occur undesired recurring calls to the same workflow.\\n\\nThe version property defined the unique version of the sub-workflow to be invoked.\\nIf this property is defined, runtimes should match both the id and the version properties\\ndefined in the sub-workflow definition.\\n\\nThe invoke property defines how the subflow is invoked (sync or async). Default value of this property is\\nsync, meaning that workflow execution should wait until the subflow completes.\\nIf set to async, workflow execution should just invoke the subflow and not wait for its results.\\nNote that in this case the action does not produce any results, and the associated actions actionDataFilter as well as\\nits retry definition, if defined, should be ignored.\\nSubflows that are invoked async do not propagate their errors to the associated action definition and the\\nworkflow state, meaning that any errors that happen during their execution cannot be handled in the workflow states\\nonErrors definition. Note that errors raised during subflows that are invoked async\\nshould not fail workflow execution.\\n\\nThe onParentComplete property defines how subflow execution that is invoked async should behave if the parent workflow \\ncompletes execution before the subflow completes its own execution.\\nThe default value of this property is terminate, meaning that if the parent workflow (the workflow that invoked the subflow)\\ncompletes, execution of the subflow should be terminated.\\nIf it is set to continue, if the parent workflow completes, the subflow execution is allowed to continue its own execution.\\n\\nError Definition\\n\\n| Parameter | Description | Type | Required |\\n| --- | --- | --- | --- |\\n| errorRef or errorRefs | Reference one unique workflow error definition, or multiple unique workflow error definitions | string (errorRef) or array (errorRefs) | yes |\\n| transition | Transition to next state to handle the error | string or object | yes (if end is not defined) |\\n| end | End workflow execution if this error is encountered | boolean or object | yes (if transition is not defined) |\\n\\n```json\\n{\\n   \"errorRef\": \"Item not in inventory\",\\n   \"transition\": \"IssueRefundToCustomer\"\\n}\\n```\\n\\n```yaml\\nerrorRef: Item not in inventory\\ntransition: IssueRefundToCustomer\\n```\\n\\nError definitions describe checked errors that can occur during workflow execution and how to handle them.\\n\\nThe errorRef property references the unique workflow error definition. For more info on workflow error handling\\nreferece this section.\\n\\nThe errorRefsproperty references at least one of the defined workflow error definitions. \\nCan be used when errorRef is not used. Usable when you want to define multiple error refs for which the same transition\\nor end definition should be applied.For more info on workflow error handling\\nreferece this section.\\n\\nNote that the errorRef and errorRefs properties are mutually exclusive, meaning that you can only specify one or the other,\\nbut not both at the same time.\\n\\nThe transition property defines the transition to the next workflow state in cases when the defined\\nerror happens during runtime execution.\\n\\nIf transition is not defined you can also define the end property which will end workflow execution at that point.\\nNote that the transition and end properties are mutually exclusive, meaning that you can only specify one or the other,\\nbut not both at the same time.\\n\\nFor more information, see the Workflow Error Handling sections.\\n\\nRetry Definition\\n\\n| Parameter | Description | Type | Required |\\n| --- | --- | --- | --- |\\n| name | Unique retry strategy name | string | yes |\\n| delay | Time delay between retry attempts (ISO 8601 duration format) | string | no |\\n| maxAttempts | Maximum number of retry attempts. Value of 1 means no retries are performed | string or number | yes |\\n| maxDelay | Maximum amount of delay between retry attempts (ISO 8601 duration format) | string | no |\\n| increment | Static duration which will be added to the delay between successive retries (ISO 8601 duration format) | string | no |\\n| multiplier | Float value by which the delay is multiplied before each attempt. For example: \"1.2\" meaning that each successive delay is 20% longer than the previous delay.  For example, if delay is \\'PT10S\\', then the delay between the first and second attempts will be 10 seconds, and the delay before the third attempt will be 12 seconds. | float or string | no |\\n| jitter | If float type, maximum amount of random time added or subtracted from the delay between each retry relative to total delay (between 0.0 and 1.0). If string type, absolute maximum amount of random time added or subtracted from the delay between each retry (ISO 8601 duration format) | float or string | no |\\n\\n```json\\n{\\n   \"name\": \"TimeoutRetryStrat\",\\n   \"delay\": \"PT2M\",\\n   \"maxAttempts\": 3,\\n   \"jitter\": \"PT0.001S\"\\n}\\n```\\n\\n```yaml\\nname: TimeoutRetryStrat\\ndelay: PT2M\\nmaxAttempts: 3\\njitter: PT0.001S\\n```\\n\\nDefines the states retry policy (strategy). This is an explicit definition and can be reused across multiple\\ndefined state actions.\\n\\nThe name property specifies the unique name of the retry definition (strategy). This unique name\\ncan be referred by workflow states error definitions.\\n\\nThe delay property specifies the initial time delay between retry attempts (ISO 8601 duration format).\\n\\nThe increment property specifies a static duration which will be added to the delay between successive retries.\\nTo explain this better, let\\'s say we have the following retry definition:\\n\\njson\\n{\\n  \"name\": \"Timeout Errors Strategy\",\\n  \"delay\": \"PT10S\",\\n  \"increment\": \"PT2S\",\\n  \"maxAttempts\": 4\\n}\\n\\nwhich means that we will retry up to 4 times after waiting with increasing delay between attempts;\\nin this example 10, 12, 14, and 16 seconds between retries.\\n\\nThe multiplier property specifies the value by which the interval time is increased for each of the retry attempts.\\nTo explain this better, let\\'s say we have the following retry definition:\\n\\njson\\n{\\n  \"name\": \"Timeout Errors Strategy\",\\n  \"delay\": \"PT10S\",\\n  \"multiplier\": 2,\\n  \"maxAttempts\": 4\\n}\\n\\nwhich means that we will retry up to 4 times after waiting with increasing delay between attempts;\\nin this example 10, 20, 40, and 80 seconds between retries.\\n\\nIf both increment and multiplier properties are defined, increment should be applied first and then \\nthe multiplier when determining the next retry time.\\n\\nThe maxAttempts property determines the maximum number of retry attempts allowed and is a positive integer value.\\n\\nThe jitter property is important to prevent certain scenarios where clients\\nare retrying in sync, possibly causing or contributing to a transient failure\\nprecisely because they\\'re retrying at the same time. Adding a typically small,\\nbounded random amount of time to the period between retries serves the purpose\\nof attempting to prevent these retries from happening simultaneously, possibly\\nreducing total time to complete requests and overall congestion. How this value\\nis used in the exponential backoff algorithm is left up to implementations.\\n\\njitter may be specified as a percentage relative to the total delay.\\nOnce the next retry attempt delay is calculated, we can apply jitter as a percentage value relative to this\\ncalculated delay. For example, if your calculated delay for the next retry is six seconds, and we specify \\na jitter value of 0.3, a random amount of time between 0 and 1.8 (0.3 times 6) is to be added or subtracted\\nfrom the calculated delay.\\n\\nAlternatively, jitter may be defined as an absolute value specified as an ISO\\n8601 duration. This way, the maximum amount of random time added is fixed and\\nwill not increase as new attempts are made.\\n\\nThe maxDelay property determines the maximum amount of delay that is desired between retry attempts, and is applied\\nafter increment, multiplier, and jitter.\\n\\nTo explain this better, let\\'s say we have the following retry definition:\\n\\njson\\n{\\n  \"name\": \"Timeout Errors Strategy\",\\n  \"delay\": \"PT10S\",\\n  \"maxDelay\": \"PT100S\",\\n  \"multiplier\": 4,\\n  \"jitter\": \"PT1S\",\\n  \"maxAttempts\": 4\\n}\\n\\nwhich means that we will retry up to 4 times after waiting with increasing delay between attempts;\\nin this example we might observe the following series of delays:\\n\\n11s (min(maxDelay, (delay +/- rand(jitter)) => min(100, 10 + 1))\\n\\n43s (min(maxDelay, (11s * multiplier) +/- rand(jitter)) => min(100, (11 * 4) - 1))\\n\\n100s (min(maxDelay, (43s * multiplier) +/- rand(jitter)) => min(100, (43 * 4) + 0))\\n\\n100s (min(maxDelay, (100s * multiplier) +/- rand(jitter)) => min(100, (100 * 4) - 1))\\n\\nTransition Definition\\n\\nTransition definition can have two types, either string or object.\\nIf string, it defines the name of the state to transition to.\\nThis can be used as a short-cut definition when you don\\'t need to define any other parameters, for example:\\n\\njson\\n\"transition\": \"myNextState\"\\n\\nIf you need to define additional parameters in your transition definition, you can define\\nit with its object type which has the following properties:\\n\\n| Parameter | Description | Type | Required |\\n| --- | --- | --- | --- |\\n| nextState | Name of the state to transition to next | string | yes |\\n| compensate | If set to true, triggers workflow compensation before this transition is taken. Default is false | boolean | no |\\n| produceEvents | Array of producedEvent definitions. Events to be produced before the transition takes place | array | no |\\n\\n```json\\n{\\n   \"produceEvents\": [{\\n       \"eventRef\": \"produceResultEvent\",\\n       \"data\": \"${ .result.data }\"\\n   }],\\n   \"nextState\": \"EvalResultState\"\\n}\\n```\\n\\n```yaml\\nproduceEvents:\\n- eventRef: produceResultEvent\\n  data: \"${ .result.data }\"\\nnextState: EvalResultState\\n```\\n\\nThe nextState property defines the name of the state to transition to next.\\nThe compensate property allows you to trigger compensation before the transition (if set to true).\\nThe produceEvents property allows you to define a list of events to produce before the transition happens.\\n\\nTransitions allow you to move from one state (control-logic block) to another. For more information see the\\nTransitions section section.\\n\\nSwitch State Data Conditions\\n\\ncondition | Workflow expression evaluated against state data. Must evaluate to\\n\\ntransition | Transition to another state if condition is\\n\\nend | End workflow execution if condition is\\n\\nmetadata | Metadata information| object | no |\\n\\n```json\\n{\\n      \"name\": \"Eighteen or older\",\\n      \"condition\": \"${ .applicant | .age >= 18 }\",\\n      \"transition\": \"StartApplication\"\\n}\\n```\\n\\n```yaml\\nname: Eighteen or older\\ncondition: \"${ .applicant | .age >= 18 }\"\\ntransition: StartApplication\\n```\\n\\nSwitch state data conditions specify a data-based condition statement, which causes a transition to another\\nworkflow state if evaluated to true.\\nThe condition property of the condition defines an expression (e.g., ${ .applicant | .age > 18 }), which selects\\nparts of the state data input. The condition must evaluate to true or false.\\n\\nIf the condition is evaluated to true, you can specify either the transition or end definitions\\nto decide what to do, transition to another workflow state, or end workflow execution. Note that transition and end\\ndefinitions are mutually exclusive, meaning that you can specify either one or the other, but not both.\\n\\nSwitch State Event Conditions\\n\\ntransition | Transition to another state if condition is\\n\\nend | End workflow execution if condition is\\n\\neventDataFilter | Event data filter definition | object | no |\\n|\\n\\nmetadata | Metadata information| object | no |\\n\\n```json\\n{\\n      \"name\": \"Visa approved\",\\n      \"eventRef\": \"visaApprovedEvent\",\\n      \"transition\": \"HandleApprovedVisa\"\\n}\\n```\\n\\n```yaml\\nname: Visa approved\\neventRef: visaApprovedEvent\\ntransition: HandleApprovedVisa\\n```\\n\\nSwitch state event conditions specify events, which the switch state must wait for. Each condition\\ncan reference one workflow-defined event. Upon arrival of this event, the associated transition is taken.\\nThe eventRef property references a name of one of the defined workflow events.\\n\\nIf the referenced event is received, you can specify either the transition or end definitions\\nto decide what to do, transition to another workflow state, or end workflow execution.\\n\\nThe eventDataFilter property can be used to filter event data when it is received.\\n\\nNote that transition and end\\ndefinitions are mutually exclusive, meaning that you can specify either one or the other, but not both.\\n\\nParallel State Branch\\n\\n| Parameter | Description | Type | Required |\\n| --- | --- | --- | --- |\\n| name | Branch name | string | yes |\\n| actions | Actions to be executed in this branch | array | yes |\\n| timeouts | Branch specific timeout settings | object | no |\\n\\n```json\\n{\\n      \"name\": \"Branch1\",\\n      \"actions\": [\\n          {\\n              \"functionRef\": {\\n                  \"refName\": \"functionNameOne\",\\n                  \"arguments\": {\\n                      \"order\": \"${ .someParam }\"\\n                  }\\n              }\\n          },\\n          {\\n              \"functionRef\": {\\n                  \"refName\": \"functionNameTwo\",\\n                  \"arguments\": {\\n                      \"order\": \"${ .someParamTwo }\"\\n                  }\\n              }\\n          }\\n      ]\\n}\\n```\\n\\n```yaml\\nname: Branch1\\nactions:\\n- functionRef:\\n    refName: functionNameOne\\n    arguments:\\n      order: \"${ .someParam }\"\\n- functionRef:\\n    refName: functionNameTwo\\n    arguments:\\n      order: \"${ .someParamTwo }\"\\n```\\n\\nEach branch receives the same copy of the Parallel state\\'s data input.\\n\\nA branch can define actions that need to be executed. For the SubFlowRef action, the workflow id should not be the same id of the workflow where the branch is defined. Otherwise, it may occur undesired recurring calls to the same workflow.\\n\\nThe timeouts property can be used to set branch specific timeout settings. Parallel state branches can set the\\nactionExecTimeout and branchExecTimeout timeout properties. For more information on workflow timeouts reference the\\nWorkflow Timeouts section.\\n\\nParallel State Handling Exceptions\\n\\nExceptions can occur during execution of Parallel state branches.\\n\\nBy default, exceptions that are not handled within branches stop branch execution and are propagated\\nto the Parallel state and should be handled with its onErrors definition.\\n\\nIf the parallel states branch defines actions, all exceptions that arise from executing these actions (after all\\nallotted retries are exhausted)\\nare propagated to the parallel state\\nand can be handled with the parallel states onErrors definition.\\n\\nIf the parallel states defines a subflow action, exceptions that occur during execution of the called workflow\\ncan choose to handle exceptions on their own. All unhandled exceptions from the called workflow\\nexecution however are propagated back to the parallel state and can be handled with the parallel states\\nonErrors definition.\\n\\nNote that once an error that is propagated to the parallel state from a branch and handled by the\\nstates onErrors definition is handled (its associated transition is taken) no further errors from branches of this\\nparallel state should be considered as the workflow control flow logic has already moved to a different state.\\n\\nFor more information, see the Workflow Error Handling sections.\\n\\nStart Definition\\n\\nCan be either string or object type. If type string, it defines the name of the workflow starting state.\\n\\njson\\n\"start\": \"MyStartingState\"\\n\\nIn this case it\\'s assumed that the schedule property is not defined.\\n\\nIf the start definition is of type object, it has the following structure:\\n\\n| Parameter | Description | Type | Required |\\n| --- | --- | --- | --- |\\n| stateName | Name of the starting workflow state | string | no |\\n| schedule | Define the recurring time intervals or cron expressions at which workflow instances should be automatically started. | string or object | yes |\\n\\n```json\\n{\\n  \"stateName\": \"MyStartingstate\",\\n  \"schedule\": \"2020-03-20T09:00:00Z/PT2H\"\\n}\\n```\\n\\n```yaml\\nstateName: MyStartingstate\\nschedule: 2020-03-20T09:00:00Z/PT2H\\n```\\n\\nStart definition explicitly defines how/when workflow instances should be created and what the workflow starting state is.\\n\\nThe start definition can be either string or object type.\\n\\nIf string type, it defines the name of the workflow starting state.\\n\\nIf object type, it provides the ability to set the workflow starting state name, as well as the schedule property.\\n\\nThe stateName property can be set to define the starting workflow state. If not specified, the first state\\nin the workflow states definition should be used as the starting workflow state.\\n\\nThe schedule property allows to define scheduled workflow instance creation.\\nScheduled starts have two different choices. You can define a recurring time interval or cron-based schedule at which a workflow\\ninstance should be created (automatically).\\n\\nYou can also define cron-based scheduled starts, which allows you to specify periodically started workflow instances based on a cron definition.\\nCron-based scheduled starts can handle absolute time intervals (i.e., not calculated in respect to some particular point in time).\\nOne use case for cron-based scheduled starts is a workflow that performs periodical data batch processing.\\nIn this case we could use a cron definition\\n\\ntext\\n0 0/5 * * * ?\\n\\nto define that a workflow instance from the workflow definition should be created every 5 minutes, starting at full hour.\\n\\nHere are some more examples of cron expressions and their meanings:\\n\\ntext\\n* * * * *   - Create workflow instance at the top of every minute\\n0 * * * *   - Create workflow instance at the top of every hour\\n0 */2 * * * - Create workflow instance every 2 hours\\n0 9 8 * *   - Create workflow instance at 9:00:00AM on the eighth day of every month\\n\\nSee here to get more information on defining cron expressions.\\n\\nOne thing to discuss when dealing with cron-based scheduled starts is when the workflow starting state is an Event.\\nEvent states define that workflow instances are triggered by the existence of the defined event(s).\\nDefining a cron-based scheduled starts for the runtime implementations would mean that there needs to be an event service that issues\\nthe needed events at the defined times to trigger workflow instance creation.\\n\\nDefining a start definition is not required. If it\\'s not defined, the starting workflow\\nstate has to be the very first state defined in the workflow states array.\\n\\nSchedule Definition\\n\\nSchedule definition can have two types, either string or object.\\nIf string type, it defines time interval describing when the workflow instance should be automatically created.\\nThis can be used as a short-cut definition when you don\\'t need to define any other parameters, for example:\\n\\njson\\n{\\n  \"schedule\": \"R/PT2H\"\\n}\\n\\nIf you need to define the cron or the timezone parameters in your schedule definition, you can define\\nit with its object type which has the following properties:\\n\\n| Parameter | Description | Type | Required |\\n| --- | --- | --- | --- |\\n| interval | A recurring time interval expressed in the derivative of ISO 8601 format specified below. Declares that workflow instances should be automatically created at the start of each time interval in the series. | string | yes (if cron is not defined) |\\n| cron | Cron expression defining when workflow instances should be automatically created | object | yes (if interval is not defined) |\\n| timezone | Timezone name used to evaluate the interval & cron-expression. If the interval specifies a date-time w/ timezone then proper timezone conversion will be applied. (default: UTC). | string | no |\\n\\n```json\\n{\\n   \"cron\": \"0 0/15 * * * ?\"\\n}\\n```\\n\\n```yaml\\ncron: 0 0/15 * * * ?\\n```\\n\\nThe interval property uses a derivative of ISO 8601 recurring time interval format to describe a series of consecutive time intervals for workflow instances to be automatically created at the start of. Unlike full ISO 8601, this derivative format does not allow expression of an explicit number of recurrences or identification of a series by the date and time at the start and end of its first time interval.\\nThere are three ways to express a recurring interval:\\n\\nR/<Start>/<Duration>: Defines the start time and a duration, for example: \"R/2020-03-20T13:00:00Z/PT2H\", meaning workflow\\n   instances will be automatically created every 2 hours starting from March 20th 2020 at 1pm UTC.\\n\\nR/<Duration>/<End>: Defines a duration and an end, for example: \"R/PT2H/2020-05-11T15:30:00Z\", meaning that workflow instances will be\\n   automatically created every 2 hours until until May 11th 2020 at 3:30pm UTC (i.e., the last instance will be created 2 hours prior to that, at 1:30pm UTC).\\n\\nR/<Duration>: Defines a duration only, for example: \"R/PT2H\", meaning workflow instances will be automatically created every 2 hours. The start time of the first interval may be indeterminate, but should be delayed by no more than the specified duration and must repeat on schedule after that (this is effectively supplying the start time \"out-of-band\" as permitted ISO ISO 8601-1:2019 section 5.6.1 NOTE 1). Each runtime implementation should document how the start time for a duration-only interval is established.\\n\\nThe cron property uses a cron expression\\nto describe a repeating interval upon which a workflow instance should be created automatically.\\nFor more information see the cron definition section.\\n\\nhere for a list of timezone names.  For ISO 8601 date time\\nvalues in\\n\\nNote that when the workflow starting state is an Event\\ndefining cron-based scheduled starts for the runtime implementations would mean that there needs to be an event service that issues\\nthe needed events at the defined times to trigger workflow instance creation.\\n\\nCron Definition\\n\\nCron definition can have two types, either string or object.\\nIf string type, it defines the cron expression describing when the workflow instance should be created (automatically).\\nThis can be used as a short-cut definition when you don\\'t need to define any other parameters, for example:\\n\\njson\\n{\\n  \"cron\": \"0 15,30,45 * ? * *\"\\n}\\n\\nIf you need to define the validUntil parameters in your cron definition, you can define\\nit with its object type which has the following properties:\\n\\n| Parameter | Description | Type | Required |\\n| --- | --- | --- | --- |\\n| expression | Cron expression describing when the workflow instance should be created (automatically) | string | yes |\\n| validUntil | Specific date and time (ISO 8601 format) when the cron expression is no longer valid | string | no |\\n\\n```json\\n{\\n    \"expression\": \"0 15,30,45 * ? * *\",\\n    \"validUntil\": \"2021-11-05T08:15:30-05:00\"\\n}\\n```\\n\\n```yaml\\nexpression: 0 15,30,45 * ? * *\\nvalidUntil: \\'2021-11-05T08:15:30-05:00\\'\\n```\\n\\nThe expression property is a a cron expression which defines\\nwhen workflow instances should be created (automatically).\\n\\nThe validUntil property defines a date and time (using ISO 8601 format). When the\\nvalidUntil time is reached, the cron expression for instances creations of this workflow\\nshould no longer be valid.\\n\\nFor example let\\'s say we have to following cron definitions:\\n\\njson\\n{\\n    \"expression\": \"0 15,30,45 * ? * *\",\\n    \"validUntil\": \"2021-11-05T08:15:30-05:00\"\\n}\\n\\nThis tells the runtime engine to create an instance of this workflow every hour\\nat minutes 15, 30 and 45. This is to be done until November 5, 2021, 8:15:30 am, US Eastern Standard Time\\nas defined by the validUntil property value.\\n\\nEnd Definition\\n\\nCan be either boolean or object type. If type boolean, must be set to true, for example:\\n\\njson\\n\"end\": true\\n\\nIn this case it\\'s assumed that the terminate property has its default value of false, and the produceEvents,\\ncompensate, and  continueAs properties are not defined.\\n\\nIf the end definition is of type object, it has the following structure:\\n\\nproducedEvent definitions. Defines events that should be produced. | array | no |\\n|\\n\\ncompensate | If set to\\n\\ncontinueAs | Defines that current workflow execution should stop, and execution should continue as a new workflow instance of the provided id | string or object | no |\\n\\n```json\\n{\\n    \"terminate\": true,\\n    \"produceEvents\": [{\\n        \"eventRef\": \"provisioningCompleteEvent\",\\n        \"data\": \"${ .provisionedOrders }\"\\n    }]\\n}\\n```\\n\\n```yaml\\nterminate: true\\nproduceEvents:\\n- eventRef: provisioningCompleteEvent\\n  data: \"${ .provisionedOrders }\"\\n\\n```\\n\\nEnd definitions are used to explicitly define execution completion of a workflow instance or workflow execution path.\\nA workflow definition must include at least one workflow state.\\nNote that Switch states cannot declare to be workflow end states. Their conditions however can \\ndefine a stop of workflow execution.\\n\\nThe terminate property, if set to true, completes the workflow instance execution, this any other active\\nexecution paths.\\nIf a terminate end is reached inside a ForEach or Parallel state the entire workflow instance is terminated.\\n\\nThe produceEvents allows defining events which should be produced\\nby the workflow instance before workflow stops its execution.\\n\\nworkflowExecTimeout property is defined, the time defined in its\\n\\nThe compensate property defines that workflow compensation should be performed before the workflow \\nexecution is completed.\\n\\ncontinueAs property defines that the current workflow instance should stop its execution,\\nand worklow execution should continue as a new instance of a new workflow.\\nWhen defined, it should be assumed that\\n\\nProducedEvent Definition\\n\\n| Parameter | Description | Type | Required |\\n| --- | --- | --- | --- |\\n| eventRef | Reference to a defined unique event name in the events definition | string | yes |\\n| data | If string type, an expression which selects parts of the states data output to become the data (payload) of the produced event. If object type, a custom object to become the data (payload) of produced event. | string or object | no |\\n| contextAttributes | Add additional event extension context attributes | object | no |\\n\\n```json\\n{\\n    \"eventRef\": \"provisioningCompleteEvent\",\\n    \"data\": \"${ .provisionedOrders }\",\\n    \"contextAttributes\": [{\\n         \"buyerId\": \"${ .buyerId }\"\\n     }]\\n }\\n```\\n\\n```yaml\\neventRef: provisioningCompleteEvent\\ndata: \"${ .provisionedOrders }\"\\ncontextAttributes:\\n- buyerId: \"${ .buyerId }\"\\n```\\n\\nDefines the event (CloudEvent format) to be produced when workflow execution completes or during a workflow transitions.\\nThe eventRef property must match the name of\\none of the defined produced events in the events definition.\\n\\nThe data property can have two types, object or string. If of string type, it is an expression that can select parts of state data\\nto be used as the event payload. If of object type, you can define a custom object to be the event payload.\\n\\nThe contextAttributes property allows you to add one or more extension context attributes\\nto the generated event.\\n\\nBeing able to produce events when workflow execution completes or during state transition\\nallows for event-based orchestration communication.\\nFor example, completion of an orchestration workflow can notify other orchestration workflows to decide if they need to act upon\\nthe produced event, or notify monitoring services of the current state of workflow execution, etc.\\nIt can be used to create very dynamic orchestration scenarios.\\n\\nTransitions\\n\\nServerless workflow states can have one or more incoming and outgoing transitions (from/to other states).\\nEach state can define a transition definition that is used to determine which\\nstate to transition to next.\\n\\nImplementers must use the unique State name property for determining the transition.\\n\\nEvents can be produced during state transitions. The produceEvents property of the transition definitions allows you\\nto reference one or more defined produced events in the workflow events definitions.\\nFor each of the produced events you can select what parts of state data to be the event payload.\\n\\nTransitions can trigger compensation via their compensate property. See the Workflow Compensation\\nsection for more information.\\n\\nAdditional Properties\\n\\nSpecifying additional properties, namely properties which are not defined by the specification\\nare only allowed in the Workflow Definition.\\nAdditional properties serve the same purpose as Workflow Metadata.\\nThey allow you to enrich the workflow definition with custom information.\\n\\nAdditional properties, just like workflow metadata, should not affect workflow execution.\\nImplementations may choose to use additional properties or ignore them.\\n\\nIt is recommended to use workflow metadata instead of additional properties in the workflow definition.\\n\\nLet\\'s take a look at an example of additional properties:\\n\\njson\\n{\\n  \"id\": \"myworkflow\",\\n  \"version\": \"1.0.0\",\\n  \"specVersion\": \"0.8\",\\n  \"name\": \"My Test Workflow\",\\n  \"start\": \"My First State\",\\n  \"loglevel\": \"Info\",\\n  \"environment\": \"Production\",\\n  \"category\": \"Sales\",\\n  \"states\": [ ... ]\\n}\\n\\nIn this example, we specify the loglevel, environment, and category additional properties.\\n\\nNote the same can be also specified using workflow metadata, which is the preferred approach:\\n\\njson\\n{\\n  \"id\": \"myworkflow\",\\n  \"version\": \"1.0.0\",\\n  \"specVersion\": \"0.8\",\\n  \"name\": \"Py Test Workflow\",\\n  \"start\": \"My First State\",\\n  \"metadata\": {\\n    \"loglevel\": \"Info\",\\n    \"environment\": \"Production\",\\n    \"category\": \"Sales\"\\n  },\\n  \"states\": [ ... ]\\n}\\n\\nWorkflow Error Handling\\n\\nServerless Workflow language allows you to define explicit error handling, meaning you can define what should happen\\nin case of errors inside your workflow model rather than some generic error handling entity.\\nThis allows error handling to become part of your orchestration activities and as such part of your business problem\\nsolutions.\\n\\nThe idea behind the way Serverless Workflow defines error handling is that workflows should only fail due to unknown bugs \\nduring execution. In general, you should always write your workflows so that they do not fail on any known failures.\\n\\nEach workflow state can define error handling, which is related only to errors that may arise during its\\nexecution. Error handling defined in one state cannot be used to handle errors that happened during execution of another state\\nduring workflow execution.\\n\\nUnknown errors that may arise during workflow state execution that are not explicitly handled within the workflow definition\\nshould be reported by runtime implementations and halt workflow execution.\\n\\nWithin workflow definitions, errors defined are domain specific, meaning they are defined within\\nthe actual business domain, rather than their technical (programming-language-specific) description.\\n\\nFor example, we can define errors such as \"Order not found\", or \"Item not in inventory\", rather than having to\\nuse terms such as \"java.lang.IllegalAccessError\", or \"response.status == 404\", which\\nmight make little to no sense to our specific problem domain, as well as may not be portable across various runtime implementations.\\n\\nIn addition to the domain specific error name, users have the option to also add an optional error code\\nto help runtime implementations with mapping defined errors to concrete underlying technical ones.\\n\\nRuntime implementations must be able to map the error domain specific name (and the optional error code)\\nto concrete technical errors that arise during workflow execution.\\n\\nDefining Errors\\n\\nKnown workflow errors, that we know we need to handle during workflow execution should be defined in\\nthe workflow top-level \\'errors\\' property. This property can be either a string type, meaning it can reference \\na reusable JSON or Yaml definition file including the error definitions, or it can have an array type where you can\\ndefine these checked errors in-line in your workflow definition.\\n\\nHere is an example of such a definition for both cases:\\n\\nReferencing a reusable JSON/Yaml error definition file:\\n\\n```json\\n{\\n\"errors\": \"file://documents/reusable/errors.json\"\\n}\\n```\\n\\n```yaml\\nerrors: file://documents/reusable/errors.json\\n```\\n\\nDefining workflow errors in-line:\\n\\n```json\\n{\\n\"errors\": [\\n  {\\n    \"name\": \"Service not found error\",\\n    \"code\": \"404\",\\n    \"description\": \"Server has not found anything matching the provided service endpoint information\"\\n  }\\n]\\n}\\n```\\n\\n```yaml\\nerrors:\\n  - name: Service not found error\\n    code: \\'404\\'\\n    description: Server has not found anything matching the provided service endpoint\\n      information\\n```\\n\\nThese defined errors can then be referenced by their unique name in both states onErrors definitions as well as in \\nactions nonRetryableErrors and retryableErrors properties.\\n\\nAction retries\\n\\nRetries allow workflows to deal with intermittent failures of services they are trying to invoke.\\nIn addition, retries allow workflows to continue (not fail) execution and allow us to fix possible errors with invoked \\nservices and continue execution after they are fixed. \\nRetries are important for both short-lived and long-lived workflows, as well as in both stateless and stateful \\nscenarios.\\n\\nServerless workflow supports two distinct ways of defining retries:\\n1. Retrying on specified known (checked) errors.\\n2. Automatic retrying on both known (checked) and not-known (unchecked) errors.\\n\\nWhich retry option the workflow should use by default is defined via the workflow top-level autoRetries property.\\nBy default, the value of the autoRetries is set to false, meaning that retry option 1) is used by default.\\nYou can enable automatic retrying (option 2) by setting autoRetries to true.\\n\\nRegardless of the chosen retries option, note that workflows in general should be designed to not fail. \\nWorkflows should be able to recover from intermittent failures.\\n\\nThe next sections provide more details to each action retry option.\\n\\nRetry actions on known errors\\n\\nThis is the default option when the workflow top-level autoRetries property is not specified or is set to false.\\nThis retry options is suited for stateless / short-running workflows where retries should  be performed when specifically\\nwanted. Note that in this scenario when unknown (unchecked) errors happen during action execution (service invocation), \\nworkflow execution should fail.\\n\\nLet\\'s take a look at an example. To start, let\\'s define a workflow top-level retries definition:\\n\\n```json\\n{\\n\"retries\": [\\n  {\\n    \"name\": \"FirstRetryStrategy\",\\n    \"delay\": \"PT1M\",\\n    \"maxAttempts\": 5\\n  },\\n  {\\n    \"name\": \"SecondRetryStrategy\",\\n    \"delay\": \"PT10M\",\\n    \"maxAttempts\": 10\\n  }\\n]\\n}\\n```\\n\\n```yaml\\nretries:\\n  - name: FirstRetryStrategy\\n    delay: PT1M\\n    maxAttempts: 5\\n  - name: SecondRetryStrategy\\n    delay: PT10M\\n    maxAttempts: 10\\n\\n```\\n\\nOur retries definitions can be referenced by actions. For example:\\n\\n```json\\n{\\n  \"actions\": [\\n    {\\n      \"functionRef\": \"MyFirstFunction\",\\n      \"retryRef\": \"FirstRetryStrategy\",\\n      \"retryableErrors\": [\"SomeErrorOne\", \"SomeErrorTwo\"]\\n    },\\n    {\\n      \"functionRef\": \"MySecondFunction\",\\n      \"retryRef\": \"SecondRetryStrategy\",\\n      \"retryableErrors\": [\"SomeErrorTwo\", \"SomeErrorThree\"]\\n    },\\n    {\\n      \"functionRef\": \"MyThirdFunction\"\\n    }\\n  ]\\n}\\n```\\n\\n```yaml\\nactions:\\n  - functionRef: MyFirstFunction\\n    retryRef: FirstRetryStrategy\\n    nonRetryableErrors:\\n      - SomeErrorOne\\n      - SomeErrorTwo\\n  - functionRef: MySecondFunction\\n    retryRef: SecondRetryStrategy\\n    nonRetryableErrors:\\n      - SomeErrorTwo\\n      - SomeErrorThree\\n  - functionRef: MyThirdFunction\\n```\\n\\nEach action can define the retry strategy it wants to use. If it does not define one, the action is in this case not retries.\\nActions can define a list of known errors in its retryableErrors array. If defined, then the action should be retried\\nfor those errors according to the referenced retry strategy.\\n\\nIn our example, \"MyFirstFunction\" invocation should be retried according to the \"FirstRetryStrategy\" policy only on known errors\\n\"SomeErrorOne\" and \"SomeErrorTwo\".\\n\\nIf for a known error (defined in retryableErrors) the retry limit is reached and the error still persist, it can be handled in the states\\nonErrors definition.\\n\\nIf an unknown (unchecked) error happens during action execution, and this error is also not handled in the states onErrors definition, the\\nworkflow execution should fail.\\n\\nAutomatic retries on known and unknown errors\\n\\nThis is the option used when the workflow top-level autoRetries property is set to true.\\nAutomatic retries are well suited to long-running and stateful workflow orchestrations. It allows workflows\\nto recover from failures thus providing more resilience. There is a possible cost associated with automatic retries\\nin terms of resource and computing power utilization.\\n\\nWith this retries option, action executions should be retried automatically for both known (checked) as well as unknown (unchecked)\\nerrors. This means that you do not have to define a retry strategy for actions for them to have retried, it\\'s included by default.\\nUsers can still define a custom retry strategy for each action via the retryRef property.\\n\\nIf a retry strategy is not defined, a default retry strategy should be used.\\nRuntime implementations can define their own default retry strategy. Serverless Workflow recommends the following settings:\\n\\nmaxAttempts to be unlimited, meaning that the action should be retried indefinitely until successful.\\n\\ndelay to be set to one second, meaning that there is a one second delay between action retries.\\n\\nmultiplier to be set to two meaning that the delay should be multiplied by two for each retry attempt.\\n\\nRuntimes should document their default retry strategy to users, so it\\'s clear which\\nproperty values they are using for the default.\\n\\nActions can define for which known (checked) errors they should not be retried for. \\nThis is done via the actions nonRetryableErrors property. If a known error happens during action execution \\nwhich is included in the nonRetryableErrors property array, that action should not be retried and the error \\nthen should be handled in the workflow states onErrors property.\\n\\nLet\\'s take a look at an examples of defining retries when using the automatic retries option. \\nThis example assumes that the workfow top level autoRetries property is set to true.\\nTo start, let\\'s define a workflow top-level retries definition:\\n\\n```json\\n{\\n\"retries\": [\\n  {\\n    \"name\": \"FirstRetryStrategy\",\\n    \"delay\": \"PT1M\",\\n    \"maxAttempts\": 5\\n  },\\n  {\\n    \"name\": \"SecondRetryStrategy\",\\n    \"delay\": \"PT10M\",\\n    \"maxAttempts\": 10\\n  },\\n  {\\n    \"name\": \"DoNotRetryStrategy\",\\n    \"maxAttempts\": 1\\n  }\\n]\\n}\\n```\\n\\n```yaml\\nretries:\\n  - name: FirstRetryStrategy\\n    delay: PT1M\\n    maxAttempts: 5\\n  - name: SecondRetryStrategy\\n    delay: PT10M\\n    maxAttempts: 10\\n  - name: DoNotRetryStrategy\\n    maxAttempts: 1\\n\\n```\\n\\nOur retry definitions can be referenced by state actions. For example:\\n\\n```json\\n{\\n  \"actions\": [\\n    {\\n      \"functionRef\": \"MyFirstFunction\",\\n      \"retryRef\": \"FirstRetryStrategy\",\\n      \"nonRetryableErrors\": [\"SomeErrorOne\", \"SomeErrorTwo\"]\\n    },\\n    {\\n      \"functionRef\": \"MySecondFunction\",\\n      \"retryRef\": \"SecondRetryStrategy\",\\n      \"nonRetryableErrors\": [\"SomeErrorTwo\", \"SomeErrorThree\"]\\n    },\\n    {\\n      \"functionRef\": \"MyThirdFunction\"\\n    },\\n    {\\n      \"functionRef\": \"MyFourthFunction\",\\n      \"retryRef\": \"DoNotRetryStrategy\"\\n    }\\n  ]\\n}\\n```\\n\\n```yaml\\nactions:\\n  - functionRef: MyFirstFunction\\n    retryRef: FirstRetryStrategy\\n    nonRetryableErrors:\\n      - SomeErrorOne\\n      - SomeErrorTwo\\n  - functionRef: MySecondFunction\\n    retryRef: SecondRetryStrategy\\n    nonRetryableErrors:\\n      - SomeErrorTwo\\n      - SomeErrorThree\\n  - functionRef: MyThirdFunction\\n  - functionRef: MyFourthFunction\\n    retryRef: DoNotRetryStrategy\\n\\n```\\n\\nIn our example the first action named MyFirstFunction is going to be retried according to the FirstRetryStrategy\\nretry policy\\nfor all errors except SomeErrorOne and SomeErrorTwo.\\n\\nThe seconds action named MySecondFunction is going to be retried according to the SecondRetryStrategy\\nretry policy \\nfor all errors except SomeErrorTwo and SomeErrorThree.\\n\\nThe third action named MyThirdFunction is going to retried according to the default runtime retry policy.\\nIt will be retried for all errors both known (checked) as well as unknown (unckecked).\\n\\nThe fourth action named MyFourthFunction is going to be retried according to the DoNotRetryStrategy\\nretry policy which has the maxAttempts property set to 1, meaning that this action will not be retried.\\n\\nWorkflow Timeouts\\n\\nWorkflow timeouts define the maximum times for:\\n\\nWorkflow execution\\n\\nState execution\\n\\nAction execution\\n\\nBranch execution\\n\\nEvent consumption time\\n\\nThe specification allows for timeouts to be defined on the top-level workflow definition, as well as\\nin each of the workflow state definitions. Note that the timeout settings defined in states, and state branches overwrite the top-level\\nworkflow definition for state, action and branch execution. If they are not defined, then the top-level\\ntimeout settings should take in effect.\\n\\nTo give an example, let\\'s say that in our workflow definition we define the timeout for state execution:\\n\\njson\\n{\\n   \"id\": \"testWorkflow\",\\n   ...\\n   \"timeouts\": {\\n     ...\\n     \"stateExecTimeout\": \"PT2S\"\\n   }\\n   ...\\n}\\n\\nThis top-level workflow timeout setting defines that the maximum execution time of all defined workflow states\\nis two seconds each.\\n\\nNow let\\'s say that we have worfklow states \"A\" and \"B\". State \"A\" does not define a timeout definition, but state\\n\"B\" does:\\n\\njson\\n{\\n   \"name\": \"B\",\\n   \"type\": \"operation\",\\n   ...\\n   \"timeouts\": {\\n     ...\\n     \"stateExecTimeout\": \"PT10S\"\\n   }\\n   ...\\n}\\n\\nSince state \"A\" does not overwrite the top-level stateExecTimeout, its execution timeout should be inherited from\\nthe top-level timeout definition.\\nOn the other hand, state \"B\" does define it\\'s own stateExecTimeout, in which case it would overwrite the default\\nsetting, meaning that it would its execution time has a max limit of ten seconds.\\n\\nDefining timeouts is not mandatory, meaning that if not defined, all the timeout settings should be assumed to\\nbe \"unlimited\".\\n\\nNote that the defined workflow execution timeout has precedence over all other defined timeouts.\\nJust to give an extreme example, let\\'s say we define the workflow execution timeout to ten seconds,\\nand the state execution timeout to twenty seconds. In this case if the workflow execution timeout is reached\\nit should follow the rules of workflow execution timeout and end workflow execution, no matter what the\\nstate execution time has been set to.\\n\\nLet\\'s take a look all possible timeout definitions:\\n\\nWorkflow Timeout Definition\\n\\nWorkflow timeouts are defined with the top-level timeouts property. It can have two types, string and object.\\nIf string type it defines an URI that points to a Json or Yaml file containing the workflow timeout definitions.\\nIf object type, it is used to define the timeout definitions in-line and has the following properties:\\n\\n| Parameter | Description | Type | Required |\\n| --- | --- | --- | --- |\\n| workflowExecTimeout | Workflow execution timeout (ISO 8601 duration format) | string or object | no |\\n| stateExecTimeout | Workflow state execution timeout (ISO 8601 duration format) | string | no |\\n| actionExecTimeout | Actions execution timeout (ISO 8601 duration format) | string | no |\\n| branchExecTimeout | Branch execution timeout (ISO 8601 duration format) | string | no |\\n| eventTimeout | Default timeout for consuming defined events (ISO 8601 duration format) | string | no |\\n\\nThe eventTimeout property defines the maximum amount of time to wait to consume defined events. If not specified it should default to\\n\"unlimited\".\\n\\nThe branchExecTimeout property defines the maximum execution time for a single branch. If not specified it should default to\\n\"unlimited\".\\n\\nThe actionExecTimeout property defines the maximum execution time for a single actions definition. If not specified it should default to\\n\"unlimited\". Note that an action definition can include multiple actions.\\n\\nThe stateExecTimeout property defines the maximum execution time for a single workflow state. If not specified it should default to\\n\"unlimited\".\\n\\nThe workflowExecTimeout property defines the workflow execution timeout.\\nIt is defined using the ISO 8601 duration format. If not defined, the workflow execution should be given \"unlimited\"\\namount of time to complete.\\nworkflowExecTimeout can have two possibly types, either string or object.\\nIf string type, it defines the maximum workflow execution time.\\nIf Object type it has the following format:\\n\\nWorkflowExecTimeout Definition\\n\\n| Parameter | Description | Type | Required |\\n| --- | --- | --- | --- |\\n| duration | Timeout duration (ISO 8601 duration format) | string | yes |\\n| interrupt | If false, workflow instance is allowed to finish current execution. If true, current workflow execution is stopped immediately. Default is false  | boolean | no |\\n| runBefore | Name of a workflow state to be executed before workflow instance is terminated | string | no |\\n\\n```json\\n{\\n   \"duration\": \"PT2M\",\\n   \"runBefore\": \"createandsendreport\"\\n}\\n```\\n\\n```yaml\\nduration: PT2M\\nrunBefore: createandsendreport\\n```\\n\\nThe duration property defines the time duration of the execution timeout. Once a workflow instance is created,\\nand the amount of the defined time is reached, the workflow instance should be terminated.\\n\\nThe interrupt property defines if the currently running instance should be allowed to finish its current\\nexecution flow before it needs to be terminated. If set to true, the current instance execution should stop immediately.\\n\\nThe runBefore property defines a name of a workflow state to be executed before workflow instance is terminated.\\nStates referenced by runBefore (as well as any other states that they transition to) must obey following rules:\\n\\nThey should not have any incoming transitions (should not be part of the main workflow control-flow logic)\\n\\nThey cannot be states marked for compensation (have their usedForCompensation property set to true)\\n\\nIf it is a single state, it must define an end definition, if it transitions to other states,\\n  at last one must define it.\\n\\nThey can transition only to states are also not part of the main control flow logic (and are not marked\\n  for compensation).\\n\\nRuntime implementations should raise compile time / parsing exceptions if any of the rules mentioned above are\\nnot obeyed in the workflow definition.\\n\\nStates Timeout Definition\\n\\nAll workflow states can define the timeouts property and can define different timeout\\nsettings depending on their state type.\\nPlease reference each workflow state definitions for more information on which\\ntimeout settings are available for each state type.\\n\\nWorkflow states timeouts cannot define the workflowExecTimeout property.\\n\\nWorkflow states can set their stateExecTimeout property inside the timeouts definition. \\nThe value of this property is a time duration (ISO 8601 duration format). \\nIt must be a duration that\\'s greater than zero and defines the total state execution timeout. \\nWhen this timeout is reached, state execution\\nshould be stopped and can be handled as a timeout error in the states onErrors definition.\\n\\nBranch Timeout Definition\\n\\nParallel states can define the branchExecTimeout property. If defined on the state\\nlevel, it applies to each branch of the Parallel state. Note that each parallel state branch\\ncan overwrite this setting to define its own branch execution timeout.\\nIf a branch does not define this timeout property, it should be inherited from it\\'s state definition branch timeout setting.\\nIf its state does not define it either, it should be inherited from the top-level workflow branch timeout settings.\\n\\nEvent Timeout Definition\\n\\nThe Event state timeouts property can be used to\\nspecify state specific timeout settings. For event state it can contain the eventTimeout property\\nwhich is defined using the ISO 8601 data and time format.\\nYou can specify for example \"PT15M\" to represent 15 minutes or \"P2DT3H4M\" to represent 2 days, 3 hours and 4 minutes.\\neventTimeout values should always be represented as durations and not as specific time intervals.\\n\\nThe eventTimeout property needs to be described in detail  for Event states as it depends on whether or not the Event state is a workflow starting state or not.\\n\\nIf the Event state is a workflow starting state, incoming events may trigger workflow instances. In this case,\\nif the exclusive property is set to true, the eventTimeout property should be ignored.\\n\\nIf the exclusive property is set to false, in this case, the defined eventTimeout represents the time\\nbetween arrival of specified events. To give an example, consider the following:\\n\\njson\\n{\\n\"states\": [\\n{\\n    \"name\": \"ExampleEventState\",\\n    \"type\": \"event\",\\n    \"exclusive\": false,\\n    \"timeouts\": {\\n      \"eventTimeout\": \"PT2M\"\\n    }\\n    \"onEvents\": [\\n        {\\n            \"eventRefs\": [\\n                \"ExampleEvent1\",\\n                \"ExampleEvent2\"\\n            ],\\n            \"actions\": [\\n              ...\\n            ]\\n        }\\n    ],\\n    \"end\": {\\n        \"terminate\": true\\n    }\\n}\\n]\\n}\\n\\nThe first eventTimeout would start once any of the referenced events are consumed. If the second event does not occur within\\nthe defined eventTimeout, no workflow instance should be created.\\n\\nIf the event state is not a workflow starting state, the eventTimeout property is relative to the time when the\\nstate becomes active. If the defined event conditions (regardless of the value of the exclusive property)\\nare not satisfied within the defined timeout period, the event state should transition to the next state or end the workflow\\ninstance in case it is an end state without performing any actions.\\n\\nWorkflow Compensation\\n\\nCompensation deals with undoing or reversing the work of one or more states which have\\nalready successfully completed. For example, let\\'s say that we have charged a customer $100 for an item\\npurchase. In the case customer laster on decides to cancel this purchase we need to undo it. One way of\\ndoing that is to credit the customer $100.\\n\\nIt\\'s important to understand that compensation with workflows is not the same as for example rolling back\\na transaction (a strict undo). Compensating a workflow state which has successfully completed\\nmight involve multiple logical steps and thus is part of the overall business logic that must be\\ndefined within the workflow itself. To explain this let\\'s use our previous example and say that when our\\ncustomer made the item purchase, our workflow has sent her/him a confirmation email. In the case, to\\ncompensate this purchase, we cannot just \"undo\" the confirmation email sent. Instead, we want to\\nsend a second email to the customer which includes purchase cancellation information.\\n\\nCompensation in Serverless Workflow must be explicitly defined by the workflow control flow logic.\\nIt cannot be dynamically triggered by initial workflow data, event payloads, results of service invocations, or\\nerrors.\\n\\nDefining Compensation\\n\\nEach workflow state can define how it should be compensated via its compensatedBy property.\\nThis property references another workflow state (by its unique name) which is responsible for the actual compensation.\\n\\nStates referenced by compensatedBy (as well as any other states that they transition to) must obey following rules:\\n\\nThey should not have any incoming transitions (should not be part of the main workflow control-flow logic)\\n\\nThey cannot be an event state\\n\\nThey cannot define an end definition. If they do, it should be ignored\\n\\nThey must define the usedForCompensation property and set it to true\\n\\nThey can transition only to states which also have their usedForCompensation property set to true\\n\\nThey cannot themselves set their compensatedBy property to any state (compensation is not recursive)\\n\\nRuntime implementations should raise compile time / parsing exceptions if any of the rules mentioned above are\\nnot obeyed in the workflow definition.\\n\\nLet\\'s take a look at an example workflow state which defines its compensatedBy property, and the compensation\\nstate it references:\\n\\n```json\\n {\\n \"states\": [\\n      {\\n          \"name\": \"NewItemPurchase\",\\n          \"type\": \"event\",\\n          \"onEvents\": [\\n            {\\n              \"eventRefs\": [\\n                \"NewPurchase\"\\n              ],\\n              \"actions\": [\\n                {\\n                  \"functionRef\": {\\n                    \"refName\": \"DebitCustomerFunction\",\\n                    \"arguments\": {\\n                        \"customerid\": \"${ .purchase.customerid }\",\\n                        \"amount\": \"${ .purchase.amount }\"\\n                    }\\n                  }\\n                },\\n                {\\n                  \"functionRef\": {\\n                    \"refName\": \"SendPurchaseConfirmationEmailFunction\",\\n                    \"arguments\": {\\n                        \"customerid\": \"${ .purchase.customerid }\"\\n                    }\\n                  }\\n                }\\n              ]\\n            }\\n          ],\\n          \"compensatedBy\": \"CancelPurchase\",\\n          \"transition\": \"SomeNextWorkflowState\"\\n      },\\n      {\\n        \"name\": \"CancelPurchase\",\\n        \"type\": \"operation\",\\n        \"usedForCompensation\": true,\\n        \"actions\": [\\n            {\\n              \"functionRef\": {\\n                \"refName\": \"CreditCustomerFunction\",\\n                \"arguments\": {\\n                    \"customerid\": \"${ .purchase.customerid }\",\\n                    \"amount\": \"${ .purchase.amount }\"\\n                }\\n              }\\n            },\\n            {\\n              \"functionRef\": {\\n                \"refName\": \"SendPurchaseCancellationEmailFunction\",\\n                \"arguments\": {\\n                    \"customerid\": \"${ .purchase.customerid }\"\\n                }\\n              }\\n            }\\n          ]\\n    }\\n ]\\n }\\n```\\n\\n```yaml\\nstates:\\n- name: NewItemPurchase\\n  type: event\\n  onEvents:\\n  - eventRefs:\\n    - NewPurchase\\n    actions:\\n    - functionRef:\\n        refName: DebitCustomerFunction\\n        arguments:\\n          customerid: \"${ .purchase.customerid }\"\\n          amount: \"${ .purchase.amount }\"\\n    - functionRef:\\n        refName: SendPurchaseConfirmationEmailFunction\\n        arguments:\\n          customerid: \"${ .purchase.customerid }\"\\n  compensatedBy: CancelPurchase\\n  transition: SomeNextWorkflowState\\n- name: CancelPurchase\\n  type: operation\\n  usedForCompensation: true\\n  actions:\\n  - functionRef:\\n      refName: CreditCustomerFunction\\n      arguments:\\n        customerid: \"${ .purchase.customerid }\"\\n        amount: \"${ .purchase.amount }\"\\n  - functionRef:\\n      refName: SendPurchaseCancellationEmailFunction\\n      arguments:\\n        customerid: \"${ .purchase.customerid }\"\\n```\\n\\nIn this example our \"NewItemPurchase\" event state waits for a \"NewPurchase\" event and then\\ndebits the customer and sends them a purchase confirmation email. It defines that it\\'s compensated by the\\n\"CancelPurchase\" operation state which performs two actions, namely credits back the\\npurchase amount to customer and sends them a purchase cancellation email.\\n\\nTriggering Compensation\\n\\nAs previously mentioned, compensation must be explicitly triggered by the workflows control-flow logic.\\nThis can be done via transition and end definitions.\\n\\nLet\\'s take a look at each:\\n\\nCompensation triggered on transition:\\n\\n```json\\n{\\n  \"transition\": {\\n      \"compensate\": true,\\n      \"nextState\": \"NextWorkflowState\"\\n  }\\n}\\n```\\n\\n```yaml\\ntransition:\\n  compensate: true\\n  nextState: NextWorkflowState\\n```\\n\\nTransitions can trigger compensations by specifying the compensate property and setting it to true.\\nThis means that before the transition is executed (workflow continues its execution to the \"NextWorkflowState\" in this example),\\nworkflow compensation must be performed.\\n\\nCompensation triggered by end definition:\\n\\n```json\\n{\\n  \"end\": {\\n    \"compensate\": true\\n  }\\n}\\n```\\n\\n```yaml\\nend:\\n  compensate: true\\n```\\n\\nCompensation Execution Details\\n\\nNow that we have seen how to define and trigger compensation, we need to go into details on how compensation should be executed.\\nCompensation is performed on all already successfully completed states (that define compensatedBy) in reverse order.\\nCompensation is always done in sequential order, and should not be executed in parallel.\\n\\nLet\\'s take a look at the following workflow image:\\n\\nIn this example lets say our workflow execution is at the \"End\" state which defines the compensate property to true\\nas shown in the previous section. States with a red border, namely \"A\", \"B\", \"D\" and \"E\" are states which have so far\\nbeen executed successfully. State \"C\" has not been executed during workflow execution in our example.\\n\\nWhen workflow execution encounters our \"End\" state, compensation has to be performed. This is done in reverse order:\\n\\nState \"E\" is not compensated as it does not define a compensatedBy state\\n\\nState \"D\" is compensated by executing compensation \"D1\"\\n\\nState \"B\" is compensated by executing \"B1\" and then \"B1-2\"\\n\\nState C is not compensated as it was never active during workflow execution\\n\\nState A is not comped as it does not define a compensatedBy state\\n\\nSo if we look just at the workflow execution flow, the same workflow could be seen as:\\n\\nIn our example, when compensation triggers,\\nthe current workflow data is passed as input to the \"D1\" state, the first compensation state for our example.\\nThe states data output is then passed as states data input to \"B1\", and so on.\\n\\nCompensation and Active States\\n\\nIn some cases when compensation is triggered, some states such as Parallel and ForEach\\nstates can still be \"active\", meaning they still might have some async executions that are being performed.\\n\\nIf compensation needs to performed on such still active states, the state execution must be first cancelled.\\nAfter it is cancelled, compensation should be performed.\\n\\nUnrecoverable errors during compensation\\n\\nStates that are marked as usedForCompensation can define error handling via their\\nonErrors property just like any other workflow states. In case of unrecoverable errors during their execution\\n(errors not explicitly handled),\\nworkflow execution should be stopped, which is the same behavior as when not using compensation as well.\\n\\nContinuing as a new Execution\\n\\nIn some cases our workflows are deployed and executed on runtimes and/or cloud platforms that expose some \\nexecution limitations such as finite execution duration, finite number of workflow transitions, etc.\\nSome runtimes, especially when dealing with stateful workflow orchestrations have a finite limit of \\nexecution history log sizes, meaning that once a long-running workflow reaches these limits workflow executions is \\nlikely to be forced to stop before reaching its completion. This can result in unexpected issues, especially with\\nmission-critical workflows.\\n\\nFor those cases, the Serverless Workflow DSL provides a way to explicitly define stopping the current workflow\\ninstance execution, and starting a new one (for the same workflow id or a different one).\\nThis can be done via the end definitions continueAs property.\\n\\nThe end definitions continueAs can be either of type string or object.\\nIf string type, it contains the unique workflow id of the workflow that the execution should continue as, for example:\\n\\njson\\n{ \\n  \"end\": {\\n    \"continueAs\": \"myworkflowid\"\\n  }\\n}\\n\\nDefining this should stop the current workflow execution, and continue execution as a new workflow instance of the \\nworkflow which defines the workflow id of \"myworkflowid\". The state data where this is define should \\nbecome the workflow data input of the workflow that is continuing the current workflow execution.\\n\\nNote that any defined produceEvents and compensate definitions should be honored before continueAs is applied.\\n\\nIf object type, the continueAs property has the following properties:\\n\\n| Parameter | Description | Type | Required |\\n| --- | --- | --- | --- |\\n| workflowId | Unique id of the workflow to continue execution as. | string | yes |\\n| version | Version of the workflow to continue execution as. | string | no |\\n| data | If string type, a workflow expression which selects parts of the states data output to become the workflow data input of continued execution. If object type, a custom object to become the workflow data input of the continued execution. | string or object | no |\\n| workflowExecTimeout | Workflow execution timeout to be used by the workflow continuing execution. Overwrites any specific settings set by that workflow. | string or object | no |\\n\\nContinuing execution with continueAs can also be used inside sub-workflow executions, which brings its next use case.\\n\\nContinueAs in sub workflows\\n\\nWorkflows can invoke sub-workflows during their execution. In Serverless Workflow DSL, sub-workflows are invoked\\nsimilarly to other function types via the SubFlowRef Definition \\nin workflow states Action definitions.\\n\\nJust like \"parent\" workflows, sub-workflow can also be long-running, and can run into the same type of runtime/serverless platform\\nlimitations as previously discussed. As such they can also use continueAs to stop their current execution and continue it as \\na new one of the same or different workflow id.\\n\\nNote that when a sub-workflow is invoked it can produce a result that is then merged into the parent workflow state data.\\nThis may bring up a question as to what happens when a sub-workflow calls continueAs in terms of what is returned as\\nresult to of its invocation by the parent workflow.\\n\\nNo matter how many times sub-workflow may use continueAs, to the parent workflow it should be as a single invocation is performed,\\nmeaning that the results of the last sub-workflow invocation (triggered by continueAs) should be used as the \\ndata returned by the invocation of the sub-workflow to the parent workflow.\\n\\nWorkflow Versioning\\n\\nIn any application, regardless of size or type, one thing is for sure: changes happen.\\nVersioning your workflow definitions is an important task to consider. Versions indicate\\nchanges or updates of your workflow definitions to the associated execution runtimes.\\n\\nThere are two places in the workflow definition where versioning can be applied:\\n\\nTop level workflow definition version property.\\n\\nActions subflowRef version property.\\n\\nThe version property must respect the semantic versioning guidelines.\\n\\nWorkflow Constants\\n\\nWorkflow constants are used to define static, and immutable, data which is available to Workflow Expressions.\\n\\nConstants can be defined via the Workflow top-level \"constants\" property,\\nfor example:\\n\\njson\\n\"constants\": {\\n  \"Translations\": {\\n    \"Dog\": {\\n      \"Serbian\": \"pas\",\\n      \"Spanish\": \"perro\",\\n      \"French\": \"chien\"\\n    }\\n  }\\n}\\n\\nConstants can only be accessed inside Workflow expressions via the $CONST variable.\\nRuntimes must make $CONST available to expressions as a predefined variable.\\n\\nHere is an example of using constants in Workflow expressions:\\n\\njson\\n{\\n...,\\n\"constants\": {\\n  \"AGE\": {\\n    \"MIN_ADULT\": 18\\n  }\\n},\\n...\\n\"states\":[\\n  {\\n     \"name\":\"CheckApplicant\",\\n     \"type\":\"switch\",\\n     \"dataConditions\": [\\n        {\\n          \"name\": \"Applicant is adult\",\\n          \"condition\": \"${ .applicant | .age >= $CONST.AGE.MIN_ADULT }\",\\n          \"transition\": \"ApproveApplication\"\\n        },\\n        {\\n          \"name\": \"Applicant is minor\",\\n          \"condition\": \"${ .applicant | .age < $CONST.AGE.MIN_ADULT }\",\\n          \"transition\": \"RejectApplication\"\\n        }\\n     ],\\n     ...\\n  },\\n  ...\\n]\\n}\\n\\nNote that constants can also be used in expression functions,\\nfor example:\\n\\njson\\n{\\n\"functions\": [\\n  {\\n    \"name\": \"isAdult\",\\n    \"operation\": \".applicant | .age >= $CONST.AGE.MIN_ADULT\",\\n    \"type\": \"expression\"\\n  },\\n  {\\n    \"name\": \"isMinor\",\\n    \"operation\": \".applicant | .age < $CONST.AGE.MIN_ADULT\",\\n    \"type\": \"expression\"\\n  }\\n]\\n}\\n\\nWorkflow constants values should only contain static data, meaning that their value should not\\ncontain Workflow expressions.\\nWorkflow constants data must be immutable.\\nWorkflow constants should not have access to Workflow secrets definitions.\\n\\nWorkflow Secrets\\n\\nSecrets allow you access sensitive information, such as passwords, OAuth tokens, ssh keys, etc\\ninside your Workflow Expressions.\\n\\nYou can define the names of secrets via the Workflow top-level \"secrets\" property,\\nfor example:\\n\\njson\\n\"secrets\": [\"MY_PASSWORD\", \"MY_STORAGE_KEY\", \"MY_ACCOUNT\"]\\n\\nIf secrets are defined in a Workflow definition, runtimes must assure to provide their values\\nduring Workflow execution.\\n\\nSecrets can be used only in Workflow expressions by referencing them via the $SECRETS variable.\\nRuntimes must make $SECRETS available to expressions as a predefined variable.\\n\\nHere is an example on how to use secrets and pass them as arguments to a function invocation:\\n\\n```json\\n\"secrets\": [\"AZURE_STORAGE_ACCOUNT\", \"AZURE_STORAGE_KEY\"],\\n\\n...\\n\\n{\\n  \"refName\": \"uploadToAzure\",\\n    \"arguments\": {\\n      \"account\": \"${ $SECRETS.AZURE_STORAGE_ACCOUNT }\",\\n      \"account-key\": \"${ $SECRETS.AZURE_STORAGE_KEY }\",\\n      ...\\n    }\\n\\n}\\n```\\n\\nNote that secrets can also be used in expression functions.\\n\\nSecrets are immutable, meaning that workflow expressions are not allowed to change their values.\\n\\nWorkflow Metadata\\n\\nMetadata enables you to enrich the serverless workflow model with information beyond its core definitions.\\nIt is intended to be used by clients, such as tools and libraries, as well as users that find this information relevant.\\n\\nMetadata should not affect workflow execution. Implementations may choose to use metadata information or ignore it.\\nNote, however, that using metadata to control workflow execution can lead to vendor-locked implementations that do not comply with the main goals of this specification, which is to be completely vendor-neutral.\\n\\nMetadata includes key/value pairs (string types). Both keys and values are completely arbitrary and non-identifying.\\n\\nMetadata can be added to:\\n\\nWorkflow Definition\\n\\nFunction definitions\\n\\nEvent definitions\\n\\nState definitions\\n\\nSwitch state data and event conditions.\\n\\nHere is an example of metadata attached to the core workflow definition:\\n\\njson\\n{\\n  \"id\": \"processSalesOrders\",\\n  \"name\": \"Process Sales Orders\",\\n  \"version\": \"1.0.0\",\\n  \"specVersion\": \"0.8\",\\n  \"start\": \"MyStartingState\",\\n  \"metadata\": {\\n    \"loglevel\": \"Info\",\\n    \"environment\": \"Production\",\\n    \"category\": \"Sales\",\\n    \"giturl\": \"github.com/myproject\",\\n    \"author\": \"Author Name\",\\n    \"team\": \"Team Name\",\\n    ...\\n  },\\n  \"states\": [\\n    ...\\n  ]\\n}\\n\\nSome other examples of information that could be recorded in metadata are:\\n\\nUI tooling information such as sizing or scaling factors.\\n\\nBuild, release, or image information such as timestamps, release ids, git branches, PR numbers, etc.\\n\\nLogging, monitoring, analytics, or audit repository information.\\n\\nLabels used for organizing/indexing purposes, such as \"release\" \"stable\", \"track\", \"daily\", etc.\\n\\nWorkflow Context\\n\\nSimilar to Constants and Secrets, workflows expressions can have access to the context information of a running instance via the keyword WORKFLOW.\\n\\nImplementations may use this keyword to give access to any relevant information of the running instance within an expression. For example:\\n\\n```json\\n\\n{\\n  \"id\": \"processSalesOrders\",\\n  \"name\": \"Process Sales Orders\",\\n  \"version\": \"1.0.0\",\\n  \"specVersion\": \"0.8\",\\n  \"start\": \"MyStartingState\",\\n  \"functions\": [{\\n    \"name\": \"myFunction\",\\n    \"operation\": \"myopenapi.json#myFunction\"\\n  }],\\n  \"states\":[\\n  {\\n     \"name\":\"MyStartingState\",\\n     \"type\":\"operation\",\\n     \"actions\": [{\\n       \"functionRef\": \"myFunction\",\\n       \"args\": {\\n          \"order\": \"${ .orderId }\",\\n          \"callerId\": \"${ $WORKFLOW.instanceId  }\"\\n       }\\n     }],\\n     \"end\": true\\n  }] \\n}\\n```\\n\\nIn this use case, a third-party service may require information from the caller for traceability purposes.\\n\\nThe specification doesn\\'t define any specific variable within the WORKFLOW bucket, but it\\'s considered a reserved keyword.\\n\\nExtensions\\n\\nThe workflow extension mechanism allows you to enhance your model definitions with additional information useful for\\nthings like analytics, rate limiting, logging, simulation, debugging, tracing, etc.\\n\\nModel extensions do no influence control flow logic (workflow execution semantics).\\nThey enhance it with extra information that can be consumed by runtime systems or tooling and\\nevaluated with the end goal being overall workflow improvements in terms of time, cost, efficiency, etc.\\n\\nServerless Workflow specification provides extensions which can be found here.\\n\\nYou can define extensions in your workflow definition using its top-level extensions property.\\nFor more information about this property, see the extensions property in the \\nWorkflow Definition Structure section.\\n\\nEven tho users can define their own extensions, it is encouraged to use the ones provided by the specification.\\nWe also encourage users to contribute their extensions to the specification. That way they can be shared\\nwith the rest of the community.\\n\\nIf you have an idea for a new workflow extension, or would like to enhance an existing one,\\nplease open an New Extension Request issue in this repository.\\n\\nUse Cases\\n\\nYou can find different Serverless Workflow use cases here.\\n\\nExamples\\n\\nYou can find many Serverless Workflow examples here.\\n\\nComparison to other workflow languages\\n\\nYou can find info how the Serverless Workflow language compares with\\nother workflow languages here.\\n\\nReferences\\n\\nYou can find a list of other languages, technologies and specifications related to workflows here.\\n\\nLicense\\n\\nServerless Workflow specification operates under the\\nApache License version 2.0.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/markdown.html\n",
    "loader = UnstructuredMarkdownLoader(\"/data/serverless_workflow_specification.md\")\n",
    "markdown_text = loader.load()\n",
    "markdown_text[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a84ccb53",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serverless Workflow Specification\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "Abstract\n",
      "\n",
      "Status of this document\n",
      "\n",
      "Overview\n",
      "\n",
      "Why we need a specification?\n",
      "\n",
      "Focus on standards\n",
      "\n",
      "Project Components\n",
      "\n",
      "Specification Details\n",
      "Core Concepts\n",
      "\n",
      "Workflow Definition\n",
      "\n",
      "Workflow Instance\n",
      "\n",
      "Workflow Model\n",
      "Workflow Data\n",
      "Workflow Data Input\n",
      "Information Passing Between States\n",
      "Workflow data output\n",
      "State data filters\n",
      "Action data filters\n",
      "Event data filters\n",
      "Using multiple data filters\n",
      "Data Merging\n",
      "Workflow Functions\n",
      "Using Functions for RESTful Service Invocations\n",
      "Using Functions for Async API Service Invocations\n",
      "Using Functions for RPC Service Invocations\n",
      "Using Functions for GraphQL Service Invocations\n",
      "Invoking a GraphQL Query\n",
      "Invoking a GraphQL Mutation\n",
      "Using Functions for OData Service Invocations\n",
      "Creating an OData Function Definition\n",
      "Invoking an OData Function Definition\n",
      "Using Functions for Expression Evaluation\n",
      "Defining custom function types\n",
      "Workflow Expressions\n",
      "Workflow Definition Structure\n",
      "Workflow States\n",
      "Event State\n",
      "Operation State\n",
      "Switch State\n",
      "Sleep State\n",
      "Parallel State\n",
      "Inject State\n",
      "ForEach State\n",
      "Callback State\n",
      "Related State Definitions\n",
      "Function Definition\n",
      "Event Definition\n",
      "Auth Definition\n",
      "Basic Properties Definition\n",
      "Bearer Properties Definition\n",
      "OAuth2 Properties Definition\n",
      "Correlation Definition\n",
      "OnEvents Definition\n",
      "Action Definition\n",
      "Subflow Action\n",
      "FunctionRef Definition\n",
      "EventRef Definition\n",
      "SubFlowRef Definition\n",
      "Error Definition\n",
      "Retry Definition\n",
      "Transition Definition\n",
      "Switch State Data Conditions\n",
      "Switch State Event Conditions\n",
      "Parallel State Branch\n",
      "Parallel State Handling Exceptions\n",
      "Start Definition\n",
      "Schedule Definition\n",
      "Cron Definition\n",
      "End Definition\n",
      "ProducedEvent Definition\n",
      "Transitions\n",
      "Additional Properties\n",
      "Workflow Error Handling\n",
      "Defining Errors\n",
      "\n",
      "Action retries\n",
      "Retry actions on known errors\n",
      "Automatic retries on known and unknown errors\n",
      "Workflow Timeouts\n",
      "Workflow Timeout Definition\n",
      "WorkflowExecTimeout Definition\n",
      "States Timeout Definition\n",
      "Branch Timeout Definition\n",
      "Event Timeout Definition\n",
      "Workflow Compensation\n",
      "Defining Compensation\n",
      "Triggering Compensation\n",
      "Compensation Execution Details\n",
      "Compensation and Active States\n",
      "Unrecoverable errors during compensation\n",
      "Continuing as a new Execution\n",
      "ContinueAs in sub workflows\n",
      "\n",
      "Workflow Versioning\n",
      "\n",
      "Workflow Constants\n",
      "\n",
      "Workflow Secrets\n",
      "\n",
      "Workflow Metadata\n",
      "\n",
      "Workflow Context\n",
      "\n",
      "Extensions\n",
      "\n",
      "Use Cases\n",
      "\n",
      "Examples\n",
      "Comparison to other workflow languages\n",
      "\n",
      "References\n",
      "\n",
      "License\n",
      "\n",
      "Abstract\n",
      "The Serverless Workflow project defines a vendor-neutral and declarative workflow language,\n",
      "targeting the Serverless computing technology domain.\n",
      "\n",
      "Status of this document\n",
      "This document represents the current state of the specification.\n",
      "It includes all features so far released\n",
      "as well as all features planned to be added in the next release.\n",
      "You can find all specification releases here.\n",
      "You can find the specification roadmap here.\n",
      "\n",
      "Overview\n",
      "Workflows allow us to capture and organize business requirements in a unified manner.\n",
      "They can bridge the gap between how we express and model business logic.\n",
      "A key component of workflows is the domain-specific language (DSL) we use to model our\n",
      "business logic and solutions. Selecting the appropriate workflow language for our business and technology domains is\n",
      "a very important decision to be considered.\n",
      "Serverless Workflow focuses on defining a vendor-neutral, platform-independent, and declarative workflow\n",
      "language that targets the serverless computing technology domain.\n",
      "It can be used to significantly bridge the gap between your unique business domain and the target technology domain.\n",
      "Why we need a specification?\n",
      "The lack of a common way to define and model workflows means that we must constantly re-learn\n",
      "how to write them. This also limits the potential for common libraries, tooling and\n",
      "infrastructure to aid workflow modeling and execution across different platforms.\n",
      "Portability as well as productivity that can be achieved from workflow orchestration is hindered overall.\n",
      "Serverless Workflow addresses the need for a community-driven, vendor-neutral and a platform-independent\n",
      "workflow language specification that targets the serverless computing technology domain.\n",
      "Having and using a specification-based workflow language allows us to model our workflows once and deploy them\n",
      "onto many different container/cloud platforms, expecting the same execution results.\n",
      "For more information on the history, development and design rationale behind the specification, see the Serverless Workflow Wiki.\n",
      "\n",
      "Focus on standards\n",
      "Serverless Workflow language takes advantage of well-established and known standards such as CloudEvents, OpenAPI specifications,\n",
      "gRPC and GraphQL.\n",
      "\n",
      "Project Components\n",
      "The specification has multiple components:\n",
      "\n",
      "Definitions of the workflow language. This is defined via the Workflow JSON Schema. You can use both\n",
      "  JSON and YAML formats to model your workflows.\n",
      "Software Development Kits (SDKs) for Go, Java, .NET, Typescript and Python, and we plan to add them for more languages in the future.\n",
      "Set of Workflow Extensions which\n",
      "  allow users to define additional, non-execution-related workflow information. This information can be used to improve\n",
      "  workflow performance.\n",
      "Some example workflow extensions include Key Performance Indicators (KPIs), Rate Limiting, Simulation, Tracing, etc.\n",
      "Technology Compatibility Kit (TCK) to be used as a specification conformance tool for runtime implementations.\n",
      "\n",
      "Specification Details\n",
      "Following sections provide detailed descriptions of all parts of the Serverless Workflow language.\n",
      "\n",
      "Core Concepts\n",
      "\n",
      "This section describes some of the core Serverless Workflow concepts:\n",
      "Workflow Definition\n",
      "A workflow definition is a JSON or YAML file that conforms to the Serverless Workflow specification DSL. \n",
      "It consists of the core Workflow Definition Structure\n",
      "and the Workflow Model It defines a blueprint used by runtimes for its execution.\n",
      "A business solution can be composed of any number of related workflow definitions.\n",
      "Their relationships are explicitly modeled with the Serverless Workflow language (for example\n",
      "by using SubFlowRef Definition in actions).\n",
      "Runtimes can initialize workflow definitions for some particular set of data inputs or events.\n",
      "\n",
      "Workflow Instance\n",
      "A workflow instance represents a single workflow execution corresponding to the instructions provided by a\n",
      "workflow definition. A workflow instance can be short or long-running. A single workflow instance\n",
      "should be isolated, meaning it should not share state and data with other workflow instances.\n",
      "Workflow instances should be able to communicate with each other via events.\n",
      "Depending on their workflow definition, workflow instances can be short-lived or\n",
      "can execute for days, weeks, or years.\n",
      "Each workflow instances should have its unique identifier, which should remain\n",
      "unchanged throughout its execution.\n",
      "Workflow instances can be started providing some data input. This is described in detail in the \n",
      "workflow data input section.\n",
      "Workflow instances can also wait for examples to start their execution, which is the case\n",
      "where a workflow definition contains a EventState starting workflow state.\n",
      "The workflow definition also explicitly defines when a workflow instance should be completed. \n",
      "By default, instances should be completed once there are no active workflow paths (all active\n",
      "paths reach a state containing the default end definition),\n",
      "or if the defined workflowExecTimeout time is reached.\n",
      "Other ways, such as using the terminate property of the end definition to terminate instance execution,\n",
      "or defining an workflowExecTimeout property are also possible.\n",
      "For long-running workflow-executions, you can utilize the keepActive workflow property which \n",
      "provides more control as to when exactly to terminate workflow execution. In cases where a\n",
      "workflow execution should be continued as a new one, the DSL also provides the continueAs property which is described\n",
      "in detail in the Continuing a new Execution section.\n",
      "Workflow Model\n",
      "\n",
      "The Serverless Workflow language is composed of:\n",
      "\n",
      "Function definitions -  Reusable functions that can declare services that need to be invoked, or expressions to be evaluated.\n",
      "Event definitions - Reusable declarations of events that need to be consumed to start or continue workflow instances, trigger function/service execution, or be produced during workflow execution.\n",
      "Retry definitions - Reusable retry definitions. Can specify retry strategies for service invocations during workflow execution.\n",
      "Timeout definitions - Reusable timeout definitions. Can specify default workflow execution timeout, as well as workflow state, action, and branch execution timeouts.\n",
      "Errors definition - Reusable error definitions. Provide domain-specific error definitions which can be referenced in workflow states error handling.\n",
      "State definitions - Definition of states, the building blocks of workflow control flow logic. States can reference the reusable function, event and retry definitions.\n",
      "\n",
      "Workflow Data\n",
      "Serverless Workflow data is represented in JSON format.\n",
      "Data flow and execution logic go hand in hand, meaning as workflow execution follows the workflow definition\n",
      "logic, so does the workflow data:\n",
      "The initial Workflow data input is passed to the workflow starting state as its data input.\n",
      "When a state finishes its execution, its data output is passed as data input to the next state that should be executed.\n",
      "When workflow execution ends, the last executed workflow state's data output becomes the final Workflow data output.\n",
      "\n",
      "States can filter their data inputs and outputs using State Data filters.\n",
      "States can also consume events as well as invoke services. These event payloads and service invocation results\n",
      "can be filtered using Event data filters and Action data filters.\n",
      "Data filters use workflow expressions for selecting and manipulating state data\n",
      "input and output, action inputs and results, and event payloads.\n",
      "Multiple filters can be combined to gain high level of control of your workflow state data. You can find an example of that in\n",
      "this section.\n",
      "Data from consumed events,and action execution results are added/merged\n",
      "to state data. Reference the data merging section to learn about the merging rules that should be applied.\n",
      "\n",
      "Workflow Data Input\n",
      "The initial data input into a workflow instance. Must be a valid JSON object.\n",
      "If no input is provided, the default data input should be an empty JSON object:\n",
      "\n",
      "json\n",
      "{ }\n",
      "Workflow data input is passed to the workflow starting state as its data input.\n",
      "\n",
      "Information Passing Between States\n",
      "States in a workflow can receive data (data input) and produce a data result (data output). The state's data input is typically the previous state's data output.\n",
      "When a state completes its execution, its data output is passed to the state's data input it transitions to.\n",
      "There are two rules to consider here:\n",
      "If the state is the workflow starting state, its data input is the workflow data input.\n",
      "\n",
      "When workflow execution ends, the data output of the last executed state becomes the workflow data output.\n",
      "Workflow data output\n",
      "\n",
      "Each workflow execution should produce a data output.\n",
      "The workflow data output is the data output of the last executed workflow state.\n",
      "\n",
      "State data filters\n",
      "| Parameter | Description | Type | Required |\n",
      "| --- | --- | --- | --- |\n",
      "| input | Workflow expression to filter the states data input | string | no |\n",
      "| output | Workflow expression that filters the states data output | string | no |\n",
      "```json\n",
      "{\n",
      "    \"stateDataFilter\": {\n",
      "      \"input\": \"${ .orders }\",\n",
      "      \"output\": \"${ .provisionedOrders }\"\n",
      "    }\n",
      "}\n",
      "```yaml\n",
      "stateDataFilter:\n",
      "  input: \"${ .orders }\"\n",
      "  output: \"${ .provisionedOrders }\"\n",
      "State data filters can be used to filter the state's data input and output.\n",
      "The state data filters input property expression is applied when the workflow transitions to the current state and receives its data input.\n",
      "It can be used to select only data that is needed and disregard what is not needed.\n",
      "If input is not defined or does not select any parts of the state's data input, its data input is not filtered.\n",
      "The state data filter output property expression is applied right before the state transitions to the next state defined.\n",
      "It filters the state's data output to be passed as data input to the transitioning state.\n",
      "If the current state is the workflow end state, the filtered state's data output becomes the workflow data output.\n",
      "If output is not defined or does not select any parts of the state's data output, its data output is not filtered.\n",
      "Results of the input expression should become the state data input.\n",
      "Results of the output expression should become the state data output.\n",
      "For more information on this you can reference the data merging section.\n",
      "\n",
      "Let's take a look at some examples of state filters. For our examples let's say the data input to our state is as follows:\n",
      "json\n",
      "{\n",
      "  \"fruits\": [ \"apple\", \"orange\", \"pear\" ],\n",
      "  \"vegetables\": [\n",
      "    {\n",
      "      \"veggieName\": \"potato\",\n",
      "      \"veggieLike\": true\n",
      "    },\n",
      "    {\n",
      "      \"veggieName\": \"broccoli\",\n",
      "      \"veggieLike\": false\n",
      "}\n",
      "  ]\n",
      "}\n",
      "For the first example, our state only cares about fruits data, and we want to disregard the vegetables. To do this\n",
      "we can define a state filter:\n",
      "json\n",
      "{\n",
      "  \"stateDataFilter\": {\n",
      "    \"input\": \"${ {fruits: .fruits} }\"\n",
      "  }\n",
      "}\n",
      "\n",
      "The state data output then would include only the fruits data:\n",
      "\n",
      "json\n",
      "{\n",
      "  \"fruits\": [ \"apple\", \"orange\", \"pear\"]\n",
      "}\n",
      "For our second example, let's say that we are interested in the only vegetable \"veggie-like\".\n",
      "Here we have two ways of filtering our data, depending on if actions within our state need access to all vegetables, or\n",
      "only the ones that are \"veggie-like\".\n",
      "The first way would be to use both \"input\", and \"output\":\n",
      "json\n",
      "{\n",
      "  \"stateDataFilter\": {\n",
      "    \"input\": \"${ {vegetables: .vegetables} }\",\n",
      "    \"output\": \"${ {vegetables: [.vegetables[] | select(.veggieLike == true)]} }\"\n",
      "  }\n",
      "}\n",
      "The states data input filter selects all the vegetables from the main data input. Once all actions have performed, before the state transition\n",
      "or workflow execution completion (if this is an end state), the \"output\" of the state filter selects only the vegetables which are \"veggie like\".\n",
      "The second way would be to directly filter only the \"veggie like\" vegetables with just the data input path:\n",
      "json\n",
      "{\n",
      "  \"stateDataFilter\": {\n",
      "    \"input\": \"${ {vegetables: [.vegetables[] | select(.veggieLike == true)]} }\"\n",
      "  }\n",
      "}\n",
      "\n",
      "Action data filters\n",
      "| Parameter | Description | Type | Required |\n",
      "| --- | --- | --- | --- |\n",
      "| fromStateData | Workflow expression that filters state data that can be used by the action | string | no |\n",
      "| useResults | If set to false, action data results are not added/merged to state data. In this case 'results' and 'toStateData' should be ignored. Default is true.  | boolean | no |\n",
      "| results | Workflow expression that filters the actions data results | string | no |\n",
      "| toStateData | Workflow expression that selects a state data element to which the action results should be added/merged into. If not specified denotes the top-level state data element | string | no |\n",
      "```json\n",
      "{\n",
      "  \"actionDataFilter\": {\n",
      "    \"fromStateData\": \"${ .language }\",\n",
      "    \"results\": \"${ .results.greeting }\",\n",
      "    \"toStateData\": \"${ .finalgreeting }\"\n",
      "  }\n",
      "}\n",
      "```yaml\n",
      "actionDataFilter:\n",
      "  fromStateData: \"${ .language }\"\n",
      "  results: \"${ .results.greeting }\"\n",
      "  toStateData: \"${ .finalgreeting }\"\n",
      "Action data filters can be used inside Action definitions.\n",
      "Each action can define this filter which can:\n",
      "Filter the state data to select only the data that can be used within function definition arguments using its fromStateData property.\n",
      "Filter the action results to select only the result data that should be added/merged back into the state data\n",
      "  using its results property.\n",
      "Select the part of state data which the action data results should be added/merged to\n",
      "  using the toStateData property.\n",
      "To give an example, let's say we have an action which returns a list of breads and pasta types.\n",
      "For our workflow, we are only interested into breads and not the pasta.\n",
      "\n",
      "Action results:\n",
      "json\n",
      "{\n",
      "  \"breads\": [\"baguette\", \"brioche\", \"rye\"],\n",
      "  \"pasta\": [ \"penne\",  \"spaghetti\", \"ravioli\"]\n",
      "}\n",
      "\n",
      "We can use an action data filter to filter only the breads data:\n",
      "json\n",
      "{\n",
      "\"actions\":[\n",
      "    {\n",
      "       \"functionRef\": \"breadAndPastaTypesFunction\",\n",
      "       \"actionDataFilter\": {\n",
      "          \"results\": \"${ {breads: .breads} }\"\n",
      "       }\n",
      "    }\n",
      " ]\n",
      "}\n",
      "The results will filter the action results, which would then be:\n",
      "\n",
      "json\n",
      "{\n",
      "  \"breads\": [\n",
      "    \"baguette\",\n",
      "    \"brioche\",\n",
      "    \"rye\"\n",
      "  ]\n",
      "}\n",
      "Now let's take a look at a similar example (same expected action results) and assume our current state data is:\n",
      "\n",
      "json\n",
      "{\n",
      "  \"itemsToBuyAtStore\": [\n",
      "  ]\n",
      "}\n",
      "\n",
      "and have the following action definition:\n",
      "json\n",
      "{\n",
      "\"actions\":[\n",
      "    {\n",
      "       \"functionRef\": \"breadAndPastaTypesFunction\",\n",
      "       \"actionDataFilter\": {\n",
      "          \"results\": \"${ [ .breads[0], .pasta[1] ] }\",\n",
      "\"toStateData\": \"${ .itemsToBuyAtStore }\"\n",
      "       }\n",
      "    }\n",
      " ]\n",
      "}\n",
      "In this case, our results select the first bread and the second element of the pasta array.\n",
      "The toStateData expression then selects the itemsToBuyAtStore array of the state data to add/merge these results\n",
      "into. With this, after our action executes the state data would be:\n",
      "json\n",
      "{\n",
      "  \"itemsToBuyAtStore\": [\n",
      "    \"baguette\",\n",
      "    \"spaghetti\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "Event data filters\n",
      "| Parameter | Description | Type | Required |\n",
      "| --- | --- | --- | --- |\n",
      "| useData | If set to false, event payload is not added/merged to state data. In this case 'data' and 'toStateData' should be ignored. Default is true. | boolean | no |\n",
      "| data | Workflow expression that filters the event data (payload) | string | no |\n",
      "| toStateData | Workflow expression that selects a state data element to which the action results should be added/merged into. If not specified denotes the top-level state data element | string | no |\n",
      "```json\n",
      "{\n",
      "    \"eventDataFilter\": {\n",
      "       \"data\": \"${ .data.results }\"\n",
      "    }\n",
      "}\n",
      "```yaml\n",
      "eventDataFilter:\n",
      "  data: \"${ .data.results }\"\n",
      "Event data filters can be used to filter consumed event payloads.\n",
      "They can be used to:\n",
      "Filter the event payload to select only the data that should be added/merged into the state data\n",
      "  using its data property.\n",
      "Select the part of state data into which the event payload should be added/merged into\n",
      "  using the toStateData property.\n",
      "Allows event data to be filtered and added to or merged with the state data. All events have to be in the CloudEvents format\n",
      "and event data filters can filter both context attributes and the event payload (data) using the data property.\n",
      "Here is an example using an event filter:\n",
      "Note that the data input to the Event data filters depends on the dataOnly property of the associated Event definition.\n",
      "If this property is not defined (has default value of true), Event data filter expressions are evaluated against the event payload (the CloudEvents data attribute only). If it is set to\n",
      "false, the expressions should be evaluated against the entire CloudEvent (including its context attributes).\n",
      "Using multiple data filters\n",
      "As Event states can take advantage of all defined data filters. In the example below, we define\n",
      "a workflow with a single event state and show how data filters can be combined.\n",
      "json\n",
      "{\n",
      "    \"id\": \"GreetCustomersWorkflow\",\n",
      "    \"name\": \"Greet Customers when they arrive\",\n",
      "    \"version\": \"1.0.0\",\n",
      "    \"specVersion\": \"0.8\",\n",
      "    \"start\": \"WaitForCustomerToArrive\",\n",
      "    \"states\":[\n",
      "{\n",
      "            \"name\": \"WaitForCustomerToArrive\",\n",
      "            \"type\": \"event\",\n",
      "            \"onEvents\": [{\n",
      "                \"eventRefs\": [\"CustomerArrivesEvent\"],\n",
      "\"eventDataFilter\": {\n",
      "                    \"data\": \"${ .customer }\",\n",
      "                    \"toStateData\": \"${ .customerInfo }\"\n",
      "                },\n",
      "                \"actions\":[\n",
      "{\n",
      "                        \"functionRef\": {\n",
      "                            \"refName\": \"greetingFunction\",\n",
      "                            \"arguments\": {\n",
      "\"greeting\": \"${ .hello.spanish } \",\n",
      "                                \"customerName\": \"${ .customerInfo.name } \"\n",
      "                            }\n",
      "                        },\n",
      "\"actionDataFilter\": {\n",
      "                            \"fromStateData\": \"${ { hello, customerInfo } }\",\n",
      "                            \"results\": \"${ .greetingMessageResult }\",\n",
      "\"toStateData\": \"${ .finalCustomerGreeting }\"\n",
      "                        }\n",
      "                    }\n",
      "                ]\n",
      "            }],\n",
      "            \"stateDataFilter\": {\n",
      "\"input\": \"${ .greetings } \",\n",
      "                \"output\": \"${ { finalCustomerGreeting } }\"\n",
      "            },\n",
      "            \"end\": true\n",
      "        }\n",
      "    ],\n",
      "    \"events\": [{\n",
      "\"name\": \"CustomerArrivesEvent\",\n",
      "        \"type\": \"customer-arrival-type\",\n",
      "        \"source\": \"customer-arrival-event-source\"\n",
      "     }],\n",
      "    \"functions\": [{\n",
      "        \"name\": \"greetingFunction\",\n",
      "\"operation\": \"http://my.api.org/myapi.json#greeting\"\n",
      "    }]\n",
      "}\n",
      "The workflow data input when starting workflow execution is assumed to include greetings in different languages:\n",
      "json\n",
      "{\n",
      "  \"greetings\": {\n",
      "      \"hello\": {\n",
      "        \"english\": \"Hello\",\n",
      "        \"spanish\": \"Hola\",\n",
      "        \"german\": \"Hallo\",\n",
      "        \"russian\": \"Здравствуйте\"\n",
      "      },\n",
      "      \"goodbye\": {\n",
      "\"english\": \"Goodbye\",\n",
      "        \"spanish\": \"Adiós\",\n",
      "        \"german\": \"Auf Wiedersehen\",\n",
      "        \"russian\": \"Прощай\"\n",
      "      }\n",
      "  }\n",
      "}\n",
      "The workflow data input then becomes the data input of the starting workflow state.\n",
      "\n",
      "We also assume for this example that the CloudEvent that our event state consumes include the data (payload):\n",
      "json\n",
      "{\n",
      " \"customer\": {\n",
      "   \"name\": \"John Michaels\",\n",
      "   \"address\": \"111 Some Street, SomeCity, SomeCountry\",\n",
      "   \"age\": 40\n",
      " }\n",
      "}\n",
      "Here is a sample diagram showing our workflow, each numbered step on this diagram shows a certain defined point during\n",
      "workflow execution at which data filters are invoked and correspond to the numbered items below.\n",
      "(1) Workflow execution starts: Workflow data is passed to our \"WaitForCustomerToArrive\" event state as data input.\n",
      "Workflow executes its starting state, namely the \"WaitForCustomerToArrive\" event state.\n",
      "The event state stateDataFilter is invoked to filter its data input. The filters \"input\" expression is evaluated and\n",
      "selects only the \"greetings\" data. The rest of the state data input should be disregarded.\n",
      "At this point our state data should be:\n",
      "json\n",
      "{\n",
      "  \"hello\": {\n",
      "    \"english\": \"Hello\",\n",
      "    \"spanish\": \"Hola\",\n",
      "    \"german\": \"Hallo\",\n",
      "    \"russian\": \"Здравствуйте\"\n",
      "  },\n",
      "  \"goodbye\": {\n",
      "    \"english\": \"Goodbye\",\n",
      "    \"spanish\": \"Adiós\",\n",
      "\"german\": \"Auf Wiedersehen\",\n",
      "    \"russian\": \"Прощай\"\n",
      "  }\n",
      "}\n",
      "(2) CloudEvent of type \"customer-arrival-type\" is consumed: Once the event is consumed, the \"eventDataFilter\" is triggered.\n",
      "Its \"data\" expression selects the \"customer\" object from the events data. The \"toStateData\" expression\n",
      "says that we should add/merge this selected event data to the state data in its \"customerInfo\" property. If this property\n",
      "exists it should be merged, if it does not exist, one should be created.\n",
      "At this point our state data contains:\n",
      "json\n",
      "{\n",
      "    \"hello\": {\n",
      "      \"english\": \"Hello\",\n",
      "      \"spanish\": \"Hola\",\n",
      "      \"german\": \"Hallo\",\n",
      "      \"russian\": \"Здравствуйте\"\n",
      "    },\n",
      "    \"goodbye\": {\n",
      "      \"english\": \"Goodbye\",\n",
      "\"spanish\": \"Adiós\",\n",
      "      \"german\": \"Auf Wiedersehen\",\n",
      "      \"russian\": \"Прощай\"\n",
      "    },\n",
      "    \"customerInfo\": {\n",
      "       \"name\": \"John Michaels\",\n",
      "\"address\": \"111 Some Street, SomeCity, SomeCountry\",\n",
      "       \"age\": 40\n",
      "     }\n",
      "}\n",
      "(3) Event state performs its actions:\n",
      "Before the first action is executed, its actionDataFilter is invoked. Its \"fromStateData\" expression filters\n",
      "the current state data to select from its data that should be available to action arguments. In this example\n",
      "it selects the \"hello\" and \"customerInfo\" properties from the current state data.\n",
      "At this point the action is executed.\n",
      "We assume that for this example \"greetingFunction\" returns:\n",
      "json\n",
      "{\n",
      "   \"execInfo\": {\n",
      "     \"execTime\": \"10ms\",\n",
      "     \"failures\": false\n",
      "   },\n",
      "   \"greetingMessageResult\": \"Hola John Michaels!\"\n",
      "}\n",
      "After the action is executed, the actionDataFilter \"results\" expression is evaluated to filter the results returned from the action execution. In this case, we select only the \"greetingMessageResult\"\n",
      "element from the results.\n",
      "The action filters \"toStateData\" expression then defines that we want to add/merge this action result to\n",
      "state data under the \"finalCustomerGreeting\" element.\n",
      "\n",
      "At this point, our state data contains:\n",
      "json\n",
      "{\n",
      "  \"hello\": {\n",
      "      \"english\": \"Hello\",\n",
      "      \"spanish\": \"Hola\",\n",
      "      \"german\": \"Hallo\",\n",
      "      \"russian\": \"Здравствуйте\"\n",
      "    },\n",
      "    \"goodbye\": {\n",
      "      \"english\": \"Goodbye\",\n",
      "\"spanish\": \"Adiós\",\n",
      "      \"german\": \"Auf Wiedersehen\",\n",
      "      \"russian\": \"Прощай\"\n",
      "    },\n",
      "    \"customerInfo\": {\n",
      "       \"name\": \"John Michaels\",\n",
      "\"address\": \"111 Some Street, SomeCity, SomeCountry\",\n",
      "       \"age\": 40\n",
      "     },\n",
      "     \"finalCustomerGreeting\": \"Hola John Michaels!\"\n",
      "}\n",
      "(4) Event State Completes  Execution:\n",
      "When our event state finishes its execution, the states \"stateDataFilter\" \"output\" filter expression is executed\n",
      "to filter the state data to create the final state data output.\n",
      "Because our event state is also an end state, its data output becomes the final workflow data output. Namely:\n",
      "\n",
      "json\n",
      "{\n",
      "   \"finalCustomerGreeting\": \"Hola John Michaels!\"\n",
      "}\n",
      "\n",
      "Data Merging\n",
      "Consumed event data (payload) and action execution results should be merged into the state data.\n",
      "Event and action data filters can be used to give more details about this operation.\n",
      "By default, with no data filters specified, when an event is consumed, its entire data section (payload) should be merged\n",
      "to the state data. Merging should be applied to the entire state data JSON element.\n",
      "In case of event and action filters, their \"toStateData\" property can be defined to select a specific element\n",
      "of the state data with which merging should be done against. If this element does not exist, a new one should\n",
      "be created first.\n",
      "When merging, the state data element and the data (payload)/action result should have the same type, meaning\n",
      "that you should not merge arrays with objects or objects with arrays etc.\n",
      "When merging elements of type object should be done by inserting all the key-value pairs from both objects into\n",
      "a single combined object. If both objects contain a value for the same key, the object of the event data/action results\n",
      "should \"win\". To give an example, let's say we have the following state data:\n",
      "json\n",
      "{\n",
      "    \"customer\": {\n",
      "        \"name\": \"John\",\n",
      "        \"address\": \"1234 street\",\n",
      "        \"zip\": \"12345\"\n",
      "    }\n",
      "}\n",
      "\n",
      "and we have the following event payload that needs to be merged into the state data:\n",
      "json\n",
      "{\n",
      "    \"customer\": {\n",
      "        \"name\": \"John\",\n",
      "        \"zip\": \"54321\"\n",
      "    }\n",
      "}\n",
      "\n",
      "After merging the state data should be:\n",
      "json\n",
      "{\n",
      "  \"customer\": {\n",
      "    \"name\": \"John\",\n",
      "    \"address\": \"1234 street\",\n",
      "    \"zip\": \"54321\"\n",
      "  }\n",
      "}\n",
      "Merging array types should be done by concatenating them into a larger array including unique elements of both arrays.\n",
      "To give an example, merging:\n",
      "json\n",
      "{\n",
      "    \"customers\": [\n",
      "      {\n",
      "        \"name\": \"John\",\n",
      "        \"address\": \"1234 street\",\n",
      "        \"zip\": \"12345\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Jane\",\n",
      "        \"address\": \"4321 street\",\n",
      "\"zip\": \"54321\"\n",
      "      }\n",
      "    ]\n",
      "}\n",
      "into state data:\n",
      "\n",
      "json\n",
      "{\n",
      "    \"customers\": [\n",
      "      {\n",
      "        \"name\": \"Michael\",\n",
      "        \"address\": \"6789 street\",\n",
      "        \"zip\": \"6789\"\n",
      "      }\n",
      "    ]\n",
      "}\n",
      "\n",
      "should produce state data:\n",
      "json\n",
      "{\n",
      "    \"customers\": [\n",
      "      {\n",
      "        \"name\": \"Michael\",\n",
      "        \"address\": \"6789 street\",\n",
      "        \"zip\": \"6789\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"John\",\n",
      "        \"address\": \"1234 street\",\n",
      "\"zip\": \"12345\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Jane\",\n",
      "        \"address\": \"4321 street\",\n",
      "        \"zip\": \"54321\"\n",
      "      }\n",
      "    ]\n",
      "}\n",
      "Merging number types should be done by overwriting the data from events data/action results into the merging element of the state data.\n",
      "For example merging action results:\n",
      "\n",
      "json\n",
      "{\n",
      "    \"age\": 30\n",
      "}\n",
      "into state data:\n",
      "\n",
      "json\n",
      "{\n",
      "    \"age\": 20\n",
      "}\n",
      "\n",
      "would produce state data:\n",
      "\n",
      "json\n",
      "{\n",
      "    \"age\": 30\n",
      "}\n",
      "Merging string types should be done by overwriting the data from events data/action results into the merging element of the state data.\n",
      "\n",
      "Workflow Functions\n",
      "Workflow functions are reusable definitions for service invocations and/or expression evaluation.\n",
      "They can be referenced by their domain-specific names inside workflow states.\n",
      "Reference the following sections to learn more about workflow functions:\n",
      "\n",
      "Using functions for RESTful service invocations\n",
      "\n",
      "Using Functions for Async API Service Invocations\n",
      "Using functions for gRPC service invocation\n",
      "\n",
      "Using functions for GraphQL service invocation\n",
      "\n",
      "Using Functions for OData Service Invocations\n",
      "\n",
      "Using functions for expression evaluations\n",
      "Defining custom function types\n",
      "\n",
      "We can define if functions are invoked sync or async. Reference\n",
      "the functionRef to learn more on how to do this.\n",
      "\n",
      "Using Functions for RESTful Service Invocations\n",
      "Functions can be used to describe services and their operations that need to be invoked during\n",
      "workflow execution. They can be referenced by states action definitions to clearly\n",
      "define when the service operations should be invoked during workflow execution, as well as the data parameters\n",
      "passed to them if needed.\n",
      "Note that with Serverless Workflow, we can also define invocation of services which are triggered via an event.\n",
      "To learn more about that, please reference the event definitions section,\n",
      "as well as the actions definitions eventRef property.\n",
      "Because of an overall lack of a common way to describe different services and their operations,\n",
      "many workflow languages typically chose to define custom function definitions.\n",
      "This approach, however, often runs into issues such as lack of portability, limited capabilities, as well as\n",
      "forcing non-workflow-specific information, such as service authentication, to be added inside the workflow language.\n",
      "To avoid these issues, the Serverless Workflow specification mandates that details about\n",
      "RESTful services and their operations be described using the OpenAPI Specification.\n",
      "OpenAPI is a language-agnostic standard that describes discovery of RESTful services.\n",
      "This allows Serverless Workflow language to describe RESTful services in a portable\n",
      "way, as well as workflow runtimes to utilize OpenAPI tooling and APIs to invoke service operations.\n",
      "Here is an example function definition for a RESTful service operation.\n",
      "json\n",
      "{\n",
      "\"functions\": [\n",
      "  {\n",
      "    \"name\": \"sendOrderConfirmation\",\n",
      "    \"operation\": \"file://confirmationapi.json#sendOrderConfirmation\"\n",
      "  }\n",
      "]\n",
      "}\n",
      "It can, as previously mentioned be referenced during workflow execution when the invocation of this service is desired.\n",
      "For example:\n",
      "json\n",
      "{\n",
      "\"states\": [\n",
      "  {\n",
      "      \"name\":\"SendConfirmState\",\n",
      "      \"type\":\"operation\",\n",
      "      \"actions\":[\n",
      "       {\n",
      "       \"functionRef\": \"sendOrderConfirmation\"\n",
      "      }],\n",
      "      \"end\": true\n",
      "  }]\n",
      "}\n",
      "Note that the referenced function definition type in this case must be rest (default type).\n",
      "\n",
      "For more information about functions, reference the Functions definitions section.\n",
      "Using Functions for Async API Service Invocations\n",
      "Functions can be used to invoke PUBLISH and SUBSCRIBE operations on a message broker documented by the Async API Specification.\n",
      "Async API operations are bound to a channel which describes the technology, security mechanisms, input and validation to be used for their execution.\n",
      "Let's take a look at a hypothetical Async API document (assumed its stored locally with the file name streetlightsapi.yaml) and define a single publish operation:\n",
      "yaml\n",
      "asyncapi: 2.1.0\n",
      "info:\n",
      "  title: Streetlights API\n",
      "  version: 1.0.0\n",
      "  description: |\n",
      "    The Smartylighting Streetlights API allows you\n",
      "    to remotely manage the city lights.\n",
      "  license:\n",
      "name: Apache 2.0\n",
      "    url: https://www.apache.org/licenses/LICENSE-2.0\n",
      "servers:\n",
      "  mosquitto:\n",
      "    url: mqtt://test.mosquitto.org\n",
      "    protocol: mqtt\n",
      "channels:\n",
      "  light/measured:\n",
      "    publish:\n",
      "summary: Inform about environmental lighting conditions for a particular streetlight.\n",
      "      operationId: onLightMeasured\n",
      "      message:\n",
      "        name: LightMeasured\n",
      "        payload:\n",
      "type: object\n",
      "          properties:\n",
      "            id:\n",
      "              type: integer\n",
      "              minimum: 0\n",
      "              description: Id of the streetlight.\n",
      "            lumens:\n",
      "type: integer\n",
      "              minimum: 0\n",
      "              description: Light intensity measured in lumens.\n",
      "            sentAt:\n",
      "              type: string\n",
      "              format: date-time\n",
      "description: Date and time when the message was sent.\n",
      "To define a workflow action invocation, we can then use the following workflow Function Definition and set the operation to onLightMeasured:\n",
      "json\n",
      "{\n",
      "  \"functions\": [\n",
      "  {\n",
      "    \"name\": \"publishLightMeasurements\",\n",
      "    \"operation\": \"file://streetlightsapi.yaml#onLightMeasured\",\n",
      "    \"type\": \"asyncapi\"\n",
      "  }]\n",
      "}\n",
      "Note that the Function Definition's operation property must have the following format:\n",
      "\n",
      "text\n",
      "<URI_to_asyncapi_file>#<OperationId>\n",
      "Also note that the referenced function definition type in this case must have the value asyncapi.\n",
      "\n",
      "Our defined function definition can then we referenced in a workflow action, for example:\n",
      "json\n",
      "{\n",
      "  \"name\": \"Publish Measurements\",\n",
      "  \"type\": \"operation\",\n",
      "  \"actions\":[\n",
      "    {\n",
      "      \"name\": \"Publish Light Measurements\",\n",
      "      \"functionRef\":{\n",
      "        \"refName\": \"publishLightMeasurements\",\n",
      "\"arguments\":{\n",
      "          \"id\": \"${ .currentLight.id }\",\n",
      "          \"lumens\": \"${ .currentLight.lumens }\",\n",
      "          \"sentAt\": \"${ now }\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Using Functions for RPC Service Invocations\n",
      "Similar to defining invocations of operations on RESTful services, you can also use the workflow\n",
      "functions definitions that follow the remote procedure call (RPC) protocol.\n",
      "For RPC invocations, the Serverless Workflow specification mandates that they are described using gRPC,\n",
      "a widely used RPC system.\n",
      "gRPC uses Protocol Buffers to define messages, services,\n",
      "and the methods on those services that can be invoked.\n",
      "Let's look at an example of invoking a service method using RPC. For this example let's say we have the following\n",
      "gRPC protocol buffer definition in a myuserservice.proto file:\n",
      "text\n",
      "service UserService {\n",
      "    rpc AddUser(User) returns (google.protobuf.Empty) {\n",
      "        option (google.api.http) = {\n",
      "            post: \"/api/v1/users\"\n",
      "            body: \"*\"\n",
      "        };\n",
      "    }\n",
      "rpc ListUsers(ListUsersRequest) returns (stream User) {\n",
      "        option (google.api.http) = {\n",
      "            get: \"/api/v1/users\"\n",
      "        };\n",
      "    }\n",
      "rpc ListUsersByRole(UserRole) returns (stream User) {\n",
      "        option (google.api.http) = {\n",
      "            get: \"/api/v1/users/role\"\n",
      "        };\n",
      "    }\n",
      "rpc UpdateUser(UpdateUserRequest) returns (User) {\n",
      "        option (google.api.http) = {\n",
      "            patch: \"/api/v1/users/{user.id}\"\n",
      "            body: \"*\"\n",
      "        };\n",
      "    }\n",
      "}\n",
      "In our workflow definition, we can then use function definitions:\n",
      "json\n",
      "{\n",
      "\"functions\": [\n",
      "  {\n",
      "    \"name\": \"listUsers\",\n",
      "    \"operation\": \"file://myuserservice.proto#UserService#ListUsers\",\n",
      "    \"type\": \"rpc\"\n",
      "  }\n",
      "]\n",
      "}\n",
      "Note that the operation property has the following format:\n",
      "\n",
      "text\n",
      "<URI_to_proto_file>#<Service_Name>#<Service_Method_Name>\n",
      "\n",
      "Note that the referenced function definition type in this case must be rpc.\n",
      "For more information about functions, reference the Functions definitions section.\n",
      "\n",
      "Using Functions for GraphQL Service Invocations\n",
      "If you want to use GraphQL services, you can also invoke them using a similar syntax to the above methods.\n",
      "We'll use the following GraphQL schema definition to show how that would work with both a query and a mutation:\n",
      "\n",
      "```graphql\n",
      "type Query {\n",
      "    pets: [Pet]\n",
      "    pet(id: Int!): Pet\n",
      "}\n",
      "type Mutation {\n",
      "    createPet(pet: PetInput!): Pet\n",
      "}\n",
      "\n",
      "type Treat {\n",
      "    id: Int!\n",
      "}\n",
      "\n",
      "type Pet {\n",
      "    id: Int!\n",
      "    name: String!\n",
      "    favoriteTreat: Treat\n",
      "}\n",
      "input PetInput {\n",
      "    id: Int!\n",
      "    name: String!\n",
      "    favoriteTreatId: Int\n",
      "}\n",
      "Invoking a GraphQL Query\n",
      "\n",
      "In our workflow definition, we can then use a function definition for the pet query field as such:\n",
      "json\n",
      "{\n",
      "  \"functions\": [\n",
      "    {\n",
      "      \"name\": \"getOnePet\",\n",
      "      \"operation\": \"https://example.com/pets/graphql#query#pet\",\n",
      "      \"type\": \"graphql\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Note that the operation property has the following format for the graphql type:\n",
      "\n",
      "text\n",
      "<url_to_graphql_endpoint>#<literal \"mutation\" or \"query\">#<mutation_or_query_field>\n",
      "In order to invoke this query, we would use the following functionRef parameters:\n",
      "json\n",
      "{\n",
      "  \"refName\": \"getOnePet\",\n",
      "  \"arguments\": {\n",
      "    \"id\": 42\n",
      "  },\n",
      "  \"selectionSet\": \"{ id, name, favoriteTreat { id } }\"\n",
      "}\n",
      "\n",
      "Which would return the following result:\n",
      "json\n",
      "{\n",
      "  \"pet\": {\n",
      "    \"id\": 42,\n",
      "    \"name\": \"Snuffles\",\n",
      "    \"favoriteTreat\": {\n",
      "      \"id\": 9001\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Invoking a GraphQL Mutation\n",
      "\n",
      "Likewise, we would use the following function definition:\n",
      "json\n",
      "{\n",
      "  \"functions\": [\n",
      "    {\n",
      "      \"name\": \"createPet\",\n",
      "      \"operation\": \"https://example.com/pets/graphql#mutation#createPet\",\n",
      "      \"type\": \"graphql\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "With the parameters for the functionRef:\n",
      "json\n",
      "{\n",
      "  \"refName\": \"createPet\",\n",
      "  \"arguments\": {\n",
      "    \"pet\": {\n",
      "      \"id\": 43,\n",
      "      \"name\":\"Sadaharu\",\n",
      "      \"favoriteTreatId\": 9001\n",
      "    }\n",
      "  },\n",
      "  \"selectionSet\": \"{ id, name, favoriteTreat { id } }\"\n",
      "}\n",
      "Which would execute the mutation, creating the object and returning the following data:\n",
      "\n",
      "json\n",
      "{\n",
      "  \"pet\": {\n",
      "    \"id\": 43,\n",
      "    \"name\": \"Sadaharu\",\n",
      "    \"favoriteTreat\": {\n",
      "      \"id\": 9001\n",
      "    }\n",
      "  }\n",
      "}\n",
      "Note you can include expressions in both arguments and selectionSet:\n",
      "json\n",
      "{\n",
      "  \"refName\": \"getOnePet\",\n",
      "  \"arguments\": {\n",
      "    \"id\": \"${ .petId }\"\n",
      "  },\n",
      "  \"selectionSet\": \"{ id, name, age(useDogYears: ${ .isPetADog }) { dateOfBirth, years } }\"\n",
      "}\n",
      "Expressions must be evaluated before executing the operation.\n",
      "\n",
      "Note that GraphQL Subscriptions are not supported at this time.\n",
      "For more information about functions, reference the Functions definitions section.\n",
      "\n",
      "Using Functions for OData Service Invocations\n",
      "Similar to defining invocations of operations on GraphQL services, you can also use workflow\n",
      "Functions Definitions to execute complex queries on an OData service.\n",
      "Creating an OData Function Definition\n",
      "\n",
      "We start off by creating a workflow Functions Definitions. For example:\n",
      "json\n",
      "{\n",
      "\"functions\": [\n",
      "  {\n",
      "    \"name\": \"queryPersons\",\n",
      "    \"operation\": \"https://services.odata.org/V3/OData/OData.svc#Persons\",\n",
      "    \"type\": \"odata\"\n",
      "  }\n",
      "]\n",
      "}\n",
      "Note that the operation property must follow the following format:\n",
      "\n",
      "text\n",
      "<URI_to_odata_service>#<Entity_Set_Name>\n",
      "\n",
      "Invoking an OData Function Definition\n",
      "In order to invoke the defined OData function, \n",
      "simply reference it in a workflow Action Definition and set its  function arguments. For example:\n",
      "json\n",
      "{\n",
      "  \"refName\": \"queryPersons\",\n",
      "  \"arguments\": {\n",
      "    \"queryOptions\":{\n",
      "      \"expand\": \"PersonDetail/Person\",\n",
      "      \"select\": \"Id, PersonDetail/Person/Name\",\n",
      "      \"top\": 5,\n",
      "\"orderby\": \"PersonDetail/Person/Name\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "In order to ensure compatibility of OData support across runtimes, \n",
      "thearguments property of an OData function reference \n",
      "should follow the Serverless Workflow OData Json schema\n",
      "Using Functions for Expression Evaluation\n",
      "In addition to defining RESTful, AsyncAPI, RPC, GraphQL and OData services and their operations, workflow functions definitions\n",
      "can also be used to define expressions that should be evaluated during workflow execution.\n",
      "Defining expressions as part of function definitions has the benefit of being able to reference\n",
      "them by their logical name through workflow states where expression evaluation is required.\n",
      "Expression functions must declare their type parameter to be expression.\n",
      "\n",
      "Let's take a look at an example of such definitions:\n",
      "json\n",
      "{\n",
      "\"functions\": [\n",
      "  {\n",
      "    \"name\": \"isAdult\",\n",
      "    \"operation\": \".applicant | .age >= 18\",\n",
      "    \"type\": \"expression\"\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"isMinor\",\n",
      "    \"operation\": \".applicant | .age < 18\",\n",
      "\"type\": \"expression\"\n",
      "  }\n",
      "]\n",
      "}\n",
      "Here we define two reusable expression functions. Expressions in Serverless Workflow\n",
      "can be evaluated against the workflow, or workflow state data. Note that different data filters play a big role as to which parts of the\n",
      "workflow data are being evaluated by the expressions. Reference the\n",
      "State Data Filters section for more information on this.\n",
      "Our expression function definitions can now be referenced by workflow states when they need to be evaluated. For example:\n",
      "json\n",
      "{\n",
      "\"states\":[\n",
      "  {\n",
      "     \"name\":\"CheckApplicant\",\n",
      "     \"type\":\"switch\",\n",
      "     \"dataConditions\": [\n",
      "        {\n",
      "          \"name\": \"Applicant is adult\",\n",
      "          \"condition\": \"${ fn:isAdult }\",\n",
      "\"transition\": \"ApproveApplication\"\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"Applicant is minor\",\n",
      "          \"condition\": \"${ fn:isMinor }\",\n",
      "          \"transition\": \"RejectApplication\"\n",
      "}\n",
      "     ],\n",
      "     \"defaultCondition\": {\n",
      "        \"transition\": \"RejectApplication\"\n",
      "     }\n",
      "  }\n",
      "]\n",
      "}\n",
      "Our expression functions can also be referenced and executed as part of state action execution.\n",
      "Let's say we have the following workflow definition:\n",
      "json\n",
      "{\n",
      "    \"name\": \"simpleadd\",\n",
      "    \"functions\": [\n",
      "        {\n",
      "            \"name\": \"Increment Count Function\",\n",
      "            \"type\": \"expression\",\n",
      "            \"operation\": \".count += 1 | .count\"\n",
      "        }\n",
      "],\n",
      "    \"start\": \"Initialize Count\",\n",
      "    \"states\": [\n",
      "        {\n",
      "            \"name\": \"Initialize Count\",\n",
      "            \"type\": \"inject\",\n",
      "            \"data\": {\n",
      "                \"count\": 0\n",
      "            },\n",
      "\"transition\": \"Increment Count\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Increment Count\",\n",
      "            \"type\": \"operation\",\n",
      "            \"actions\": [\n",
      "                {\n",
      "\"functionRef\": \"Increment Count Function\",\n",
      "                    \"actionDataFilter\": {\n",
      "                        \"toStateData\": \"${ .count }\"\n",
      "                    }\n",
      "                }\n",
      "],\n",
      "            \"end\": true\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "The starting inject state \"Initialize Count\" injects the count element into our state data,\n",
      "which then becomes the state data input of our \"Increment Count\" operation state.\n",
      "This state defines an invocation of the \"Increment Count Function\" expression function defined in our workflow definition.\n",
      "This triggers the evaluation of the defined expression. The input of this expression is by default the current state data.\n",
      "Just like with \"rest\", and \"rpc\" type functions, expression functions also produce a result. In this case\n",
      "the result of the expression is just the number 1.\n",
      "The actions filter then assigns this result to the state data element \"count\" and the state data becomes:\n",
      "json\n",
      "{\n",
      "    \"count\": 1\n",
      "}\n",
      "\n",
      "Note that the used function definition type in this case must be expression.\n",
      "\n",
      "For more information about functions, reference the Functions definitions section.\n",
      "For more information about workflow expressions, reference the Workflow Expressions section.\n",
      "\n",
      "Defining custom function types\n",
      "Function definitions type property defines a list of function types that are set by\n",
      "the specification.\n",
      "Some runtime implementations might support additional function types that extend the ones\n",
      "defined in the specification. In those cases you can define a custom function type with for example:\n",
      "json\n",
      "{\n",
      "\"functions\": [\n",
      "  {\n",
      "    \"name\": \"sendOrderConfirmation\",\n",
      "    \"operation\": \"/path/to/my/script/order.ts#myFunction\",\n",
      "    \"type\": \"custom\"\n",
      "  }\n",
      "]\n",
      "}\n",
      "In this example we define a custom function type that is meant to execute an external TypeScript script.\n",
      "When a custom function type is specified, the operation property value has a custom format, meaning that\n",
      "its format is controlled by the runtime which provides the custom function type.\n",
      "Later, the function should be able to be used in an action as any other function supported by the specification:\n",
      "json\n",
      "[{\n",
      "  \"states\": [{\n",
      "      \"name\": \"handleOrder\",\n",
      "      \"type\": \"operation\",\n",
      "      \"actions\": [\n",
      "        {\n",
      "          \"name\": \"sendOrderConfirmation\",\n",
      "          \"functionRef\": {\n",
      "\"refName\": \"sendOrderConfirmation\",\n",
      "            \"arguments\": {\n",
      "              \"order\": \"${ .order }\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"transition\": \"emailCustomer\"\n",
      "  }]\n",
      "}]\n",
      "Note that custom function types are not portable across runtimes.\n",
      "\n",
      "Workflow Expressions\n",
      "\n",
      "Workflow model parameters can use expressions to select/manipulate workflow and/or state data.\n",
      "Note that different data filters play a big role as to which parts of the states data are to be used when the expression is\n",
      "evaluated. Reference the\n",
      "State Data Filtering section for more information about state data filters.\n",
      "By default, all workflow expressions should be defined using the jq version 1.6 syntax.\n",
      "You can find more information on jq in its manual.\n",
      "Serverless Workflow does not mandate the use of jq and it's possible to use an expression language\n",
      "of your choice with the restriction that a single one must be used for all expressions\n",
      "in a workflow definition. If a different expression language needs to be used, make sure to set the workflow\n",
      "expressionLang property to identify it to runtime implementations.\n",
      "Note that using a non-default expression language could lower the portability of your workflow definitions\n",
      "across multiple container/cloud platforms.\n",
      "All workflow expressions in this document, specification examples as well as comparisons examples\n",
      "are written using the default jq syntax.\n",
      "\n",
      "Workflow expressions have the following format:\n",
      "text\n",
      "${ expression }\n",
      "\n",
      "Where expression can be either an in-line expression, or a reference to a\n",
      "defined expression function definition.\n",
      "To reference a defined expression function definition\n",
      "the expression must have the following format, for example:\n",
      "\n",
      "text\n",
      "${ fn:myExprFuncName }\n",
      "Where fn is the namespace of the defined expression functions and\n",
      "myExprName is the unique expression function name.\n",
      "\n",
      "To show some expression examples, let's say we have the following state data:\n",
      "json\n",
      "{\n",
      "  \"applicant\": {\n",
      "    \"name\": \"John Doe\",\n",
      "    \"age\"      : 26,\n",
      "    \"email\": \"johndoe@something.com\",\n",
      "    \"address\"  : {\n",
      "      \"streetAddress\": \"Naist street\",\n",
      "      \"city\"         : \"Nara\",\n",
      "\"postalCode\"   : \"630-0192\"\n",
      "    },\n",
      "    \"phoneNumbers\": [\n",
      "      {\n",
      "        \"type\"  : \"iPhone\",\n",
      "        \"number\": \"0123-4567-8888\"\n",
      "      },\n",
      "      {\n",
      "        \"type\"  : \"home\",\n",
      "\"number\": \"0123-4567-8910\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "In our workflow model we can define our reusable expression function:\n",
      "json\n",
      "{\n",
      "\"functions\": [\n",
      "  {\n",
      "    \"name\": \"IsAdultApplicant\",\n",
      "    \"operation\": \".applicant | .age > 18\",\n",
      "    \"type\": \"expression\"\n",
      "  }\n",
      "]\n",
      "}\n",
      "We will get back to this function definition in just a bit, but now let's take a look at using\n",
      "an inline expression that sets an input parameter inside an action for example:\n",
      "json\n",
      "{\n",
      "\"actions\": [\n",
      "    {\n",
      "        \"functionRef\": {\n",
      "            \"refName\": \"confirmApplicant\",\n",
      "            \"arguments\": {\n",
      "                \"applicantName\": \"${ .applicant.name }\"\n",
      "            }\n",
      "        }\n",
      "}\n",
      "]\n",
      "}\n",
      "In this case our input parameter applicantName would be set to \"John Doe\".\n",
      "\n",
      "Expressions can also be used to select and manipulate state data, this is in particularly useful for\n",
      "state data filters.\n",
      "For example let's use another inline expression:\n",
      "\n",
      "json\n",
      "{\n",
      "   \"stateDataFilter\": {\n",
      "       \"output\": \"${ .applicant | {applicant: .name, contactInfo: { email: .email, phone: .phoneNumbers }} }\"\n",
      "   }\n",
      "}\n",
      "This would set the data output of the particular state to:\n",
      "json\n",
      "{\n",
      "  \"applicant\": \"John Doe\",\n",
      "  \"contactInfo\": {\n",
      "    \"email\": \"johndoe@something.com\",\n",
      "    \"phone\": [\n",
      "      {\n",
      "        \"type\": \"iPhone\",\n",
      "        \"number\": \"0123-4567-8888\"\n",
      "      },\n",
      "      {\n",
      "\"type\": \"home\",\n",
      "        \"number\": \"0123-4567-8910\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "Switch state conditions require for expressions to be resolved to a boolean value (true/false).\n",
      "\n",
      "We can now get back to our previously defined \"IsAdultApplicant\" expression function and reference it:\n",
      "json\n",
      "{\n",
      "  \"dataConditions\": [ {\n",
      "    \"condition\": \"${ fn:IsAdultApplicant }\",\n",
      "    \"transition\": \"StartApplication\"\n",
      "  }]\n",
      "}\n",
      "As previously mentioned, expressions are evaluated against certain subsets of data. For example\n",
      "the parameters param of the functionRef definition can evaluate expressions\n",
      "only against the data that is available to the action it belongs to.\n",
      "One thing to note here are the top-level workflow definition parameters. Expressions defined\n",
      "in them can only be evaluated against the initial workflow data input.\n",
      "For example let's say that we have a workflow data input of:\n",
      "\n",
      "json\n",
      "{\n",
      "   \"inputVersion\" : \"1.0.0\"\n",
      "}\n",
      "\n",
      "we can use this expression in the workflow \"version\" parameter:\n",
      "json\n",
      "{\n",
      "   \"id\": \"MySampleWorkflow\",\n",
      "   \"name\": \"Sample Workflow\",\n",
      "   \"version\": \"${ .inputVersion }\",\n",
      "   \"specVersion\": \"0.8\"\n",
      "}\n",
      "which would set the workflow version to \"1.0.0\".\n",
      "Note that the workflow \"id\" property value is not allowed to use an expression. The workflow\n",
      "definition \"id\" must be a constant value.\n",
      "Workflow Definition Structure\n",
      "semantic versioning format | string | no |\n",
      "| annotations | List of helpful terms describing the workflows intended purpose, subject areas, or other important qualities | array | no |\n",
      "| dataInputSchema | Used to validate the workflow data input against a defined JSON Schema| string or object | no |\n",
      "|\n",
      "constants | Workflow constants | string or object | no |\n",
      "|\n",
      "\n",
      "secrets | Workflow secrets | string or array | no |\n",
      "|\n",
      "start | Workflow start definition | string or object | no |\n",
      "| specVersion | Serverless Workflow specification release version | string | yes |\n",
      "| expressionLang | Identifies the expression language used for workflow expressions. Default value is \"jq\" | string | no |\n",
      "|\n",
      "timeouts | Defines the workflow default timeout settings | string or object | no |\n",
      "|\n",
      "errors | Defines checked errors that can be explicitly handled during workflow execution | string or array | no |\n",
      "| keepActive | If\n",
      "auth | Workflow authentication definitions | array or string | no |\n",
      "|\n",
      "\n",
      "events | Workflow event definitions.  | array or string | no |\n",
      "|\n",
      "functions | Workflow function definitions. Can be either inline function definitions (if array) or URI pointing to a resource containing json/yaml function definitions (if string) | array or string|\n",
      "no |\n",
      "| autoRetries | If set to\n",
      "actions should automatically be retried on unchecked errors. Default is\n",
      "retries | Workflow retries definitions. Can be either inline retries definitions (if array) or URI pointing to a resource containing json/yaml retry definitions (if string) | array or string| no |\n",
      "|\n",
      "states | Workflow states | array | yes |\n",
      "|\n",
      "\n",
      "extensions | Workflow extensions definitions | array or string | no |\n",
      "|\n",
      "\n",
      "metadata | Metadata information | object | no |\n",
      "```json\n",
      "{\n",
      "   \"id\": \"sampleWorkflow\",\n",
      "   \"version\": \"1.0.0\",\n",
      "   \"specVersion\": \"0.8\",\n",
      "   \"name\": \"Sample Workflow\",\n",
      "   \"description\": \"Sample Workflow\",\n",
      "   \"start\": \"MyStartingState\",\n",
      "   \"states\": [],\n",
      "\"functions\": [],\n",
      "   \"events\": [],\n",
      "   \"errors\": [],\n",
      "   \"retries\":[]\n",
      "}\n",
      "```yaml\n",
      "id: sampleWorkflow\n",
      "version: '1.0.0'\n",
      "specVersion: '0.8'\n",
      "name: Sample Workflow\n",
      "description: Sample Workflow\n",
      "start: MyStartingState\n",
      "states: []\n",
      "functions: []\n",
      "events: []\n",
      "errors: []\n",
      "retries: []\n",
      "Defines the top-level structure of a serverless workflow model.\n",
      "Following figure describes the main workflow definition blocks.\n",
      "The id property defines the unique, domain-specific workflow identifier, for example \"orders\", \"payment\", etc.\n",
      "The key property defines the unique, domain-specific workflow identifier.\n",
      "It can be used when the id property is auto-generated by a content-management system for example.\n",
      "In these cases, you can specify the key property to be the domain-specific identifier of the workflow definition.\n",
      "The id and key properties are mutually exclusive, meaning you cannot define both.\n",
      "The name property is the workflow logical name.\n",
      "\n",
      "The description property can be used to give further information about the workflow.\n",
      "The version property can be used to provide a specific workflow version. It must use the semantic versioning format.\n",
      "The annotations property defines a list of helpful terms describing the workflows intended purpose, subject areas, or other important qualities,\n",
      "for example \"machine learning\", \"monitoring\", \"networking\", etc\n",
      "The dataInputSchema property can be used to validate the workflow data input against a defined JSON Schema.\n",
      "This check should be done before any states are executed. dataInputSchema can have two different types.\n",
      "If it is an object type it has the following definition:\n",
      "json\n",
      "\"dataInputSchema\": {\n",
      "   \"schema\": \"URL_to_json_schema\",\n",
      "   \"failOnValidationErrors\": false\n",
      "}\n",
      "It's schema property can be an URI, which points to the JSON schema used to validate the workflow data input, or it can be the JSON schema object.\n",
      "If it's a JSON schema object, it has the following definition:\n",
      "```json\n",
      "\"dataInputSchema\": {\n",
      "   \"schema\": {\n",
      "     \"title\": \"MyJSONSchema\",\n",
      "     \"properties\":{\n",
      "       \"firstName\":{\n",
      "         \"type\": \"string\"\n",
      "       },\n",
      "       \"lastName\":{\n",
      "         \"type\": \"string\"\n",
      "}\n",
      "     }\n",
      "   },\n",
      "   \"failOnValidationErrors\": false\n",
      "}\n",
      "``\n",
      "It'failOnValidationErrorsproperty  determines if workflow execution should continue in case of validation\n",
      "errors. The default value offailOnValidationErrorsistrue.\n",
      "IfdataInputSchema` has the string type, it has the following definition:\n",
      "json\n",
      "\"dataInputSchema\": \"URL_to_json_schema\"\n",
      "\n",
      "In this case the failOnValidationErrors default value of true is assumed.\n",
      "The dataInputSchema property validates the workflow data input. In case of\n",
      "a starting Event state, it is not used to validate its event payloads.\n",
      "The secrets property allows you to use sensitive information such as passwords, OAuth tokens, ssh keys, etc. inside your\n",
      "Workflow expressions.\n",
      "It has two possible types, string or array.\n",
      "If string type, it is an URI pointing to a JSON or YAML document\n",
      "which contains an array of names of the secrets, for example:\n",
      "json\n",
      "\"secrets\": \"file://workflowsecrets.json\"\n",
      "\n",
      "If array type, it defines an array (of string types) which contains the names of the secrets, for example:\n",
      "json\n",
      "\"secrets\": [\"MY_PASSWORD\", \"MY_STORAGE_KEY\", \"MY_ACCOUNT\"]\n",
      "\n",
      "For more information about Workflow secrets, reference the Workflow Secrets section.\n",
      "The constants property can be used to define Workflow constants values\n",
      "which are accessible in Workflow Expressions.\n",
      "It has two possible types, string or object.\n",
      "If string type, it is an URI pointing to a JSON or YAML document\n",
      "which contains an object of global definitions, for example:\n",
      "json\n",
      "\"constants\": \"file://workflowconstants.json\"\n",
      "\n",
      "If object type, it defines a JSON object which contains the constants definitions, for example:\n",
      "\n",
      "json\n",
      "{\n",
      "  \"AGE\": {\n",
      "    \"MIN_ADULT\": 18\n",
      "  }\n",
      "}\n",
      "For more information see the Workflow Constants section.\n",
      "The start property defines the workflow starting information. For more information see the start definition section.\n",
      "This property is not required. If not defined, the workflow starting state has to be \n",
      "the very first state defined in the workflow states array.\n",
      "The specVersion property is used to set the Serverless Workflow specification release version\n",
      "the workflow markup adheres to.\n",
      "It has to follow the specification release versions (excluding the leading \"v\"), meaning that for\n",
      "the release version v0.8\n",
      "its value should be set to \"0.8\".\n",
      "The expressionLang property can be used to identify the expression language used for all expressions in\n",
      "the workflow definition. The default value of this property is \"jq\".\n",
      "You should set this property if you chose to define workflow expressions\n",
      "with an expression language / syntax other than the default.\n",
      "The timeouts property is used to define the default workflow timeouts for workflow, state, action, and branch\n",
      "execution. For more information about timeouts and its use cases see the Workflow Timeouts section.\n",
      "The error property is used to define checked errors that can be explicitly handled during workflow execution.\n",
      "For more information about workflow error handling see this section.\n",
      "auth definition array, or a URI reference to\n",
      "a resource containing an array of\n",
      "\n",
      "auth definitions.\n",
      "If defined in a separate resource file (Json or Yaml),\n",
      "function definitions.\n",
      "If we have the following function definition:\n",
      "json\n",
      "{\n",
      "   \"functions\": [\n",
      "      {\n",
      "         \"name\": \"HelloWorldFunction\",\n",
      "         \"operation\": \"https://secure.resources.com/myapi.json#helloWorld\",\n",
      "         \"authRef\": \"My Basic Auth\"\n",
      "      }\n",
      "   ]\n",
      "}\n",
      "The authRef property is used to reference an authentication definition in\n",
      "the auth property and should be applied when invoking the helloWorld function. An AuthRef object can alternatively be used to configure the authentication definition to use when accessing the\n",
      "function's resource and/or when invoking the function.\n",
      "The functions property can be either an in-line function definition array, or an URI reference to\n",
      "a resource containing an array of functions definition.\n",
      "Referenced resource can be used by multiple workflow definitions.\n",
      "Here is an example of using external resource for function definitions:\n",
      "\n",
      "Workflow definition:\n",
      "json\n",
      "{\n",
      "   \"id\": \"sampleWorkflow\",\n",
      "   \"version\": \"1.0.0\",\n",
      "   \"specVersion\": \"0.8\",\n",
      "   \"name\": \"Sample Workflow\",\n",
      "   \"description\": \"Sample Workflow\",\n",
      "   \"start\": \"MyStartingState\",\n",
      "\"functions\": \"http://myhost:8080/functiondefs.json\",\n",
      "   \"states\":[\n",
      "     ...\n",
      "   ]\n",
      "}\n",
      "Function definitions resource:\n",
      "\n",
      "json\n",
      "{\n",
      "   \"functions\": [\n",
      "      {\n",
      "         \"name\":\"HelloWorldFunction\",\n",
      "         \"operation\":\"file://myapi.json#helloWorld\"\n",
      "      }\n",
      "   ]\n",
      "}\n",
      "Referenced resource must conform to the specifications Workflow Functions JSON Schema.\n",
      "The events property can be either an in-line event definition array, or an URI reference to\n",
      "a resource containing an array of event definition. Referenced resource can be used by multiple workflow definitions.\n",
      "Here is an example of using external resource for event definitions:\n",
      "\n",
      "Workflow definition:\n",
      "json\n",
      "{\n",
      "   \"id\": \"sampleWorkflow\",\n",
      "   \"version\": \"1.0.0\",\n",
      "   \"specVersion\": \"0.8\",\n",
      "   \"name\": \"Sample Workflow\",\n",
      "   \"description\": \"Sample Workflow\",\n",
      "   \"start\": \"MyStartingState\",\n",
      "\"events\": \"http://myhost:8080/eventsdefs.json\",\n",
      "   \"states\":[\n",
      "     ...\n",
      "   ]\n",
      "}\n",
      "Event definitions resource:\n",
      "json\n",
      "{\n",
      "   \"events\": [\n",
      "      {\n",
      "         \"name\": \"ApplicantInfo\",\n",
      "         \"type\": \"org.application.info\",\n",
      "         \"source\": \"applicationssource\",\n",
      "         \"correlation\": [\n",
      "          {\n",
      "\"contextAttributeName\": \"applicantId\"\n",
      "          }\n",
      "         ]\n",
      "      }\n",
      "   ]\n",
      "}\n",
      "Referenced resource must conform to the specifications Workflow Events JSON Schema.\n",
      "The retries property can be either an in-line retry definition array, or an URI reference to\n",
      "a resource containing an array of retry definition.\n",
      "Referenced resource can be used by multiple workflow definitions. For more information about\n",
      "using and referencing retry definitions see the Workflow Error Handling section.\n",
      "The keepActive property allows you to change the default behavior of workflow instances.\n",
      "By default, as described in the Core Concepts section, a workflow instance is terminated once there are no more\n",
      "active execution paths, one of its active paths ends in a \"terminate\" end definition, or when\n",
      "its workflowExecTimeout time is reached.\n",
      "Setting the keepActive property to true allows you to change this default behavior in that a workflow instance\n",
      "created from this workflow definition can only be terminated if one of its active paths ends in a \"terminate\" end definition, or when\n",
      "its workflowExecTimeout time is reached.\n",
      "This allows you to explicitly model workflows where an instance should be kept alive, to collect (event) data for example.\n",
      "You can reference the specification examples to see the keepActive property in action.\n",
      "The extensions property can be used to define extensions for this workflow definition.\n",
      "You can learn more about workflow extensions in the Extensions section.\n",
      "Sample extensions property definition could look like this for example:\n",
      "json\n",
      "{\n",
      "  \"extensions\": [\n",
      "    {\n",
      "      \"extensionId\": \"workflow-ratelimiting-extension\",\n",
      "      \"path\": \"file://myextensions/ratelimiting.yml\"\n",
      "    },\n",
      "    {\n",
      "      \"extensionId\": \"workflow-kpi-extension\",\n",
      "\"path\": \"file://myextensions/kpi.yml\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Here we define two workflow extensions, namely the rate limiting and kpi extensions for our workflow definition.\n",
      "\n",
      "Workflow States\n",
      "Workflow states define building blocks of the workflow execution instructions. They define the\n",
      "control flow logic instructions on what the workflow is supposed to do.\n",
      "Serverless Workflow defines the following Workflow States:\n",
      "Event\n",
      "\n",
      "Operation\n",
      "\n",
      "Switch\n",
      "\n",
      "Sleep\n",
      "\n",
      "Parallel\n",
      "\n",
      "Inject\n",
      "\n",
      "ForEach\n",
      "\n",
      "Callback\n",
      "\n",
      "Event State\n",
      "\n",
      "onEvents | Define the events to be consumed and optional actions to be performed | array | yes |\n",
      "|\n",
      "timeouts | State specific timeout settings | object | no |\n",
      "|\n",
      "\n",
      "stateDataFilter | State data filter definition| object | no |\n",
      "|\n",
      "transition | Next transition of the workflow after all the actions have been performed | string or object | yes (if\n",
      "\n",
      "onErrors | States error handling definitions | array | no |\n",
      "|\n",
      "end | Is this state an end state | boolean or object | yes (if\n",
      "\n",
      "compensatedBy | Unique name of a workflow state which is responsible for compensation of this state | string | no |\n",
      "|\n",
      "metadata | Metadata information| object | no |\n",
      "```json\n",
      "{\n",
      "\"name\": \"MonitorVitals\",\n",
      "\"type\": \"event\",\n",
      "\"exclusive\": true,\n",
      "\"onEvents\": [{\n",
      "        \"eventRefs\": [\"HighBodyTemperature\"],\n",
      "        \"actions\": [{\n",
      "            \"functionRef\": {\n",
      "\"refName\": \"sendTylenolOrder\",\n",
      "                \"arguments\": {\n",
      "                    \"patientid\": \"${ .patientId }\"\n",
      "                }\n",
      "            }\n",
      "        }]\n",
      "    },\n",
      "    {\n",
      "\"eventRefs\": [\"HighBloodPressure\"],\n",
      "        \"actions\": [{\n",
      "            \"functionRef\": {\n",
      "                \"refName\": \"callNurse\",\n",
      "                \"arguments\": {\n",
      "\"patientid\": \"${ .patientId }\"\n",
      "                }\n",
      "            }\n",
      "        }]\n",
      "    },\n",
      "    {\n",
      "        \"eventRefs\": [\"HighRespirationRate\"],\n",
      "        \"actions\": [{\n",
      "\"functionRef\": {\n",
      "                \"refName\": \"callPulmonologist\",\n",
      "                \"arguments\": {\n",
      "                    \"patientid\": \"${ .patientId }\"\n",
      "                }\n",
      "            }\n",
      "}]\n",
      "    }\n",
      "],\n",
      "\"end\": {\n",
      "    \"terminate\": true\n",
      "}\n",
      "}\n",
      "```yaml\n",
      "name: MonitorVitals\n",
      "type: event\n",
      "exclusive: true\n",
      "onEvents:\n",
      "- eventRefs:\n",
      "  - HighBodyTemperature\n",
      "  actions:\n",
      "  - functionRef:\n",
      "      refName: sendTylenolOrder\n",
      "      arguments:\n",
      "patientid: \"${ .patientId }\"\n",
      "- eventRefs:\n",
      "  - HighBloodPressure\n",
      "  actions:\n",
      "  - functionRef:\n",
      "      refName: callNurse\n",
      "      arguments:\n",
      "        patientid: \"${ .patientId }\"\n",
      "- eventRefs:\n",
      "- HighRespirationRate\n",
      "  actions:\n",
      "  - functionRef:\n",
      "      refName: callPulmonologist\n",
      "      arguments:\n",
      "        patientid: \"${ .patientId }\"\n",
      "end:\n",
      "  terminate: true\n",
      "Event states await one or more events and perform actions when they are received.\n",
      "If defined as the workflow starting state, the event state definition controls when the workflow\n",
      "instances should be created.\n",
      "The exclusive property determines if the state should wait for any of the defined events in the onEvents array, or\n",
      "if all defined events must be present for their associated actions to be performed.\n",
      "Following two figures illustrate the exclusive property:\n",
      "\n",
      "If the Event state in this case is a workflow starting state, the occurrence of any of the defined events would start a new workflow instance.\n",
      "If the Event state in this case is a workflow starting state, the occurrence of all defined events would start a new\n",
      "workflow instance.\n",
      "In order to consider only events that are related to each other, we need to set the correlation property in the workflow\n",
      "events definitions. This allows us to set up event correlation rules against the events\n",
      "extension context attributes.\n",
      "If the Event state is not a workflow starting state, the timeout property can be used to define the time duration from the\n",
      "invocation of the event state. If the defined event, or events have not been received during this time,\n",
      "the state should transition to the next state or can end the workflow execution (if it is an end state).\n",
      "this section.\n",
      "For more information about workflow timeouts reference the\n",
      "\n",
      "Workflow Timeouts section.\n",
      "Note that transition and end properties are mutually exclusive, meaning that you cannot define both of them at the same time.\n",
      "\n",
      "Operation State\n",
      "\n",
      "actions | Actions to be performed | array | yes |\n",
      "|\n",
      "timeouts | State specific timeout settings | object | no |\n",
      "|\n",
      "\n",
      "stateDataFilter | State data filter | object | no |\n",
      "|\n",
      "\n",
      "onErrors | States error handling and retries definitions | array | no |\n",
      "|\n",
      "transition | Next transition of the workflow after all the actions have been performed | string or object | yes (if\n",
      "compensatedBy | Unique name of a workflow state which is responsible for compensation of this state | string | no |\n",
      "|\n",
      "\n",
      "usedForCompensation | If\n",
      "\n",
      "metadata | Metadata information| object | no |\n",
      "|\n",
      "end | Is this state an end state | boolean or object | yes (if\n",
      "```json\n",
      "{\n",
      "    \"name\": \"RejectApplication\",\n",
      "    \"type\": \"operation\",\n",
      "    \"actionMode\": \"sequential\",\n",
      "    \"actions\": [\n",
      "        {\n",
      "            \"functionRef\": {\n",
      "\"refName\": \"sendRejectionEmailFunction\",\n",
      "                \"arguments\": {\n",
      "                    \"customer\": \"${ .customer }\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "\"end\": true\n",
      "}\n",
      "```yaml\n",
      "name: RejectApplication\n",
      "type: operation\n",
      "actionMode: sequential\n",
      "actions:\n",
      "- functionRef:\n",
      "    refName: sendRejectionEmailFunction\n",
      "    arguments:\n",
      "      customer: \"${ .customer }\"\n",
      "end: true\n",
      "Operation state defines a set of actions to be performed in sequence or in parallel.\n",
      "Once all actions have been performed, a transition to another state can occur.\n",
      "The timeouts property can be used to define state specific timeout settings. Operation states can define\n",
      "the stateExecTimeout and actionExecTimeout settings. For more information on Workflow timeouts reference\n",
      "the Workflow Timeouts section.\n",
      "Switch State\n",
      "\n",
      "dataConditions | Defined if the Switch state evaluates conditions and transitions based on state data. | array | yes (if\n",
      "eventConditions | Defined if the Switch state evaluates conditions and transitions based on arrival of events. | array | yes (if\n",
      "\n",
      "stateDataFilter | State data filter | object | no |\n",
      "|\n",
      "onErrors | States error handling and retries definitions | array | no |\n",
      "|\n",
      "timeouts | State specific timeout settings | object | no |\n",
      "| defaultCondition | Default transition of the workflow if there is no matching data conditions or event timeout is reached. Can be a transition or end definition | object | yes |\n",
      "|\n",
      "compensatedBy | Unique name of a workflow state which is responsible for compensation of this state | string | no |\n",
      "|\n",
      "\n",
      "usedForCompensation | If\n",
      "\n",
      "metadata | Metadata information| object | no |\n",
      "```json\n",
      "{\n",
      "     \"name\":\"CheckVisaStatus\",\n",
      "     \"type\":\"switch\",\n",
      "     \"eventConditions\": [\n",
      "        {\n",
      "          \"eventRef\": \"visaApprovedEvent\",\n",
      "          \"transition\": \"HandleApprovedVisa\"\n",
      "        },\n",
      "{\n",
      "          \"eventRef\": \"visaRejectedEvent\",\n",
      "          \"transition\": \"HandleRejectedVisa\"\n",
      "        }\n",
      "     ],\n",
      "     \"timeouts\": {\n",
      "       \"eventTimeout\": \"PT1H\"\n",
      "     },\n",
      "     \"defaultCondition\": {\n",
      "\"transition\": \"HandleNoVisaDecision\"\n",
      "     }\n",
      "}\n",
      "```yaml\n",
      "name: CheckVisaStatus\n",
      "type: switch\n",
      "eventConditions:\n",
      "- eventRef: visaApprovedEvent\n",
      "  transition: HandleApprovedVisa\n",
      "- eventRef: visaRejectedEvent\n",
      "  transition: HandleRejectedVisa\n",
      "timeouts:\n",
      "eventTimeout: PT1H\n",
      "defaultCondition:\n",
      "  transition: HandleNoVisaDecision\n",
      "Switch states can be viewed as workflow gateways: they can direct transitions of a workflow based on certain conditions.\n",
      "There are two types of conditions for switch states:\n",
      "\n",
      "Data-based conditions\n",
      "Event-based conditions\n",
      "\n",
      "These are exclusive, meaning that a switch state can define one or the other condition type, but not both.\n",
      "At times multiple defined conditions can be evaluated to true by runtime implementations.\n",
      "Conditions defined first take precedence over conditions defined later. This is backed by the fact that arrays/sequences\n",
      "are ordered in both JSON and YAML. For example, let's say there are two true conditions: A and B, defined in that order.\n",
      "Because A was defined first, its transition will be executed, not B's.\n",
      "In case of data-based conditions definition, switch state controls workflow transitions based on the states data.\n",
      "If no defined conditions can be matched, the state transitions is taken based on the defaultCondition property.\n",
      "This property can be either a transition to another workflow state, or an end definition meaning a workflow end.\n",
      "For event-based conditions, a switch state acts as a workflow wait state. It halts workflow execution\n",
      "until one of the referenced events arrive, then making a transition depending on that event definition.\n",
      "If events defined in event-based conditions do not arrive before the states eventTimeout property expires,\n",
      "state transitions are based on the defined defaultCondition property.\n",
      "The timeouts property can be used to define state specific timeout settings. Switch states can define the\n",
      "stateExecTimeout setting. If eventConditions is defined, the switch state can also define the\n",
      "eventTimeout property. For more information on workflow timeouts reference the Workflow Timeouts section.\n",
      "Sleep State\n",
      "| Parameter | Description | Type | Required |\n",
      "| --- | --- | --- | --- |\n",
      "| name | Unique State name | string | yes |\n",
      "| type | State type | string | yes |\n",
      "| duration | Duration (ISO 8601 duration format) to sleep. For example: \"PT15M\" (sleep 15 minutes), or \"P2DT3H4M\" (sleep 2 days, 3 hours and 4 minutes) | string | yes |\n",
      "| transition | Next transition of the workflow after the sleep | string or object | yes (if end is not defined) |\n",
      "| end | Is this state an end state | boolean or object | yes (if transition is not defined) |\n",
      "```json\n",
      "{\n",
      "      \"name\": \"SleepFiveSeconds\",\n",
      "      \"type\": \"sleep\",\n",
      "      \"duration\": \"PT5S\",\n",
      "      \"transition\": \"GetJobStatus\"\n",
      "}\n",
      "```yaml\n",
      "name: SleepFiveSeconds\n",
      "type: sleep\n",
      "duration: PT5S\n",
      "transition: GetJobStatus\n",
      "Sleep state \n",
      "suspends workflow execution for a given time duration. The delay is defined in its duration property using the ISO 8601 \n",
      "duration format.\n",
      "Note that transition and end properties are mutually exclusive, meaning that you cannot define both of them at the same time.\n",
      "\n",
      "Parallel State\n",
      "branches | List of branches for this parallel state| array | yes |\n",
      "| completionType | Option types on how to complete branch execution. Default is \"allOf\" | enum | no |\n",
      "| numCompleted | Used when branchCompletionType is set to\n",
      "timeouts | State specific timeout settings | object | no |\n",
      "|\n",
      "\n",
      "stateDataFilter | State data filter | object | no |\n",
      "|\n",
      "\n",
      "onErrors | States error handling and retries definitions | array | no |\n",
      "|\n",
      "transition | Next transition of the workflow after all branches have completed execution | string or object | yes (if\n",
      "compensatedBy | Unique name of a workflow state which is responsible for compensation of this state | string | no |\n",
      "|\n",
      "\n",
      "usedForCompensation | If\n",
      "\n",
      "metadata | Metadata information| object | no |\n",
      "|\n",
      "end | Is this state an end state | boolean or object | yes (if\n",
      "```json\n",
      " {\n",
      "     \"name\":\"ParallelExec\",\n",
      "     \"type\":\"parallel\",\n",
      "     \"completionType\": \"allOf\",\n",
      "     \"branches\": [\n",
      "        {\n",
      "          \"name\": \"Branch1\",\n",
      "          \"actions\": [\n",
      "            {\n",
      "\"functionRef\": {\n",
      "                    \"refName\": \"functionNameOne\",\n",
      "                    \"arguments\": {\n",
      "                        \"order\": \"${ .someParam }\"\n",
      "                    }\n",
      "}\n",
      "            }\n",
      "        ]\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"Branch2\",\n",
      "          \"actions\": [\n",
      "              {\n",
      "                  \"functionRef\": {\n",
      "\"refName\": \"functionNameTwo\",\n",
      "                      \"arguments\": {\n",
      "                          \"order\": \"${ .someParam }\"\n",
      "                      }\n",
      "                  }\n",
      "}\n",
      "          ]\n",
      "        }\n",
      "     ],\n",
      "     \"end\": true\n",
      "}\n",
      "```yaml\n",
      "name: ParallelExec\n",
      "type: parallel\n",
      "completionType: allOf\n",
      "branches:\n",
      "- name: Branch1\n",
      "  actions:\n",
      "  - functionRef:\n",
      "      refName: functionNameOne\n",
      "      arguments:\n",
      "        order: \"${ .someParam }\"\n",
      "- name: Branch2\n",
      "  actions:\n",
      "  - functionRef:\n",
      "      refName: functionNameTwo\n",
      "      arguments:\n",
      "        order: \"${ .someParam }\"\n",
      "end: true\n",
      "Parallel state defines a collection of branches that are executed in parallel.\n",
      "A parallel state can be seen a state which splits up the current workflow instance execution path\n",
      "into multiple ones, one for each branch. These execution paths are performed in parallel\n",
      "and are joined back into the current execution path depending on the defined completionType parameter value.\n",
      "The \"completionType\" enum specifies the different ways of completing branch execution:\n",
      "allOf: All branches must complete execution before the state can transition/end. This is the default value in case this parameter is not defined in the parallel state definition.\n",
      "atLeast: State can transition/end once at least the specified number of branches have completed execution. In this case you must also\n",
      "  specify the numCompleted property to define this number.\n",
      "Exceptions may occur during execution of branches of the Parallel state, this is described in detail in this section.\n",
      "The timeouts property can be used to set state specific timeout settings. Parallel states can define the\n",
      "stateExecTimeout and branchExecTimeout timeout settings. For more information on workflow timeouts\n",
      "reference the Workflow Timeouts section.\n",
      "Note that transition and end properties are mutually exclusive, meaning that you cannot define both of them at the same time.\n",
      "\n",
      "Inject State\n",
      "\n",
      "stateDataFilter | State data filter | object | no |\n",
      "|\n",
      "transition | Next transition of the workflow after injection has completed | string or object | yes (if\n",
      "compensatedBy | Unique name of a workflow state which is responsible for compensation of this state | string | no |\n",
      "|\n",
      "\n",
      "usedForCompensation | If\n",
      "\n",
      "metadata | Metadata information| object | no |\n",
      "|\n",
      "end | Is this state an end state | boolean or object | yes (if\n",
      "\n",
      "```json\n",
      "{\n",
      "     \"name\":\"Hello\",\n",
      "     \"type\":\"inject\",\n",
      "     \"data\": {\n",
      "        \"result\": \"Hello\"\n",
      "     },\n",
      "     \"transition\": \"World\"\n",
      "}\n",
      "```yaml\n",
      "name: Hello\n",
      "type: inject\n",
      "data:\n",
      "  result: Hello\n",
      "transition: World\n",
      "Inject state can be used to inject static data into state data input. Inject state does not perform any actions.\n",
      "It is very useful for debugging, for example, as you can test/simulate workflow execution with pre-set data that would typically\n",
      "be dynamic in nature (e.g., function calls, events).\n",
      "The inject state data property allows you to statically define a JSON object which gets added to the states data input.\n",
      "You can use the filter property to control the states data output to the transition state.\n",
      "Here is a typical example of how to use the inject state to add static data into its states data input, which then is passed\n",
      "as data output to the transition state:\n",
      "```json\n",
      "  {\n",
      "   \"name\":\"SimpleInjectState\",\n",
      "   \"type\":\"inject\",\n",
      "   \"data\": {\n",
      "      \"person\": {\n",
      "        \"fname\": \"John\",\n",
      "        \"lname\": \"Doe\",\n",
      "        \"address\": \"1234 SomeStreet\",\n",
      "        \"age\": 40\n",
      "}\n",
      "   },\n",
      "   \"transition\": \"GreetPersonState\"\n",
      "  }\n",
      "```yaml\n",
      "  name: SimpleInjectState\n",
      "  type: inject\n",
      "  data:\n",
      "    person:\n",
      "      fname: John\n",
      "      lname: Doe\n",
      "      address: 1234 SomeStreet\n",
      "      age: 40\n",
      "  transition: GreetPersonState\n",
      "The data output of the \"SimpleInjectState\" which then is passed as input to the transition state would be:\n",
      "```json\n",
      "{\n",
      " \"person\": {\n",
      "      \"fname\": \"John\",\n",
      "      \"lname\": \"Doe\",\n",
      "      \"address\": \"1234 SomeStreet\",\n",
      "      \"age\": 40\n",
      " }\n",
      "}\n",
      "If the inject state already receives a data input from the previous transition state, the inject data should be merged\n",
      "with its data input.\n",
      "You can also use the filter property to filter the state data after data is injected. Let's say we have:\n",
      "```json\n",
      "  {\n",
      "     \"name\":\"SimpleInjectState\",\n",
      "     \"type\":\"inject\",\n",
      "     \"data\": {\n",
      "        \"people\": [\n",
      "          {\n",
      "             \"fname\": \"John\",\n",
      "             \"lname\": \"Doe\",\n",
      "\"address\": \"1234 SomeStreet\",\n",
      "             \"age\": 40\n",
      "          },\n",
      "          {\n",
      "             \"fname\": \"Marry\",\n",
      "             \"lname\": \"Allice\",\n",
      "             \"address\": \"1234 SomeStreet\",\n",
      "\"age\": 25\n",
      "          },\n",
      "          {\n",
      "             \"fname\": \"Kelly\",\n",
      "             \"lname\": \"Mill\",\n",
      "             \"address\": \"1234 SomeStreet\",\n",
      "             \"age\": 30\n",
      "          }\n",
      "        ]\n",
      "},\n",
      "     \"stateDataFilter\": {\n",
      "        \"output\": \"${ {people: [.people[] | select(.age < 40)]} }\"\n",
      "     },\n",
      "     \"transition\": \"GreetPersonState\"\n",
      "    }\n",
      "```yaml\n",
      "  name: SimpleInjectState\n",
      "  type: inject\n",
      "  data:\n",
      "    people:\n",
      "    - fname: John\n",
      "      lname: Doe\n",
      "      address: 1234 SomeStreet\n",
      "      age: 40\n",
      "    - fname: Marry\n",
      "      lname: Allice\n",
      "address: 1234 SomeStreet\n",
      "      age: 25\n",
      "    - fname: Kelly\n",
      "      lname: Mill\n",
      "      address: 1234 SomeStreet\n",
      "      age: 30\n",
      "  stateDataFilter:\n",
      "output: \"${ {people: [.people[] | select(.age < 40)]} }\"\n",
      "  transition: GreetPersonState\n",
      "In which case the states data output would include only people whose age is less than 40:\n",
      "json\n",
      "{\n",
      "  \"people\": [\n",
      "    {\n",
      "      \"fname\": \"Marry\",\n",
      "      \"lname\": \"Allice\",\n",
      "      \"address\": \"1234 SomeStreet\",\n",
      "      \"age\": 25\n",
      "    },\n",
      "    {\n",
      "      \"fname\": \"Kelly\",\n",
      "      \"lname\": \"Mill\",\n",
      "\"address\": \"1234 SomeStreet\",\n",
      "      \"age\": 30\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "You can change your output path easily during testing, for example change the expression to:\n",
      "\n",
      "text\n",
      "${ {people: [.people[] | select(.age >= 40)]} }\n",
      "This allows you to test if your workflow behaves properly for cases when there are people whose age is greater or equal 40.\n",
      "Note that transition and end properties are mutually exclusive, meaning that you cannot define both of them at the same time.\n",
      "\n",
      "ForEach State\n",
      "actions | Actions to be executed for each of the elements of inputCollection | array | yes |\n",
      "|\n",
      "\n",
      "timeouts | State specific timeout settings | object | no |\n",
      "|\n",
      "stateDataFilter | State data filter definition | object | no |\n",
      "|\n",
      "\n",
      "onErrors | States error handling and retries definitions | array | no |\n",
      "|\n",
      "transition | Next transition of the workflow after state has completed | string or object | yes (if\n",
      "compensatedBy | Unique name of a workflow state which is responsible for compensation of this state | string | no |\n",
      "|\n",
      "\n",
      "usedForCompensation | If\n",
      "\n",
      "metadata | Metadata information| object | no |\n",
      "|\n",
      "end | Is this state an end state | boolean or object | yes (if\n",
      "```json\n",
      "{\n",
      "    \"name\": \"ProvisionOrdersState\",\n",
      "    \"type\": \"foreach\",\n",
      "    \"inputCollection\": \"${ .orders }\",\n",
      "    \"iterationParam\": \"singleorder\",\n",
      "    \"outputCollection\": \"${ .provisionresults }\",\n",
      "\"actions\": [\n",
      "        {\n",
      "            \"functionRef\": {\n",
      "                \"refName\": \"provisionOrderFunction\",\n",
      "                \"arguments\": {\n",
      "                    \"order\": \"${ $singleorder }\"\n",
      "}\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```yaml\n",
      "name: ProvisionOrdersState\n",
      "type: foreach\n",
      "inputCollection: \"${ .orders }\"\n",
      "iterationParam: \"singleorder\"\n",
      "outputCollection: \"${ .provisionresults }\"\n",
      "actions:\n",
      "- functionRef:\n",
      "refName: provisionOrderFunction\n",
      "    arguments:\n",
      "      order: \"${ $singleorder }\"\n",
      "ForEach states can be used to execute actions for each element of a data set.\n",
      "Each iteration of the ForEach state is by default executed in parallel by default.\n",
      "However, executing iterations sequentially is also possible by setting the value of the mode property to\n",
      "sequential.\n",
      "The mode property defines if iterations should be done sequentially or in parallel. By default,\n",
      "if mode is not specified, iterations should be done in parallel.\n",
      "If the default parallel iteration mode is used, the batchSize property to the number of iterations (batch)\n",
      "that can be executed at a time. To give an example, if the number of iterations is 55 and batchSize\n",
      "is set to 10, 10 iterations are to be executed at a time, meaning that the state would execute 10 iterations in parallel,\n",
      "then execute the next batch of 10 iterations. After 5 such executions, the remaining 5 iterations are to be executed in the last batch.\n",
      "The batch size value must be greater than 1. If not specified, its value should be the size of the inputCollection (all iterations).\n",
      "The inputCollection property is a workflow expression which selects an array in the states data. All iterations\n",
      "are performed against data elements of this array. If this array does not exist, the runtime should throw\n",
      "an error. This error can be handled inside the states onErrors definition.\n",
      "The outputCollection property is a workflow expression which selects an array in the state data where the results\n",
      "of each iteration should be added to. If this array does not exist, it should be created.\n",
      "The iterationParam property defines the name of the iteration parameter passed to each iteration of the ForEach state.\n",
      "It should contain the unique element of the inputCollection array and made available to actions of the ForEach state.\n",
      "iterationParam can be accessed as an expression variable. In JQ, expression variables are prefixed by $.\n",
      "If iterationParam is not explicitly defined, runtimes should create one and populate it with the value of the unique \n",
      "iteration parameter for each iteration of the ForEach state.\n",
      "The actions property defines actions to be executed in each state iteration.\n",
      "\n",
      "Let's take a look at an example:\n",
      "\n",
      "In this example the data input to our workflow is an array of orders:\n",
      "json\n",
      "{\n",
      "    \"orders\": [\n",
      "        {\n",
      "            \"orderNumber\": \"1234\",\n",
      "            \"completed\": true,\n",
      "            \"email\": \"firstBuyer@buyer.com\"\n",
      "        },\n",
      "        {\n",
      "            \"orderNumber\": \"5678\",\n",
      "\"completed\": true,\n",
      "            \"email\": \"secondBuyer@buyer.com\"\n",
      "        },\n",
      "        {\n",
      "            \"orderNumber\": \"9910\",\n",
      "            \"completed\": false,\n",
      "\"email\": \"thirdBuyer@buyer.com\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "and our workflow is defined as:\n",
      "```json\n",
      "{\n",
      "  \"id\": \"sendConfirmWorkflow\",\n",
      "  \"name\": \"SendConfirmationForCompletedOrders\",\n",
      "  \"version\": \"1.0.0\",\n",
      "  \"specVersion\": \"0.8\",\n",
      "  \"start\": \"SendConfirmState\",\n",
      "  \"functions\": [\n",
      "  {\n",
      "\"name\": \"sendConfirmationFunction\",\n",
      "    \"operation\": \"file://confirmationapi.json#sendOrderConfirmation\"\n",
      "  }\n",
      "  ],\n",
      "  \"states\": [\n",
      "  {\n",
      "      \"name\":\"SendConfirmState\",\n",
      "      \"type\":\"foreach\",\n",
      "\"inputCollection\": \"${ [.orders[] | select(.completed == true)] }\",\n",
      "      \"iterationParam\": \"completedorder\",\n",
      "      \"outputCollection\": \"${ .confirmationresults }\",\n",
      "      \"actions\":[\n",
      "      {\n",
      "\"functionRef\": {\n",
      "         \"refName\": \"sendConfirmationFunction\",\n",
      "         \"arguments\": {\n",
      "           \"orderNumber\": \"${ $completedorder.orderNumber }\",\n",
      "\"email\": \"${ $completedorder.email }\"\n",
      "         }\n",
      "       }\n",
      "      }],\n",
      "      \"end\": true\n",
      "  }]\n",
      "}\n",
      "```yaml\n",
      "id: sendConfirmWorkflow\n",
      "name: SendConfirmationForCompletedOrders\n",
      "version: '1.0.0'\n",
      "specVersion: '0.8'\n",
      "start: SendConfirmState\n",
      "functions:\n",
      "- name: sendConfirmationFunction\n",
      "operation: file://confirmationapi.json#sendOrderConfirmation\n",
      "states:\n",
      "- name: SendConfirmState\n",
      "  type: foreach\n",
      "  inputCollection: \"${ [.orders[] | select(.completed == true)] }\"\n",
      "iterationParam: completedorder\n",
      "  outputCollection: \"${ .confirmationresults }\"\n",
      "  actions:\n",
      "  - functionRef:\n",
      "      refName: sendConfirmationFunction\n",
      "      arguments:\n",
      "orderNumber: \"${ $completedorder.orderNumber }\"\n",
      "        email: \"${ $completedorder.email }\"\n",
      "  end: true\n",
      "The workflow data input containing order information is passed to the SendConfirmState ForEach state.\n",
      "The ForEach state defines an inputCollection property which selects all orders that have the completed property set to true.\n",
      "For each element of the array selected by inputCollection a JSON object defined by iterationParam should be\n",
      "created containing an unique element of inputCollection and passed as the data input to the parallel executed actions.\n",
      "So for this example, we would have two parallel executions of the sendConfirmationFunction, the first one having data:\n",
      "json\n",
      "{\n",
      "    \"completedorder\": {\n",
      "        \"orderNumber\": \"1234\",\n",
      "        \"completed\": true,\n",
      "        \"email\": \"firstBuyer@buyer.com\"\n",
      "    }\n",
      "}\n",
      "\n",
      "and the second:\n",
      "json\n",
      "{\n",
      "    \"completedorder\": {\n",
      "        \"orderNumber\": \"5678\",\n",
      "        \"completed\": true,\n",
      "        \"email\": \"secondBuyer@buyer.com\"\n",
      "    }\n",
      "}\n",
      "The results of each parallel action execution are stored as elements in the state data array defined by the outputCollection property.\n",
      "The timeouts property can be used to set state specific timeout settings. ForEach states can define the\n",
      "stateExecTimeout and actionExecTimeout settings. For more information on workflow timeouts reference the Workflow Timeouts\n",
      "section.\n",
      "Note that transition and end properties are mutually exclusive, meaning that you cannot define both of them at the same time.\n",
      "\n",
      "Callback State\n",
      "action | Defines the action to be executed | object | yes |\n",
      "| eventRef | References an unique callback event name in the defined workflow\n",
      "\n",
      "events | string | yes |\n",
      "|\n",
      "timeouts | State specific timeout settings | object | no |\n",
      "|\n",
      "\n",
      "eventDataFilter | Callback event data filter definition | object | no |\n",
      "|\n",
      "stateDataFilter | State data filter definition | object | no |\n",
      "|\n",
      "\n",
      "onErrors | States error handling and retries definitions | array | no |\n",
      "|\n",
      "transition | Next transition of the workflow after callback event has been received | string or object | yes (if\n",
      "\n",
      "end | Is this state an end state | boolean or object | yes (if\n",
      "compensatedBy | Uniaue name of a workflow state which is responsible for compensation of this state | string | no |\n",
      "|\n",
      "\n",
      "usedForCompensation | If\n",
      "\n",
      "metadata | Metadata information| object | no |\n",
      "```json\n",
      "{\n",
      "        \"name\": \"CheckCredit\",\n",
      "        \"type\": \"callback\",\n",
      "        \"action\": {\n",
      "            \"functionRef\": {\n",
      "                \"refName\": \"callCreditCheckMicroservice\",\n",
      "\"arguments\": {\n",
      "                    \"customer\": \"${ .customer }\"\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"eventRef\": \"CreditCheckCompletedEvent\",\n",
      "        \"timeouts\": {\n",
      "\"stateExecTimeout\": \"PT15M\"\n",
      "        },\n",
      "        \"transition\": \"EvaluateDecision\"\n",
      "}\n",
      "```yaml\n",
      "name: CheckCredit\n",
      "type: callback\n",
      "action:\n",
      "  functionRef:\n",
      "    refName: callCreditCheckMicroservice\n",
      "    arguments:\n",
      "      customer: \"${ .customer }\"\n",
      "eventRef: CreditCheckCompletedEvent\n",
      "timeouts:\n",
      "stateExecTimeout: PT15M\n",
      "transition: EvaluateDecision\n",
      "Serverless orchestration can at times require manual steps/decisions to be made. While some work performed\n",
      "in a serverless workflow can be executed automatically, some decisions must involve manual steps (e.g., human decisions).\n",
      "The Callback state allows you to explicitly model manual decision steps during workflow execution.\n",
      "The action property defines a function call that triggers an external activity/service. Once the action executes,\n",
      "the callback state will wait for a CloudEvent (defined via the eventRef property), which indicates the completion\n",
      "of the manual decision by the called service.\n",
      "Note that the called decision service is responsible for emitting the callback CloudEvent indicating the completion of the\n",
      "decision and including the decision results as part of the event payload. This event must be correlated to the\n",
      "workflow instance using the callback events context attribute defined in the correlation property of the\n",
      "referenced Event Definition.\n",
      "Once the completion (callback) event is received, the Callback state completes its execution and transitions to the next\n",
      "defined workflow state or completes workflow execution in case it is an end state.\n",
      "The callback event payload is merged with the Callback state data and can be filtered via the \"eventDataFilter\" definition.\n",
      "If the defined callback event has not been received during this time period, the state should transition to the next state or end workflow execution if it is an end state.\n",
      "The timeouts property defines state specific timeout settings. Callback states can define the\n",
      "stateExecTimeout, actionExecTimeout, and eventTimeout properties.\n",
      "For more information on workflow timeouts reference the Workflow Timeouts\n",
      "section.\n",
      "Note that transition and end properties are mutually exclusive, meaning that you cannot define both of them at the same time.\n",
      "\n",
      "Related State Definitions\n",
      "\n",
      "Function Definition\n",
      "| Parameter | Description | Type | Required |\n",
      "| --- | --- | --- | --- |\n",
      "| name | Unique function name | string | yes |\n",
      "| operation | If type is rest, #. If type is asyncapi, #. If type is rpc, ##. If type is graphql, ##. If type is odata, #. If type is expression, defines the workflow expression. | string | yes |\n",
      "| type | Defines the function type. Can be either rest, asyncapi, rpc, graphql, odata, expression, or custom. Default is rest | enum | no |\n",
      "| authRef | References an auth definition name to be used to access to resource defined in the operation parameter | string | no |\n",
      "| metadata | Metadata information. Can be used to define custom function information | object | no |\n",
      "```json\n",
      "{\n",
      "   \"name\": \"HelloWorldFunction\",\n",
      "   \"operation\": \"https://hellworldservice.api.com/api.json#helloWorld\"\n",
      "}\n",
      "```yaml\n",
      "name: HelloWorldFunction\n",
      "operation: https://hellworldservice.api.com/api.json#helloWorld\n",
      "The name property defines an unique name of the function definition.\n",
      "\n",
      "The type property defines the function type. Its value can be either rest or expression. Default value is rest.\n",
      "Depending on the function type, the operation property can be:\n",
      "If type is rest, a combination of the function/service OpenAPI definition document URI and the particular service operation that needs to be invoked, separated by a '#'.\n",
      "For example https://petstore.swagger.io/v2/swagger.json#getPetById.\n",
      "If type is asyncapi, a combination of the AsyncApi definition document URI and the particular service operation that needs to be invoked, separated by a '#'.\n",
      "For example file://streetlightsapi.yaml#onLightMeasured.\n",
      "If type is rpc, a combination of the gRPC proto document URI and the particular service name and service method name that needs to be invoked, separated by a '#'.\n",
      "For example file://myuserservice.proto#UserService#ListUsers.\n",
      "If type is graphql, a combination of the GraphQL schema definition URI and the particular service name and service method name that needs to be invoked, separated by a '#'.\n",
      "For example file://myuserservice.proto#UserService#ListUsers.\n",
      "If type is odata, a combination of the GraphQL schema definition URI and the particular service name and service method name that needs to be invoked, separated by a '#'.\n",
      "For example https://services.odata.org/V3/OData/OData.svc#Products.\n",
      "If type is expression, defines the expression syntax. Take a look at the workflow expressions section for more information on this.\n",
      "Defining custom function types is possible, for more information on that refer to the Defining custom function types section.\n",
      "The authRef property references a name of a defined workflow auth definition.\n",
      "It is used to provide authentication info to access the resource defined in the operation property and/or to invoke the function.\n",
      "The metadata property allows users to define custom information to function definitions.\n",
      "This allows you for example to define functions that describe of a command executions on a Docker image:\n",
      "yaml\n",
      "functions:\n",
      "- name: whalesayimage\n",
      "  metadata:\n",
      "    image: docker/whalesay\n",
      "    command: cowsay\n",
      "Note that using metadata for cases such as above heavily reduces the portability of your workflow markup.\n",
      "Function definitions themselves do not define data input parameters. Parameters can be\n",
      "defined via the parameters property in function definitions inside actions.\n",
      "\n",
      "AuthRef Definition\n",
      "| Parameter | Description | Type | Required |\n",
      "| --- | --- | --- | --- |\n",
      "| resource | References an auth definition to be used to access the resource defined in the operation parameter | string | yes |\n",
      "| invocation | References an auth definition to be used to invoke the operation | string | no |\n",
      "The authRef property references a name of a defined workflow auth definition. It can be a string or an object.\n",
      "If it's a string, the referenced auth definition is used solely for the function's invocation.\n",
      "If it's an object, it is possible to specify an auth definition to use for the function's resource retrieval (as defined by the operation property) and another for its invocation.\n",
      "Example of a function definition configured to use an auth definition called \"My Basic Auth\" upon invocation:\n",
      "yaml\n",
      "functions:\n",
      "- name: SecuredFunctionInvocation\n",
      "  operation: https://test.com/swagger.json#HelloWorld\n",
      "  authRef: My Basic Auth\n",
      "Example of a function definition configured to use an auth definition called \"My Basic Auth\" to retrieve the resource defined by the operation property, and an auth definition called \"My OIDC Auth\"\n",
      "upon invocation:\n",
      "yaml\n",
      "functions:\n",
      "- name: SecuredFunctionInvocation\n",
      "  operation: https://test.com/swagger.json#HelloWorld\n",
      "  authRef:\n",
      "    resource: My Basic Auth\n",
      "    invocation: My OIDC Auth\n",
      "Note that if multiple functions share the same operation path (which is the first component of the operation value, located before the first '#' character), and if one of them defines an auth\n",
      "definition for resource access, then it should always be used to access said resource.\n",
      "In other words, when retrieving the resource of the function \"MySecuredFunction2\" defined in the following example, the \"My Api Key Auth\" auth definition should be used, because the\n",
      "\"MySecuredFunction1\" has defined it for resource access.\n",
      "This is done to avoid unnecessary repetitions of auth definition configuration when using the same resource for multiple defined functions.\n",
      "yaml\n",
      "functions:\n",
      "  - name: MySecuredFunction1\n",
      "    operation: https://secure.resources.com/myapi.json#helloWorld\n",
      "    authRef:\n",
      "      resource: My ApiKey Auth \n",
      "  - name: MySecuredFunction2\n",
      "operation: https://secure.resources.com/myapi.json#holaMundo\n",
      "It's worth noting that if an auth definition has been defined for an OpenAPI function which's resource declare an authentication mechanism, the later should be used instead, thus ignoring entirely the\n",
      "auth definition.\n",
      "Event Definition\n",
      "\n",
      "CloudEvent spec constraints)| string | yes (if\n",
      "\n",
      "correlation | Define event correlation rules for this event. Only used for consumed events | array | no |\n",
      "| dataOnly | If\n",
      "metadata | Metadata information | object | no |\n",
      "```json\n",
      "{\n",
      "   \"name\": \"ApplicantInfo\",\n",
      "   \"type\": \"org.application.info\",\n",
      "   \"source\": \"applicationssource\",\n",
      "   \"kind\": \"consumed\",\n",
      "   \"correlation\": [\n",
      "    {\n",
      "      \"contextAttributeName\": \"applicantId\"\n",
      "}\n",
      "   ]\n",
      "}\n",
      "```yaml\n",
      "name: ApplicantInfo\n",
      "type: org.application.info\n",
      "source: applicationssource\n",
      "kind: consumed\n",
      "correlation:\n",
      "- contextAttributeName: applicantId\n",
      "Used to define events and their correlations. These events can be either consumed or produced during workflow execution as well\n",
      "as can be used to trigger function/service invocations.\n",
      "The Serverless Workflow specification mandates that all events conform to the CloudEvents specification.\n",
      "This is to assure consistency and portability of the events format used.\n",
      "The name property defines a single name of the event that is unique inside the workflow definition. This event name can be\n",
      "then referenced within function and state definitions.\n",
      "The source property matches this event definition with the source\n",
      "property of the CloudEvent required attributes.\n",
      "The type property matches this event definition with the type property of the CloudEvent required attributes.\n",
      "Event correlation plays a big role in large event-driven applications. Correlating one or more events with a particular workflow instance\n",
      "can be done by defining the event correlation rules within the correlation property.\n",
      "This property is an array of correlation definitions.\n",
      "The CloudEvents specification allows users to add Extension Context Attributes\n",
      "and the correlation definitions can use these attributes to define clear matching event correlation rules.\n",
      "Extension context attributes are not part of the event payload, so they are serialized the same way as other standard required attributes.\n",
      "This means that the event payload does not have to be inspected by implementations in order to read and evaluate the defined correlation rules.\n",
      "Let's take a look at an example. Here we have two events that have an extension context attribute called \"patientId\" (as well as \"department\", which\n",
      "will be used in further examples below):\n",
      "json\n",
      "{\n",
      "    \"specversion\" : \"1.0\",\n",
      "    \"type\" : \"com.hospital.patient.heartRateMonitor\",\n",
      "    \"source\" : \"hospitalMonitorSystem\",\n",
      "    \"subject\" : \"HeartRateReading\",\n",
      "    \"id\" : \"A234-1234-1234\",\n",
      "\"time\" : \"2020-01-05T17:31:00Z\",\n",
      "    \"patientId\" : \"PID-12345\",\n",
      "    \"department\": \"UrgentCare\",\n",
      "    \"data\" : {\n",
      "      \"value\": \"80bpm\"\n",
      "    }\n",
      "}\n",
      "and\n",
      "json\n",
      "{\n",
      "    \"specversion\" : \"1.0\",\n",
      "    \"type\" : \"com.hospital.patient.bloodPressureMonitor\",\n",
      "    \"source\" : \"hospitalMonitorSystem\",\n",
      "    \"subject\" : \"BloodPressureReading\",\n",
      "    \"id\" : \"B234-1234-1234\",\n",
      "\"time\" : \"2020-02-05T17:31:00Z\",\n",
      "    \"patientId\" : \"PID-12345\",\n",
      "    \"department\": \"UrgentCare\",\n",
      "    \"data\" : {\n",
      "      \"value\": \"110/70\"\n",
      "    }\n",
      "}\n",
      "We can then define a correlation rule, through which all consumed events with the \"hospitalMonitorSystem\", and the \"com.hospital.patient.heartRateMonitor\"\n",
      "type that have the same value of the patientId property to be correlated to the created workflow instance:\n",
      "json\n",
      "{\n",
      "\"events\": [\n",
      " {\n",
      "  \"name\": \"HeartRateReadingEvent\",\n",
      "  \"source\": \"hospitalMonitorSystem\",\n",
      "  \"type\": \"com.hospital.patient.heartRateMonitor\",\n",
      "  \"kind\": \"consumed\",\n",
      "  \"correlation\": [\n",
      "    {\n",
      "\"contextAttributeName\": \"patientId\"\n",
      "    }\n",
      "  ]\n",
      " }\n",
      "]\n",
      "}\n",
      "If a workflow instance is created (e.g., via Event state) by consuming a \"HeartRateReadingEvent\" event, all other consumed events\n",
      "from the defined source and with the defined type that have the same \"patientId\" as the event that triggered the workflow instance\n",
      "should then also be associated with the same instance.\n",
      "You can also correlate multiple events together. In the following example, we assume that the workflow consumes two different event types,\n",
      "and we want to make sure that both are correlated, as in the above example, with the same \"patientId\":\n",
      "json\n",
      "{\n",
      "\"events\": [\n",
      " {\n",
      "  \"name\": \"HeartRateReadingEvent\",\n",
      "  \"source\": \"hospitalMonitorSystem\",\n",
      "  \"type\": \"com.hospital.patient.heartRateMonitor\",\n",
      "  \"kind\": \"consumed\",\n",
      "  \"correlation\": [\n",
      "    {\n",
      "\"contextAttributeName\": \"patientId\"\n",
      "    }\n",
      "  ]\n",
      " },\n",
      " {\n",
      "   \"name\": \"BloodPressureReadingEvent\",\n",
      "   \"source\": \"hospitalMonitorSystem\",\n",
      "   \"type\": \"com.hospital.patient.bloodPressureMonitor\",\n",
      "\"kind\": \"consumed\",\n",
      "   \"correlation\": [\n",
      "       {\n",
      "         \"contextAttributeName\": \"patientId\"\n",
      "       }\n",
      "     ]\n",
      "  }\n",
      "]\n",
      "}\n",
      "Event correlation can be based on equality (values of the defined \"contextAttributeName\" must be equal), but it can also be based\n",
      "on comparing it to custom defined values (string, or expression). For example:\n",
      "json\n",
      "{\n",
      "\"events\": [\n",
      " {\n",
      "  \"name\": \"HeartRateReadingEvent\",\n",
      "  \"source\": \"hospitalMonitorSystem\",\n",
      "  \"type\": \"com.hospital.patient.heartRateMonitor\",\n",
      "  \"kind\": \"consumed\",\n",
      "  \"correlation\": [\n",
      "    {\n",
      "\"contextAttributeName\": \"patientId\"\n",
      "    },\n",
      "    {\n",
      "      \"contextAttributeName\": \"department\",\n",
      "      \"contextAttributeValue\" : \"UrgentCare\"\n",
      "    }\n",
      "  ]\n",
      " }\n",
      "]\n",
      "}\n",
      "In this example, we have two correlation rules defined: The first one is on the \"patientId\" CloudEvent context attribute, meaning again that\n",
      "all consumed events from this source and type must have the same \"patientId\" to be considered. The second rule\n",
      "says that these events must all have a context attribute named \"department\" with the value of \"UrgentCare\".\n",
      "This allows developers to write orchestration workflows that are specifically targeted to patients that are in the hospital urgent care unit,\n",
      "for example.\n",
      "The dataOnly property deals with what Event data is accessible by the consuming Workflow states.\n",
      "If its value is true (default value), only the Event payload is accessible to consuming Workflow states.\n",
      "If false, both Event payload and context attributes should be accessible.\n",
      "Auth Definition\n",
      "Auth definitions can be used to define authentication information that should be applied to function definitions.\n",
      "It can be used for both the retrieval of the function's resource (as defined by the operation property) and for the function's invocation.\n",
      "| Parameter | Description | Type | Required |\n",
      "| --- | --- | --- | --- |\n",
      "| name | Unique auth definition name | string | yes |\n",
      "| scheme | Auth scheme, can be \"basic\", \"bearer\", or \"oauth2\". Default is \"basic\" | enum | no |\n",
      "| properties | Auth scheme properties. Can be one of \"Basic properties definition\", \"Bearer properties definition\", or \"OAuth2 properties definition\" | object | yes |\n",
      "\"Basic properties definition\",\n",
      "\n",
      "\"Bearer properties definition\", or\n",
      "\n",
      "\"OAuth2 properties definition\"\n",
      "\n",
      "Basic Properties Definition\n",
      "\n",
      "See here for more information about Basic Authentication scheme.\n",
      "The Basic properties definition can have two types, either string or object. \n",
      "If string type, it defines a workflow expression that contains all needed Basic auth information.\n",
      "If object type, it has the following properties:\n",
      "| Parameter | Description | Type | Required |\n",
      "| --- | --- | --- | --- |\n",
      "| username | String or a workflow expression. Contains the user name | string | yes |\n",
      "| password | String or a workflow expression. Contains the user password | string | yes |\n",
      "| metadata | Metadata information| object | no |\n",
      "Bearer Properties Definition\n",
      "\n",
      "See here for more information about Bearer Authentication scheme.\n",
      "| Parameter | Description | Type | Required |\n",
      "| --- | --- | --- | --- |\n",
      "| token | String or a workflow expression. Contains the token information | string | yes |\n",
      "| metadata | Metadata information| object | no |\n",
      "OAuth2 Properties Definition\n",
      "\n",
      "See here for more information about OAuth2 Authentication scheme.\n",
      "| Parameter | Description | Type | Required |\n",
      "| --- | --- | --- | --- |\n",
      "| authority | String or a workflow expression. Contains the authority information | string | no |\n",
      "| grantType | Defines the grant type. Can be \"password\", \"clientCredentials\", or \"tokenExchange\" | enum | yes |\n",
      "| clientId | String or a workflow expression. Contains the client identifier | string | yes |\n",
      "| clientSecret | Workflow secret or a workflow expression. Contains the client secret | string | no |\n",
      "| scopes | Array containing strings or workflow expressions. Contains the OAuth2 scopes | array | no |\n",
      "| username | String or a workflow expression. Contains the user name. Used only if grantType is 'resourceOwner' | string | no |\n",
      "| password | String or a workflow expression. Contains the user password. Used only if grantType is 'resourceOwner' | string | no |\n",
      "| audiences | Array containing strings or workflow expressions. Contains the OAuth2 audiences | array | no |\n",
      "| subjectToken | String or a workflow expression. Contains the subject token | string | no |\n",
      "| requestedSubject | String or a workflow expression. Contains the requested subject | string | no |\n",
      "| requestedIssuer | String or a workflow expression. Contains the requested issuer | string | no |\n",
      "| metadata | Metadata information| object | no |\n",
      "Correlation Definition\n",
      "| Parameter | Description | Type | Required |\n",
      "| --- | --- | --- | --- |\n",
      "| contextAttributeName | CloudEvent Extension Context Attribute name | string | yes |\n",
      "| contextAttributeValue | CloudEvent Extension Context Attribute value | string  | no |\n",
      "```json\n",
      "{\n",
      "   \"correlation\": [\n",
      "       {\n",
      "         \"contextAttributeName\": \"patientId\"\n",
      "       },\n",
      "       {\n",
      "         \"contextAttributeName\": \"department\",\n",
      "         \"contextAttributeValue\" : \"UrgentCare\"\n",
      "}\n",
      "     ]\n",
      "}\n",
      "```yaml\n",
      "correlation:\n",
      "- contextAttributeName: patientId\n",
      "- contextAttributeName: department\n",
      "  contextAttributeValue: UrgentCare\n",
      "Used to define event correlation rules. Only usable for consumed event definitions.\n",
      "The contextAttributeName property defines the name of the CloudEvent extension context attribute.\n",
      "The contextAttributeValue property defines the value of the defined CloudEvent extension context attribute.\n",
      "OnEvents Definition\n",
      "| Parameter | Description | Type | Required |\n",
      "| --- | --- | --- | --- |\n",
      "| eventRefs | References one or more unique event names in the defined workflow events | array | yes |\n",
      "| actionMode | Specifies how actions are to be performed (in sequence or in parallel). Default is sequential | enum | no |\n",
      "| actions | Actions to be performed | array | no |\n",
      "| eventDataFilter | Event data filter definition | object | no |\n",
      "```json\n",
      "{\n",
      "    \"eventRefs\": [\"HighBodyTemperature\"],\n",
      "    \"actions\": [{\n",
      "        \"functionRef\": {\n",
      "            \"refName\": \"sendTylenolOrder\",\n",
      "            \"arguments\": {\n",
      "\"patientid\": \"${ .patientId }\"\n",
      "            }\n",
      "        }\n",
      "    }]\n",
      "}\n",
      "```yaml\n",
      "eventRefs:\n",
      "- HighBodyTemperature\n",
      "actions:\n",
      "- functionRef:\n",
      "    refName: sendTylenolOrder\n",
      "    arguments:\n",
      "      patientid: \"${ .patientId }\"\n",
      "OnEvent definition allow you to define which actions are to be performed\n",
      "for the one or more events definitions defined in the eventRefs array.\n",
      "Note that the values of eventRefs array must be unique.\n",
      "The actionMode property defines if the defined actions need to be performed sequentially or in parallel.\n",
      "\n",
      "The actions property defines a list of actions to be performed.\n",
      "When specifying the onEvents definition it is important to consider the Event states exclusive property,\n",
      "because it determines how 'onEvents' is interpreted.\n",
      "Let's look at the following JSON definition of 'onEvents' to show this:\n",
      "json\n",
      "{\n",
      "    \"onEvents\": [{\n",
      "        \"eventRefs\": [\"HighBodyTemperature\", \"HighBloodPressure\"],\n",
      "        \"actions\": [{\n",
      "                \"functionRef\": {\n",
      "                    \"refName\": \"SendTylenolOrder\",\n",
      "\"arguments\": {\n",
      "                        \"patient\": \"${ .patientId }\"\n",
      "                    }\n",
      "                }\n",
      "            },\n",
      "            {\n",
      "                \"functionRef\": {\n",
      "\"refName\": \"CallNurse\",\n",
      "                    \"arguments\": {\n",
      "                        \"patient\": \"${ .patientId }\"\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        ]\n",
      "}]\n",
      "}\n",
      "Depending on the value of the Event states exclusive property, this definition can mean two different things:\n",
      "If exclusive is set to true, the consumption of either the HighBodyTemperature or HighBloodPressure events will trigger action execution.\n",
      "If exclusive is set to false, the consumption of both the HighBodyTemperature and HighBloodPressure events will trigger action execution.\n",
      "\n",
      "This is visualized in the diagram below:\n",
      "\n",
      "Action Definition\n",
      "functionRef | References a reusable function definition | object or string | yes (if\n",
      "\n",
      "eventRef | References a\n",
      "\n",
      "subFlowRef | References a workflow to be invoked | object or string | yes (if\n",
      "retryRef | References a defined workflow retry definition. If not defined uses the default runtime retry definition | string | no |\n",
      "| nonRetryableErrors | List of references to defined\n",
      "workflow errors for which the action should not be retried. Used only when\n",
      "\n",
      "workflow errors for which the action should be retried. Used only when\n",
      "actionDataFilter | Action data filter definition | object | no |\n",
      "| sleep | Defines time periods workflow execution should sleep before / after function execution | object | no |\n",
      "|\n",
      "condition | Expression, if defined, must evaluate to\n",
      "```json\n",
      "{\n",
      "    \"name\": \"Finalize Application Action\",\n",
      "    \"functionRef\": {\n",
      "        \"refName\": \"finalizeApplicationFunction\",\n",
      "        \"arguments\": {\n",
      "            \"applicantid\": \"${ .applicantId }\"\n",
      "}\n",
      "    }\n",
      "}\n",
      "```yaml\n",
      "name: Finalize Application Action\n",
      "functionRef:\n",
      "  refName: finalizeApplicationFunction\n",
      "  arguments:\n",
      "    applicantid: \"${ .applicantId }\"\n",
      "Actions specify invocations of services or other workflows during workflow execution.\n",
      "Service invocation can be done in three different ways:\n",
      "Reference functions definitions by its unique name using the functionRef property.\n",
      "\n",
      "Reference a produced and consumed event definitions via the eventRef property.\n",
      "Reference a sub-workflow invocation via the subFlowRef property.\n",
      "Note that functionRef, eventRef, and subFlowRef are mutually exclusive, meaning that only one of them can be\n",
      "specified in a single action definition.\n",
      "The name property specifies the action name.\n",
      "The id property specifies the unique action id.\n",
      "In the event-based scenario a service, or a set of services we want to invoke\n",
      "are not exposed via a specific resource URI for example, but can only be invoked via an event.\n",
      "The eventRef property defines the\n",
      "referenced produced event via its produceEventRef property and a consumed event via its consumeEventRef property.\n",
      "The sleep property can be used to define time periods that workflow execution should sleep\n",
      "before and/or after function execution. It can have two properties:\n",
      "* before - defines the amount of time (ISO 8601 duration format) to sleep before function invocation.\n",
      "* after - defines the amount of time (ISO 8601 duration format) to sleep after function invocation.\n",
      "Function invocation timeouts should be handled via the states timeouts definition.\n",
      "The retryRef property references one of the defined workflow retries by it's unique name. If not set, the action\n",
      "should be retried according to the default retry policy of the runtime implementation. For more information about workflow\n",
      "retries reference this section.\n",
      "The nonRetryableErrors property is a list that references one or more unique names of workflow error definitions. \n",
      "This is the list of known errors for which the action should not be retried for.\n",
      "It should be used only when the workflow top-level autoRetries property is set to true.\n",
      "The retryableErrors property is a list that references one or more unique names of workflow error definitions.\n",
      "This is the list of known errors for which the action should be retried for.\n",
      "It should be used only when the workflow top-level autoRetries property is set to false.\n",
      "The condition property is a workflow expression. If defined, it must evaluate to true\n",
      "for this action to be performed. If it evaluates to false the action is skipped.\n",
      "If the condition property is not defined, the action is always performed.\n",
      "Subflow Action\n",
      "\n",
      "Often you want to group your workflows into small logical units that solve a particular business problem and can be reused in\n",
      "multiple other workflow definitions.\n",
      "Reusable workflows are referenced by their id property via the SubFlow action workflowId parameter.\n",
      "For the simple case, subFlowRef can be a string containing the id of the sub-workflow to invoke.\n",
      "If you want to specify other parameters then a subFlowRef should be provided instead.\n",
      "Each referenced workflow receives the SubFlow actions data as workflow data input.\n",
      "\n",
      "Referenced sub-workflows must declare their own function and event definitions.\n",
      "\n",
      "FunctionRef Definition\n",
      "FunctionRef definition can have two types, either string or object.\n",
      "If string type, it defines the name of the referenced function.\n",
      "This can be used as a short-cut definition when you don't need to define any other parameters, for example:\n",
      "json\n",
      "\"functionRef\": \"myFunction\"\n",
      "\n",
      "Note that if used with string type, the invocation of the function is synchronous.\n",
      "If you need to define parameters in your functionRef definition, you can define\n",
      "it with its object type which has the following properties:\n",
      "function | string | yes |\n",
      "| arguments | Arguments (inputs) to be passed to the referenced function | object | yes (if function type is\n",
      "\n",
      "selection set | string | yes (if function type is\n",
      "```json\n",
      "{\n",
      "    \"refName\": \"finalizeApplicationFunction\",\n",
      "    \"arguments\": {\n",
      "        \"applicantid\": \"${ .applicantId }\"\n",
      "    }\n",
      "}\n",
      "```yaml\n",
      "refName: finalizeApplicationFunction\n",
      "arguments:\n",
      "  applicantid: \"${ .applicantId }\"\n",
      "The refName property is the name of the referenced function.\n",
      "The arguments property defines the arguments that are to be passed to the referenced function.\n",
      "Here is an example of using the arguments property:\n",
      "json\n",
      "{\n",
      "   \"refName\": \"checkFundsAvailabe\",\n",
      "   \"arguments\": {\n",
      "     \"account\": {\n",
      "       \"id\": \"${ .accountId }\"\n",
      "     },\n",
      "     \"forAmount\": \"${ .payment.amount }\",\n",
      "\"insufficientMessage\": \"The requested amount is not available.\"\n",
      "   }\n",
      "}\n",
      "The invoke property defines how the function is invoked (sync or async). Default value of this property is\n",
      "sync, meaning that workflow execution should wait until the function completes.\n",
      "If set to async, workflow execution should just invoke the function and should not wait until its completion.\n",
      "Note that in this case the action does not produce any results and the associated actions actionDataFilter as well as \n",
      "its retry definition, if defined, should be ignored.\n",
      "In addition, functions that are invoked async do not propagate their errors to the associated action definition and the\n",
      "workflow state, meaning that any errors that happen during their execution cannot be handled in the workflow states\n",
      "onErrors definition. Note that errors raised during functions that are invoked async should not fail workflow execution.\n",
      "EventRef Definition\n",
      "\n",
      "Allows defining invocation of a function via event.\n",
      "\n",
      "produceEventRef | Reference to the unique name of a\n",
      "\n",
      "consumeEventRef | Reference to the unique name of a\n",
      "actionExecutionTimeout | string | no |\n",
      "| data | If string type, an expression which selects parts of the states data output to become the data (payload) of the event referenced by\n",
      "```json\n",
      "{\n",
      "   \"eventRef\": {\n",
      "      \"produceEventRef\": \"MakeVetAppointment\",\n",
      "      \"data\": \"${ .patientInfo }\",\n",
      "      \"consumeEventRef\":  \"VetAppointmentInfo\"\n",
      "   }\n",
      "}\n",
      "```yaml\n",
      "eventRef:\n",
      "  produceEventRef: MakeVetAppointment\n",
      "  data: \"${ .patientInfo }\"\n",
      "  consumeEventRef: VetAppointmentInfo\n",
      "References a produced and consumed event definitions via the produceEventRef and consumeEventRef properties, respectively.\n",
      "The data property can have two types: string or object. If it is of string type, it is an expression that can select parts of state data\n",
      "to be used as payload of the event referenced by produceEventRef. If it is of object type, you can define a custom object to be the event payload.\n",
      "The contextAttributes property allows you to add one or more extension context attributes\n",
      "to the trigger/produced event.\n",
      "\n",
      "actionExecutionTimeout.\n",
      "If the event defined by the\n",
      "The invoke property defines how the function is invoked (sync or async). Default value of this property is\n",
      "sync, meaning that workflow execution should wait until the function completes (the result event is received).\n",
      "If set to async, workflow execution should just produce the trigger event and should not wait for the result event.\n",
      "Note that in this case the action does not produce any results (payload of the result event) and the associated actions eventDataFilter as well as\n",
      "its retry definition, if defined, should be ignored.\n",
      "Functions that are invoked via events (sync or async) do not propagate their errors to the associated action definition and the\n",
      "workflow state, meaning that any errors that happen during their execution cannot be handled in the workflow states\n",
      "onErrors definition. Note that errors raised during functions that are invoked sync or async in this case\n",
      "should not fail workflow execution.\n",
      "SubFlowRef Definition\n",
      "\n",
      "SubFlowRef definition can have two types, namely string or object.\n",
      "If string type, it defines the unique id of the sub-workflow to be invoked.\n",
      "This short-hand definition can be used if sub-workflow lookup is done only by its id\n",
      "property and not its version property.\n",
      "json\n",
      "\"subFlowRef\": \"mySubFlowId\"\n",
      "\n",
      "If you need to define the version properties, you can use its object type:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"workflowId\": \"handleApprovedVisaWorkflowID\",\n",
      "    \"version\": \"2.0.0\"\n",
      "}\n",
      "```yaml\n",
      "workflowId: handleApprovedVisaWorkflowID\n",
      "version: '2.0.0'\n",
      "The workflowId property define the unique ID of the sub-workflow to be invoked.\n",
      "Usually, the workflow id should not be the same id of the workflow where the action is defined. Otherwise, it may occur undesired recurring calls to the same workflow.\n",
      "The version property defined the unique version of the sub-workflow to be invoked.\n",
      "If this property is defined, runtimes should match both the id and the version properties\n",
      "defined in the sub-workflow definition.\n",
      "The invoke property defines how the subflow is invoked (sync or async). Default value of this property is\n",
      "sync, meaning that workflow execution should wait until the subflow completes.\n",
      "If set to async, workflow execution should just invoke the subflow and not wait for its results.\n",
      "Note that in this case the action does not produce any results, and the associated actions actionDataFilter as well as\n",
      "its retry definition, if defined, should be ignored.\n",
      "Subflows that are invoked async do not propagate their errors to the associated action definition and the\n",
      "workflow state, meaning that any errors that happen during their execution cannot be handled in the workflow states\n",
      "onErrors definition. Note that errors raised during subflows that are invoked async\n",
      "should not fail workflow execution.\n",
      "The onParentComplete property defines how subflow execution that is invoked async should behave if the parent workflow \n",
      "completes execution before the subflow completes its own execution.\n",
      "The default value of this property is terminate, meaning that if the parent workflow (the workflow that invoked the subflow)\n",
      "completes, execution of the subflow should be terminated.\n",
      "If it is set to continue, if the parent workflow completes, the subflow execution is allowed to continue its own execution.\n",
      "Error Definition\n",
      "| Parameter | Description | Type | Required |\n",
      "| --- | --- | --- | --- |\n",
      "| errorRef or errorRefs | Reference one unique workflow error definition, or multiple unique workflow error definitions | string (errorRef) or array (errorRefs) | yes |\n",
      "| transition | Transition to next state to handle the error | string or object | yes (if end is not defined) |\n",
      "| end | End workflow execution if this error is encountered | boolean or object | yes (if transition is not defined) |\n",
      "```json\n",
      "{\n",
      "   \"errorRef\": \"Item not in inventory\",\n",
      "   \"transition\": \"IssueRefundToCustomer\"\n",
      "}\n",
      "```yaml\n",
      "errorRef: Item not in inventory\n",
      "transition: IssueRefundToCustomer\n",
      "Error definitions describe checked errors that can occur during workflow execution and how to handle them.\n",
      "The errorRef property references the unique workflow error definition. For more info on workflow error handling\n",
      "referece this section.\n",
      "The errorRefsproperty references at least one of the defined workflow error definitions.\n",
      "Can be used when errorRef is not used. Usable when you want to define multiple error refs for which the same transition\n",
      "or end definition should be applied.For more info on workflow error handling\n",
      "referece this section.\n",
      "Note that the errorRef and errorRefs properties are mutually exclusive, meaning that you can only specify one or the other,\n",
      "but not both at the same time.\n",
      "The transition property defines the transition to the next workflow state in cases when the defined\n",
      "error happens during runtime execution.\n",
      "If transition is not defined you can also define the end property which will end workflow execution at that point.\n",
      "Note that the transition and end properties are mutually exclusive, meaning that you can only specify one or the other,\n",
      "but not both at the same time.\n",
      "For more information, see the Workflow Error Handling sections.\n",
      "\n",
      "Retry Definition\n",
      "| Parameter | Description | Type | Required |\n",
      "| --- | --- | --- | --- |\n",
      "| name | Unique retry strategy name | string | yes |\n",
      "| delay | Time delay between retry attempts (ISO 8601 duration format) | string | no |\n",
      "| maxAttempts | Maximum number of retry attempts. Value of 1 means no retries are performed | string or number | yes |\n",
      "| maxDelay | Maximum amount of delay between retry attempts (ISO 8601 duration format) | string | no |\n",
      "| increment | Static duration which will be added to the delay between successive retries (ISO 8601 duration format) | string | no |\n",
      "| multiplier | Float value by which the delay is multiplied before each attempt. For example: \"1.2\" meaning that each successive delay is 20% longer than the previous delay.  For example, if delay is\n",
      "'PT10S', then the delay between the first and second attempts will be 10 seconds, and the delay before the third attempt will be 12 seconds. | float or string | no |\n",
      "| jitter | If float type, maximum amount of random time added or subtracted from the delay between each retry relative to total delay (between 0.0 and 1.0). If string type, absolute maximum amount of\n",
      "random time added or subtracted from the delay between each retry (ISO 8601 duration format) | float or string | no |\n",
      "```json\n",
      "{\n",
      "   \"name\": \"TimeoutRetryStrat\",\n",
      "   \"delay\": \"PT2M\",\n",
      "   \"maxAttempts\": 3,\n",
      "   \"jitter\": \"PT0.001S\"\n",
      "}\n",
      "```yaml\n",
      "name: TimeoutRetryStrat\n",
      "delay: PT2M\n",
      "maxAttempts: 3\n",
      "jitter: PT0.001S\n",
      "Defines the states retry policy (strategy). This is an explicit definition and can be reused across multiple\n",
      "defined state actions.\n",
      "The name property specifies the unique name of the retry definition (strategy). This unique name\n",
      "can be referred by workflow states error definitions.\n",
      "The delay property specifies the initial time delay between retry attempts (ISO 8601 duration format).\n",
      "The increment property specifies a static duration which will be added to the delay between successive retries.\n",
      "To explain this better, let's say we have the following retry definition:\n",
      "json\n",
      "{\n",
      "  \"name\": \"Timeout Errors Strategy\",\n",
      "  \"delay\": \"PT10S\",\n",
      "  \"increment\": \"PT2S\",\n",
      "  \"maxAttempts\": 4\n",
      "}\n",
      "which means that we will retry up to 4 times after waiting with increasing delay between attempts;\n",
      "in this example 10, 12, 14, and 16 seconds between retries.\n",
      "The multiplier property specifies the value by which the interval time is increased for each of the retry attempts.\n",
      "To explain this better, let's say we have the following retry definition:\n",
      "json\n",
      "{\n",
      "  \"name\": \"Timeout Errors Strategy\",\n",
      "  \"delay\": \"PT10S\",\n",
      "  \"multiplier\": 2,\n",
      "  \"maxAttempts\": 4\n",
      "}\n",
      "which means that we will retry up to 4 times after waiting with increasing delay between attempts;\n",
      "in this example 10, 20, 40, and 80 seconds between retries.\n",
      "If both increment and multiplier properties are defined, increment should be applied first and then \n",
      "the multiplier when determining the next retry time.\n",
      "The maxAttempts property determines the maximum number of retry attempts allowed and is a positive integer value.\n",
      "The jitter property is important to prevent certain scenarios where clients\n",
      "are retrying in sync, possibly causing or contributing to a transient failure\n",
      "precisely because they're retrying at the same time. Adding a typically small,\n",
      "bounded random amount of time to the period between retries serves the purpose\n",
      "of attempting to prevent these retries from happening simultaneously, possibly\n",
      "reducing total time to complete requests and overall congestion. How this value\n",
      "is used in the exponential backoff algorithm is left up to implementations.\n",
      "jitter may be specified as a percentage relative to the total delay.\n",
      "Once the next retry attempt delay is calculated, we can apply jitter as a percentage value relative to this\n",
      "calculated delay. For example, if your calculated delay for the next retry is six seconds, and we specify\n",
      "a jitter value of 0.3, a random amount of time between 0 and 1.8 (0.3 times 6) is to be added or subtracted\n",
      "from the calculated delay.\n",
      "Alternatively, jitter may be defined as an absolute value specified as an ISO\n",
      "8601 duration. This way, the maximum amount of random time added is fixed and\n",
      "will not increase as new attempts are made.\n",
      "The maxDelay property determines the maximum amount of delay that is desired between retry attempts, and is applied\n",
      "after increment, multiplier, and jitter.\n",
      "To explain this better, let's say we have the following retry definition:\n",
      "json\n",
      "{\n",
      "  \"name\": \"Timeout Errors Strategy\",\n",
      "  \"delay\": \"PT10S\",\n",
      "  \"maxDelay\": \"PT100S\",\n",
      "  \"multiplier\": 4,\n",
      "  \"jitter\": \"PT1S\",\n",
      "  \"maxAttempts\": 4\n",
      "}\n",
      "which means that we will retry up to 4 times after waiting with increasing delay between attempts;\n",
      "in this example we might observe the following series of delays:\n",
      "11s (min(maxDelay, (delay +/- rand(jitter)) => min(100, 10 + 1))\n",
      "\n",
      "43s (min(maxDelay, (11s * multiplier) +/- rand(jitter)) => min(100, (11 * 4) - 1))\n",
      "100s (min(maxDelay, (43s * multiplier) +/- rand(jitter)) => min(100, (43 * 4) + 0))\n",
      "\n",
      "100s (min(maxDelay, (100s * multiplier) +/- rand(jitter)) => min(100, (100 * 4) - 1))\n",
      "\n",
      "Transition Definition\n",
      "Transition definition can have two types, either string or object.\n",
      "If string, it defines the name of the state to transition to.\n",
      "This can be used as a short-cut definition when you don't need to define any other parameters, for example:\n",
      "json\n",
      "\"transition\": \"myNextState\"\n",
      "\n",
      "If you need to define additional parameters in your transition definition, you can define\n",
      "it with its object type which has the following properties:\n",
      "| Parameter | Description | Type | Required |\n",
      "| --- | --- | --- | --- |\n",
      "| nextState | Name of the state to transition to next | string | yes |\n",
      "| compensate | If set to true, triggers workflow compensation before this transition is taken. Default is false | boolean | no |\n",
      "| produceEvents | Array of producedEvent definitions. Events to be produced before the transition takes place | array | no |\n",
      "```json\n",
      "{\n",
      "   \"produceEvents\": [{\n",
      "       \"eventRef\": \"produceResultEvent\",\n",
      "       \"data\": \"${ .result.data }\"\n",
      "   }],\n",
      "   \"nextState\": \"EvalResultState\"\n",
      "}\n",
      "```yaml\n",
      "produceEvents:\n",
      "- eventRef: produceResultEvent\n",
      "  data: \"${ .result.data }\"\n",
      "nextState: EvalResultState\n",
      "The nextState property defines the name of the state to transition to next.\n",
      "The compensate property allows you to trigger compensation before the transition (if set to true).\n",
      "The produceEvents property allows you to define a list of events to produce before the transition happens.\n",
      "Transitions allow you to move from one state (control-logic block) to another. For more information see the\n",
      "Transitions section section.\n",
      "\n",
      "Switch State Data Conditions\n",
      "condition | Workflow expression evaluated against state data. Must evaluate to\n",
      "\n",
      "transition | Transition to another state if condition is\n",
      "\n",
      "end | End workflow execution if condition is\n",
      "metadata | Metadata information| object | no |\n",
      "\n",
      "```json\n",
      "{\n",
      "      \"name\": \"Eighteen or older\",\n",
      "      \"condition\": \"${ .applicant | .age >= 18 }\",\n",
      "      \"transition\": \"StartApplication\"\n",
      "}\n",
      "```yaml\n",
      "name: Eighteen or older\n",
      "condition: \"${ .applicant | .age >= 18 }\"\n",
      "transition: StartApplication\n",
      "Switch state data conditions specify a data-based condition statement, which causes a transition to another\n",
      "workflow state if evaluated to true.\n",
      "The condition property of the condition defines an expression (e.g., ${ .applicant | .age > 18 }), which selects\n",
      "parts of the state data input. The condition must evaluate to true or false.\n",
      "If the condition is evaluated to true, you can specify either the transition or end definitions\n",
      "to decide what to do, transition to another workflow state, or end workflow execution. Note that transition and end\n",
      "definitions are mutually exclusive, meaning that you can specify either one or the other, but not both.\n",
      "Switch State Event Conditions\n",
      "\n",
      "transition | Transition to another state if condition is\n",
      "\n",
      "end | End workflow execution if condition is\n",
      "\n",
      "eventDataFilter | Event data filter definition | object | no |\n",
      "|\n",
      "metadata | Metadata information| object | no |\n",
      "\n",
      "```json\n",
      "{\n",
      "      \"name\": \"Visa approved\",\n",
      "      \"eventRef\": \"visaApprovedEvent\",\n",
      "      \"transition\": \"HandleApprovedVisa\"\n",
      "}\n",
      "```yaml\n",
      "name: Visa approved\n",
      "eventRef: visaApprovedEvent\n",
      "transition: HandleApprovedVisa\n",
      "Switch state event conditions specify events, which the switch state must wait for. Each condition\n",
      "can reference one workflow-defined event. Upon arrival of this event, the associated transition is taken.\n",
      "The eventRef property references a name of one of the defined workflow events.\n",
      "If the referenced event is received, you can specify either the transition or end definitions\n",
      "to decide what to do, transition to another workflow state, or end workflow execution.\n",
      "The eventDataFilter property can be used to filter event data when it is received.\n",
      "Note that transition and end\n",
      "definitions are mutually exclusive, meaning that you can specify either one or the other, but not both.\n",
      "\n",
      "Parallel State Branch\n",
      "| Parameter | Description | Type | Required |\n",
      "| --- | --- | --- | --- |\n",
      "| name | Branch name | string | yes |\n",
      "| actions | Actions to be executed in this branch | array | yes |\n",
      "| timeouts | Branch specific timeout settings | object | no |\n",
      "```json\n",
      "{\n",
      "      \"name\": \"Branch1\",\n",
      "      \"actions\": [\n",
      "          {\n",
      "              \"functionRef\": {\n",
      "                  \"refName\": \"functionNameOne\",\n",
      "                  \"arguments\": {\n",
      "\"order\": \"${ .someParam }\"\n",
      "                  }\n",
      "              }\n",
      "          },\n",
      "          {\n",
      "              \"functionRef\": {\n",
      "                  \"refName\": \"functionNameTwo\",\n",
      "\"arguments\": {\n",
      "                      \"order\": \"${ .someParamTwo }\"\n",
      "                  }\n",
      "              }\n",
      "          }\n",
      "      ]\n",
      "}\n",
      "```yaml\n",
      "name: Branch1\n",
      "actions:\n",
      "- functionRef:\n",
      "    refName: functionNameOne\n",
      "    arguments:\n",
      "      order: \"${ .someParam }\"\n",
      "- functionRef:\n",
      "    refName: functionNameTwo\n",
      "    arguments:\n",
      "order: \"${ .someParamTwo }\"\n",
      "Each branch receives the same copy of the Parallel state's data input.\n",
      "A branch can define actions that need to be executed. For the SubFlowRef action, the workflow id should not be the same id of the workflow where the branch is defined. Otherwise, it may occur\n",
      "undesired recurring calls to the same workflow.\n",
      "The timeouts property can be used to set branch specific timeout settings. Parallel state branches can set the\n",
      "actionExecTimeout and branchExecTimeout timeout properties. For more information on workflow timeouts reference the\n",
      "Workflow Timeouts section.\n",
      "Parallel State Handling Exceptions\n",
      "\n",
      "Exceptions can occur during execution of Parallel state branches.\n",
      "By default, exceptions that are not handled within branches stop branch execution and are propagated\n",
      "to the Parallel state and should be handled with its onErrors definition.\n",
      "If the parallel states branch defines actions, all exceptions that arise from executing these actions (after all\n",
      "allotted retries are exhausted)\n",
      "are propagated to the parallel state\n",
      "and can be handled with the parallel states onErrors definition.\n",
      "If the parallel states defines a subflow action, exceptions that occur during execution of the called workflow\n",
      "can choose to handle exceptions on their own. All unhandled exceptions from the called workflow\n",
      "execution however are propagated back to the parallel state and can be handled with the parallel states\n",
      "onErrors definition.\n",
      "Note that once an error that is propagated to the parallel state from a branch and handled by the\n",
      "states onErrors definition is handled (its associated transition is taken) no further errors from branches of this\n",
      "parallel state should be considered as the workflow control flow logic has already moved to a different state.\n",
      "For more information, see the Workflow Error Handling sections.\n",
      "\n",
      "Start Definition\n",
      "\n",
      "Can be either string or object type. If type string, it defines the name of the workflow starting state.\n",
      "json\n",
      "\"start\": \"MyStartingState\"\n",
      "\n",
      "In this case it's assumed that the schedule property is not defined.\n",
      "\n",
      "If the start definition is of type object, it has the following structure:\n",
      "| Parameter | Description | Type | Required |\n",
      "| --- | --- | --- | --- |\n",
      "| stateName | Name of the starting workflow state | string | no |\n",
      "| schedule | Define the recurring time intervals or cron expressions at which workflow instances should be automatically started. | string or object | yes |\n",
      "```json\n",
      "{\n",
      "  \"stateName\": \"MyStartingstate\",\n",
      "  \"schedule\": \"2020-03-20T09:00:00Z/PT2H\"\n",
      "}\n",
      "```yaml\n",
      "stateName: MyStartingstate\n",
      "schedule: 2020-03-20T09:00:00Z/PT2H\n",
      "Start definition explicitly defines how/when workflow instances should be created and what the workflow starting state is.\n",
      "\n",
      "The start definition can be either string or object type.\n",
      "If string type, it defines the name of the workflow starting state.\n",
      "\n",
      "If object type, it provides the ability to set the workflow starting state name, as well as the schedule property.\n",
      "The stateName property can be set to define the starting workflow state. If not specified, the first state\n",
      "in the workflow states definition should be used as the starting workflow state.\n",
      "The schedule property allows to define scheduled workflow instance creation.\n",
      "Scheduled starts have two different choices. You can define a recurring time interval or cron-based schedule at which a workflow\n",
      "instance should be created (automatically).\n",
      "You can also define cron-based scheduled starts, which allows you to specify periodically started workflow instances based on a cron definition.\n",
      "Cron-based scheduled starts can handle absolute time intervals (i.e., not calculated in respect to some particular point in time).\n",
      "One use case for cron-based scheduled starts is a workflow that performs periodical data batch processing.\n",
      "In this case we could use a cron definition\n",
      "text\n",
      "0 0/5 * * * ?\n",
      "\n",
      "to define that a workflow instance from the workflow definition should be created every 5 minutes, starting at full hour.\n",
      "Here are some more examples of cron expressions and their meanings:\n",
      "text\n",
      "* * * * *   - Create workflow instance at the top of every minute\n",
      "0 * * * *   - Create workflow instance at the top of every hour\n",
      "0 */2 * * * - Create workflow instance every 2 hours\n",
      "0 9 8 * *   - Create workflow instance at 9:00:00AM on the eighth day of every month\n",
      "See here to get more information on defining cron expressions.\n",
      "One thing to discuss when dealing with cron-based scheduled starts is when the workflow starting state is an Event.\n",
      "Event states define that workflow instances are triggered by the existence of the defined event(s).\n",
      "Defining a cron-based scheduled starts for the runtime implementations would mean that there needs to be an event service that issues\n",
      "the needed events at the defined times to trigger workflow instance creation.\n",
      "Defining a start definition is not required. If it's not defined, the starting workflow\n",
      "state has to be the very first state defined in the workflow states array.\n",
      "\n",
      "Schedule Definition\n",
      "Schedule definition can have two types, either string or object.\n",
      "If string type, it defines time interval describing when the workflow instance should be automatically created.\n",
      "This can be used as a short-cut definition when you don't need to define any other parameters, for example:\n",
      "json\n",
      "{\n",
      "  \"schedule\": \"R/PT2H\"\n",
      "}\n",
      "\n",
      "If you need to define the cron or the timezone parameters in your schedule definition, you can define\n",
      "it with its object type which has the following properties:\n",
      "| Parameter | Description | Type | Required |\n",
      "| --- | --- | --- | --- |\n",
      "| interval | A recurring time interval expressed in the derivative of ISO 8601 format specified below. Declares that workflow instances should be automatically created at the start of each time\n",
      "interval in the series. | string | yes (if cron is not defined) |\n",
      "| cron | Cron expression defining when workflow instances should be automatically created | object | yes (if interval is not defined) |\n",
      "| timezone | Timezone name used to evaluate the interval & cron-expression. If the interval specifies a date-time w/ timezone then proper timezone conversion will be applied. (default: UTC). | string\n",
      "| no |\n",
      "```json\n",
      "{\n",
      "   \"cron\": \"0 0/15 * * * ?\"\n",
      "}\n",
      "```yaml\n",
      "cron: 0 0/15 * * * ?\n",
      "The interval property uses a derivative of ISO 8601 recurring time interval format to describe a series of consecutive time intervals for workflow instances to be automatically created at the start\n",
      "of. Unlike full ISO 8601, this derivative format does not allow expression of an explicit number of recurrences or identification of a series by the date and time at the start and end of its first\n",
      "time interval.\n",
      "There are three ways to express a recurring interval:\n",
      "R/<Start>/<Duration>: Defines the start time and a duration, for example: \"R/2020-03-20T13:00:00Z/PT2H\", meaning workflow\n",
      "instances will be automatically created every 2 hours starting from March 20th 2020 at 1pm UTC.\n",
      "R/<Duration>/<End>: Defines a duration and an end, for example: \"R/PT2H/2020-05-11T15:30:00Z\", meaning that workflow instances will be\n",
      "automatically created every 2 hours until until May 11th 2020 at 3:30pm UTC (i.e., the last instance will be created 2 hours prior to that, at 1:30pm UTC).\n",
      "R/<Duration>: Defines a duration only, for example: \"R/PT2H\", meaning workflow instances will be automatically created every 2 hours. The start time of the first interval may be indeterminate, but\n",
      "should be delayed by no more than the specified duration and must repeat on schedule after that (this is effectively supplying the start time \"out-of-band\" as permitted ISO ISO 8601-1:2019 section\n",
      "5.6.1 NOTE 1). Each runtime implementation should document how the start time for a duration-only interval is established.\n",
      "The cron property uses a cron expression\n",
      "to describe a repeating interval upon which a workflow instance should be created automatically.\n",
      "For more information see the cron definition section.\n",
      "here for a list of timezone names.  For ISO 8601 date time\n",
      "values in\n",
      "Note that when the workflow starting state is an Event\n",
      "defining cron-based scheduled starts for the runtime implementations would mean that there needs to be an event service that issues\n",
      "the needed events at the defined times to trigger workflow instance creation.\n",
      "Cron Definition\n",
      "Cron definition can have two types, either string or object.\n",
      "If string type, it defines the cron expression describing when the workflow instance should be created (automatically).\n",
      "This can be used as a short-cut definition when you don't need to define any other parameters, for example:\n",
      "json\n",
      "{\n",
      "  \"cron\": \"0 15,30,45 * ? * *\"\n",
      "}\n",
      "\n",
      "If you need to define the validUntil parameters in your cron definition, you can define\n",
      "it with its object type which has the following properties:\n",
      "| Parameter | Description | Type | Required |\n",
      "| --- | --- | --- | --- |\n",
      "| expression | Cron expression describing when the workflow instance should be created (automatically) | string | yes |\n",
      "| validUntil | Specific date and time (ISO 8601 format) when the cron expression is no longer valid | string | no |\n",
      "```json\n",
      "{\n",
      "    \"expression\": \"0 15,30,45 * ? * *\",\n",
      "    \"validUntil\": \"2021-11-05T08:15:30-05:00\"\n",
      "}\n",
      "```yaml\n",
      "expression: 0 15,30,45 * ? * *\n",
      "validUntil: '2021-11-05T08:15:30-05:00'\n",
      "The expression property is a a cron expression which defines\n",
      "when workflow instances should be created (automatically).\n",
      "The validUntil property defines a date and time (using ISO 8601 format). When the\n",
      "validUntil time is reached, the cron expression for instances creations of this workflow\n",
      "should no longer be valid.\n",
      "For example let's say we have to following cron definitions:\n",
      "\n",
      "json\n",
      "{\n",
      "    \"expression\": \"0 15,30,45 * ? * *\",\n",
      "    \"validUntil\": \"2021-11-05T08:15:30-05:00\"\n",
      "}\n",
      "This tells the runtime engine to create an instance of this workflow every hour\n",
      "at minutes 15, 30 and 45. This is to be done until November 5, 2021, 8:15:30 am, US Eastern Standard Time\n",
      "as defined by the validUntil property value.\n",
      "End Definition\n",
      "\n",
      "Can be either boolean or object type. If type boolean, must be set to true, for example:\n",
      "\n",
      "json\n",
      "\"end\": true\n",
      "In this case it's assumed that the terminate property has its default value of false, and the produceEvents,\n",
      "compensate, and  continueAs properties are not defined.\n",
      "If the end definition is of type object, it has the following structure:\n",
      "\n",
      "producedEvent definitions. Defines events that should be produced. | array | no |\n",
      "|\n",
      "\n",
      "compensate | If set to\n",
      "continueAs | Defines that current workflow execution should stop, and execution should continue as a new workflow instance of the provided id | string or object | no |\n",
      "```json\n",
      "{\n",
      "    \"terminate\": true,\n",
      "    \"produceEvents\": [{\n",
      "        \"eventRef\": \"provisioningCompleteEvent\",\n",
      "        \"data\": \"${ .provisionedOrders }\"\n",
      "    }]\n",
      "}\n",
      "```yaml\n",
      "terminate: true\n",
      "produceEvents:\n",
      "- eventRef: provisioningCompleteEvent\n",
      "  data: \"${ .provisionedOrders }\"\n",
      "End definitions are used to explicitly define execution completion of a workflow instance or workflow execution path.\n",
      "A workflow definition must include at least one workflow state.\n",
      "Note that Switch states cannot declare to be workflow end states. Their conditions however can \n",
      "define a stop of workflow execution.\n",
      "The terminate property, if set to true, completes the workflow instance execution, this any other active\n",
      "execution paths.\n",
      "If a terminate end is reached inside a ForEach or Parallel state the entire workflow instance is terminated.\n",
      "The produceEvents allows defining events which should be produced\n",
      "by the workflow instance before workflow stops its execution.\n",
      "\n",
      "workflowExecTimeout property is defined, the time defined in its\n",
      "The compensate property defines that workflow compensation should be performed before the workflow \n",
      "execution is completed.\n",
      "continueAs property defines that the current workflow instance should stop its execution,\n",
      "and worklow execution should continue as a new instance of a new workflow.\n",
      "When defined, it should be assumed that\n",
      "ProducedEvent Definition\n",
      "| Parameter | Description | Type | Required |\n",
      "| --- | --- | --- | --- |\n",
      "| eventRef | Reference to a defined unique event name in the events definition | string | yes |\n",
      "| data | If string type, an expression which selects parts of the states data output to become the data (payload) of the produced event. If object type, a custom object to become the data (payload) of\n",
      "produced event. | string or object | no |\n",
      "| contextAttributes | Add additional event extension context attributes | object | no |\n",
      "```json\n",
      "{\n",
      "    \"eventRef\": \"provisioningCompleteEvent\",\n",
      "    \"data\": \"${ .provisionedOrders }\",\n",
      "    \"contextAttributes\": [{\n",
      "         \"buyerId\": \"${ .buyerId }\"\n",
      "     }]\n",
      " }\n",
      "```yaml\n",
      "eventRef: provisioningCompleteEvent\n",
      "data: \"${ .provisionedOrders }\"\n",
      "contextAttributes:\n",
      "- buyerId: \"${ .buyerId }\"\n",
      "Defines the event (CloudEvent format) to be produced when workflow execution completes or during a workflow transitions.\n",
      "The eventRef property must match the name of\n",
      "one of the defined produced events in the events definition.\n",
      "The data property can have two types, object or string. If of string type, it is an expression that can select parts of state data\n",
      "to be used as the event payload. If of object type, you can define a custom object to be the event payload.\n",
      "The contextAttributes property allows you to add one or more extension context attributes\n",
      "to the generated event.\n",
      "Being able to produce events when workflow execution completes or during state transition\n",
      "allows for event-based orchestration communication.\n",
      "For example, completion of an orchestration workflow can notify other orchestration workflows to decide if they need to act upon\n",
      "the produced event, or notify monitoring services of the current state of workflow execution, etc.\n",
      "It can be used to create very dynamic orchestration scenarios.\n",
      "Transitions\n",
      "Serverless workflow states can have one or more incoming and outgoing transitions (from/to other states).\n",
      "Each state can define a transition definition that is used to determine which\n",
      "state to transition to next.\n",
      "Implementers must use the unique State name property for determining the transition.\n",
      "Events can be produced during state transitions. The produceEvents property of the transition definitions allows you\n",
      "to reference one or more defined produced events in the workflow events definitions.\n",
      "For each of the produced events you can select what parts of state data to be the event payload.\n",
      "Transitions can trigger compensation via their compensate property. See the Workflow Compensation\n",
      "section for more information.\n",
      "\n",
      "Additional Properties\n",
      "Specifying additional properties, namely properties which are not defined by the specification\n",
      "are only allowed in the Workflow Definition.\n",
      "Additional properties serve the same purpose as Workflow Metadata.\n",
      "They allow you to enrich the workflow definition with custom information.\n",
      "Additional properties, just like workflow metadata, should not affect workflow execution.\n",
      "Implementations may choose to use additional properties or ignore them.\n",
      "It is recommended to use workflow metadata instead of additional properties in the workflow definition.\n",
      "\n",
      "Let's take a look at an example of additional properties:\n",
      "json\n",
      "{\n",
      "  \"id\": \"myworkflow\",\n",
      "  \"version\": \"1.0.0\",\n",
      "  \"specVersion\": \"0.8\",\n",
      "  \"name\": \"My Test Workflow\",\n",
      "  \"start\": \"My First State\",\n",
      "  \"loglevel\": \"Info\",\n",
      "  \"environment\": \"Production\",\n",
      "\"category\": \"Sales\",\n",
      "  \"states\": [ ... ]\n",
      "}\n",
      "In this example, we specify the loglevel, environment, and category additional properties.\n",
      "\n",
      "Note the same can be also specified using workflow metadata, which is the preferred approach:\n",
      "json\n",
      "{\n",
      "  \"id\": \"myworkflow\",\n",
      "  \"version\": \"1.0.0\",\n",
      "  \"specVersion\": \"0.8\",\n",
      "  \"name\": \"Py Test Workflow\",\n",
      "  \"start\": \"My First State\",\n",
      "  \"metadata\": {\n",
      "    \"loglevel\": \"Info\",\n",
      "\"environment\": \"Production\",\n",
      "    \"category\": \"Sales\"\n",
      "  },\n",
      "  \"states\": [ ... ]\n",
      "}\n",
      "Workflow Error Handling\n",
      "Serverless Workflow language allows you to define explicit error handling, meaning you can define what should happen\n",
      "in case of errors inside your workflow model rather than some generic error handling entity.\n",
      "This allows error handling to become part of your orchestration activities and as such part of your business problem\n",
      "solutions.\n",
      "The idea behind the way Serverless Workflow defines error handling is that workflows should only fail due to unknown bugs\n",
      "during execution. In general, you should always write your workflows so that they do not fail on any known failures.\n",
      "Each workflow state can define error handling, which is related only to errors that may arise during its\n",
      "execution. Error handling defined in one state cannot be used to handle errors that happened during execution of another state\n",
      "during workflow execution.\n",
      "Unknown errors that may arise during workflow state execution that are not explicitly handled within the workflow definition\n",
      "should be reported by runtime implementations and halt workflow execution.\n",
      "Within workflow definitions, errors defined are domain specific, meaning they are defined within\n",
      "the actual business domain, rather than their technical (programming-language-specific) description.\n",
      "For example, we can define errors such as \"Order not found\", or \"Item not in inventory\", rather than having to\n",
      "use terms such as \"java.lang.IllegalAccessError\", or \"response.status == 404\", which\n",
      "might make little to no sense to our specific problem domain, as well as may not be portable across various runtime implementations.\n",
      "In addition to the domain specific error name, users have the option to also add an optional error code\n",
      "to help runtime implementations with mapping defined errors to concrete underlying technical ones.\n",
      "Runtime implementations must be able to map the error domain specific name (and the optional error code)\n",
      "to concrete technical errors that arise during workflow execution.\n",
      "\n",
      "Defining Errors\n",
      "Known workflow errors, that we know we need to handle during workflow execution should be defined in\n",
      "the workflow top-level 'errors' property. This property can be either a string type, meaning it can reference\n",
      "a reusable JSON or Yaml definition file including the error definitions, or it can have an array type where you can\n",
      "define these checked errors in-line in your workflow definition.\n",
      "Here is an example of such a definition for both cases:\n",
      "\n",
      "Referencing a reusable JSON/Yaml error definition file:\n",
      "\n",
      "```json\n",
      "{\n",
      "\"errors\": \"file://documents/reusable/errors.json\"\n",
      "}\n",
      "```yaml\n",
      "errors: file://documents/reusable/errors.json\n",
      "Defining workflow errors in-line:\n",
      "```json\n",
      "{\n",
      "\"errors\": [\n",
      "  {\n",
      "    \"name\": \"Service not found error\",\n",
      "    \"code\": \"404\",\n",
      "    \"description\": \"Server has not found anything matching the provided service endpoint information\"\n",
      "  }\n",
      "]\n",
      "}\n",
      "```yaml\n",
      "errors:\n",
      "  - name: Service not found error\n",
      "    code: '404'\n",
      "    description: Server has not found anything matching the provided service endpoint\n",
      "      information\n",
      "These defined errors can then be referenced by their unique name in both states onErrors definitions as well as in \n",
      "actions nonRetryableErrors and retryableErrors properties.\n",
      "\n",
      "Action retries\n",
      "Retries allow workflows to deal with intermittent failures of services they are trying to invoke.\n",
      "In addition, retries allow workflows to continue (not fail) execution and allow us to fix possible errors with invoked \n",
      "services and continue execution after they are fixed.\n",
      "Retries are important for both short-lived and long-lived workflows, as well as in both stateless and stateful \n",
      "scenarios.\n",
      "Serverless workflow supports two distinct ways of defining retries:\n",
      "1. Retrying on specified known (checked) errors.\n",
      "2. Automatic retrying on both known (checked) and not-known (unchecked) errors.\n",
      "Which retry option the workflow should use by default is defined via the workflow top-level autoRetries property.\n",
      "By default, the value of the autoRetries is set to false, meaning that retry option 1) is used by default.\n",
      "You can enable automatic retrying (option 2) by setting autoRetries to true.\n",
      "Regardless of the chosen retries option, note that workflows in general should be designed to not fail. \n",
      "Workflows should be able to recover from intermittent failures.\n",
      "The next sections provide more details to each action retry option.\n",
      "\n",
      "Retry actions on known errors\n",
      "This is the default option when the workflow top-level autoRetries property is not specified or is set to false.\n",
      "This retry options is suited for stateless / short-running workflows where retries should  be performed when specifically\n",
      "wanted. Note that in this scenario when unknown (unchecked) errors happen during action execution (service invocation), \n",
      "workflow execution should fail.\n",
      "Let's take a look at an example. To start, let's define a workflow top-level retries definition:\n",
      "```json\n",
      "{\n",
      "\"retries\": [\n",
      "  {\n",
      "    \"name\": \"FirstRetryStrategy\",\n",
      "    \"delay\": \"PT1M\",\n",
      "    \"maxAttempts\": 5\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"SecondRetryStrategy\",\n",
      "    \"delay\": \"PT10M\",\n",
      "    \"maxAttempts\": 10\n",
      "  }\n",
      "]\n",
      "}\n",
      "```yaml\n",
      "retries:\n",
      "  - name: FirstRetryStrategy\n",
      "    delay: PT1M\n",
      "    maxAttempts: 5\n",
      "  - name: SecondRetryStrategy\n",
      "    delay: PT10M\n",
      "    maxAttempts: 10\n",
      "Our retries definitions can be referenced by actions. For example:\n",
      "```json\n",
      "{\n",
      "  \"actions\": [\n",
      "    {\n",
      "      \"functionRef\": \"MyFirstFunction\",\n",
      "      \"retryRef\": \"FirstRetryStrategy\",\n",
      "      \"retryableErrors\": [\"SomeErrorOne\", \"SomeErrorTwo\"]\n",
      "    },\n",
      "    {\n",
      "\"functionRef\": \"MySecondFunction\",\n",
      "      \"retryRef\": \"SecondRetryStrategy\",\n",
      "      \"retryableErrors\": [\"SomeErrorTwo\", \"SomeErrorThree\"]\n",
      "    },\n",
      "    {\n",
      "      \"functionRef\": \"MyThirdFunction\"\n",
      "    }\n",
      "]\n",
      "}\n",
      "```yaml\n",
      "actions:\n",
      "  - functionRef: MyFirstFunction\n",
      "    retryRef: FirstRetryStrategy\n",
      "    nonRetryableErrors:\n",
      "      - SomeErrorOne\n",
      "      - SomeErrorTwo\n",
      "  - functionRef: MySecondFunction\n",
      "retryRef: SecondRetryStrategy\n",
      "    nonRetryableErrors:\n",
      "      - SomeErrorTwo\n",
      "      - SomeErrorThree\n",
      "  - functionRef: MyThirdFunction\n",
      "Each action can define the retry strategy it wants to use. If it does not define one, the action is in this case not retries.\n",
      "Actions can define a list of known errors in its retryableErrors array. If defined, then the action should be retried\n",
      "for those errors according to the referenced retry strategy.\n",
      "In our example, \"MyFirstFunction\" invocation should be retried according to the \"FirstRetryStrategy\" policy only on known errors\n",
      "\"SomeErrorOne\" and \"SomeErrorTwo\".\n",
      "If for a known error (defined in retryableErrors) the retry limit is reached and the error still persist, it can be handled in the states\n",
      "onErrors definition.\n",
      "If an unknown (unchecked) error happens during action execution, and this error is also not handled in the states onErrors definition, the\n",
      "workflow execution should fail.\n",
      "Automatic retries on known and unknown errors\n",
      "This is the option used when the workflow top-level autoRetries property is set to true.\n",
      "Automatic retries are well suited to long-running and stateful workflow orchestrations. It allows workflows\n",
      "to recover from failures thus providing more resilience. There is a possible cost associated with automatic retries\n",
      "in terms of resource and computing power utilization.\n",
      "With this retries option, action executions should be retried automatically for both known (checked) as well as unknown (unchecked)\n",
      "errors. This means that you do not have to define a retry strategy for actions for them to have retried, it's included by default.\n",
      "Users can still define a custom retry strategy for each action via the retryRef property.\n",
      "If a retry strategy is not defined, a default retry strategy should be used.\n",
      "Runtime implementations can define their own default retry strategy. Serverless Workflow recommends the following settings:\n",
      "maxAttempts to be unlimited, meaning that the action should be retried indefinitely until successful.\n",
      "\n",
      "delay to be set to one second, meaning that there is a one second delay between action retries.\n",
      "multiplier to be set to two meaning that the delay should be multiplied by two for each retry attempt.\n",
      "Runtimes should document their default retry strategy to users, so it's clear which\n",
      "property values they are using for the default.\n",
      "Actions can define for which known (checked) errors they should not be retried for. \n",
      "This is done via the actions nonRetryableErrors property. If a known error happens during action execution\n",
      "which is included in the nonRetryableErrors property array, that action should not be retried and the error \n",
      "then should be handled in the workflow states onErrors property.\n",
      "Let's take a look at an examples of defining retries when using the automatic retries option. \n",
      "This example assumes that the workfow top level autoRetries property is set to true.\n",
      "To start, let's define a workflow top-level retries definition:\n",
      "```json\n",
      "{\n",
      "\"retries\": [\n",
      "  {\n",
      "    \"name\": \"FirstRetryStrategy\",\n",
      "    \"delay\": \"PT1M\",\n",
      "    \"maxAttempts\": 5\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"SecondRetryStrategy\",\n",
      "    \"delay\": \"PT10M\",\n",
      "    \"maxAttempts\": 10\n",
      "  },\n",
      "  {\n",
      "\"name\": \"DoNotRetryStrategy\",\n",
      "    \"maxAttempts\": 1\n",
      "  }\n",
      "]\n",
      "}\n",
      "```yaml\n",
      "retries:\n",
      "  - name: FirstRetryStrategy\n",
      "    delay: PT1M\n",
      "    maxAttempts: 5\n",
      "  - name: SecondRetryStrategy\n",
      "    delay: PT10M\n",
      "    maxAttempts: 10\n",
      "  - name: DoNotRetryStrategy\n",
      "    maxAttempts: 1\n",
      "Our retry definitions can be referenced by state actions. For example:\n",
      "```json\n",
      "{\n",
      "  \"actions\": [\n",
      "    {\n",
      "      \"functionRef\": \"MyFirstFunction\",\n",
      "      \"retryRef\": \"FirstRetryStrategy\",\n",
      "      \"nonRetryableErrors\": [\"SomeErrorOne\", \"SomeErrorTwo\"]\n",
      "    },\n",
      "    {\n",
      "\"functionRef\": \"MySecondFunction\",\n",
      "      \"retryRef\": \"SecondRetryStrategy\",\n",
      "      \"nonRetryableErrors\": [\"SomeErrorTwo\", \"SomeErrorThree\"]\n",
      "    },\n",
      "    {\n",
      "      \"functionRef\": \"MyThirdFunction\"\n",
      "},\n",
      "    {\n",
      "      \"functionRef\": \"MyFourthFunction\",\n",
      "      \"retryRef\": \"DoNotRetryStrategy\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```yaml\n",
      "actions:\n",
      "  - functionRef: MyFirstFunction\n",
      "    retryRef: FirstRetryStrategy\n",
      "    nonRetryableErrors:\n",
      "      - SomeErrorOne\n",
      "      - SomeErrorTwo\n",
      "  - functionRef: MySecondFunction\n",
      "retryRef: SecondRetryStrategy\n",
      "    nonRetryableErrors:\n",
      "      - SomeErrorTwo\n",
      "      - SomeErrorThree\n",
      "  - functionRef: MyThirdFunction\n",
      "  - functionRef: MyFourthFunction\n",
      "retryRef: DoNotRetryStrategy\n",
      "In our example the first action named MyFirstFunction is going to be retried according to the FirstRetryStrategy\n",
      "retry policy\n",
      "for all errors except SomeErrorOne and SomeErrorTwo.\n",
      "The seconds action named MySecondFunction is going to be retried according to the SecondRetryStrategy\n",
      "retry policy \n",
      "for all errors except SomeErrorTwo and SomeErrorThree.\n",
      "The third action named MyThirdFunction is going to retried according to the default runtime retry policy.\n",
      "It will be retried for all errors both known (checked) as well as unknown (unckecked).\n",
      "The fourth action named MyFourthFunction is going to be retried according to the DoNotRetryStrategy\n",
      "retry policy which has the maxAttempts property set to 1, meaning that this action will not be retried.\n",
      "Workflow Timeouts\n",
      "\n",
      "Workflow timeouts define the maximum times for:\n",
      "\n",
      "Workflow execution\n",
      "\n",
      "State execution\n",
      "\n",
      "Action execution\n",
      "\n",
      "Branch execution\n",
      "\n",
      "Event consumption time\n",
      "The specification allows for timeouts to be defined on the top-level workflow definition, as well as\n",
      "in each of the workflow state definitions. Note that the timeout settings defined in states, and state branches overwrite the top-level\n",
      "workflow definition for state, action and branch execution. If they are not defined, then the top-level\n",
      "timeout settings should take in effect.\n",
      "To give an example, let's say that in our workflow definition we define the timeout for state execution:\n",
      "json\n",
      "{\n",
      "   \"id\": \"testWorkflow\",\n",
      "   ...\n",
      "   \"timeouts\": {\n",
      "     ...\n",
      "     \"stateExecTimeout\": \"PT2S\"\n",
      "   }\n",
      "   ...\n",
      "}\n",
      "This top-level workflow timeout setting defines that the maximum execution time of all defined workflow states\n",
      "is two seconds each.\n",
      "Now let's say that we have worfklow states \"A\" and \"B\". State \"A\" does not define a timeout definition, but state\n",
      "\"B\" does:\n",
      "json\n",
      "{\n",
      "   \"name\": \"B\",\n",
      "   \"type\": \"operation\",\n",
      "   ...\n",
      "   \"timeouts\": {\n",
      "     ...\n",
      "     \"stateExecTimeout\": \"PT10S\"\n",
      "   }\n",
      "   ...\n",
      "}\n",
      "Since state \"A\" does not overwrite the top-level stateExecTimeout, its execution timeout should be inherited from\n",
      "the top-level timeout definition.\n",
      "On the other hand, state \"B\" does define it's own stateExecTimeout, in which case it would overwrite the default\n",
      "setting, meaning that it would its execution time has a max limit of ten seconds.\n",
      "Defining timeouts is not mandatory, meaning that if not defined, all the timeout settings should be assumed to\n",
      "be \"unlimited\".\n",
      "Note that the defined workflow execution timeout has precedence over all other defined timeouts.\n",
      "Just to give an extreme example, let's say we define the workflow execution timeout to ten seconds,\n",
      "and the state execution timeout to twenty seconds. In this case if the workflow execution timeout is reached\n",
      "it should follow the rules of workflow execution timeout and end workflow execution, no matter what the\n",
      "state execution time has been set to.\n",
      "Let's take a look all possible timeout definitions:\n",
      "\n",
      "Workflow Timeout Definition\n",
      "Workflow timeouts are defined with the top-level timeouts property. It can have two types, string and object.\n",
      "If string type it defines an URI that points to a Json or Yaml file containing the workflow timeout definitions.\n",
      "If object type, it is used to define the timeout definitions in-line and has the following properties:\n",
      "| Parameter | Description | Type | Required |\n",
      "| --- | --- | --- | --- |\n",
      "| workflowExecTimeout | Workflow execution timeout (ISO 8601 duration format) | string or object | no |\n",
      "| stateExecTimeout | Workflow state execution timeout (ISO 8601 duration format) | string | no |\n",
      "| actionExecTimeout | Actions execution timeout (ISO 8601 duration format) | string | no |\n",
      "| branchExecTimeout | Branch execution timeout (ISO 8601 duration format) | string | no |\n",
      "| eventTimeout | Default timeout for consuming defined events (ISO 8601 duration format) | string | no |\n",
      "The eventTimeout property defines the maximum amount of time to wait to consume defined events. If not specified it should default to\n",
      "\"unlimited\".\n",
      "The branchExecTimeout property defines the maximum execution time for a single branch. If not specified it should default to\n",
      "\"unlimited\".\n",
      "The actionExecTimeout property defines the maximum execution time for a single actions definition. If not specified it should default to\n",
      "\"unlimited\". Note that an action definition can include multiple actions.\n",
      "The stateExecTimeout property defines the maximum execution time for a single workflow state. If not specified it should default to\n",
      "\"unlimited\".\n",
      "The workflowExecTimeout property defines the workflow execution timeout.\n",
      "It is defined using the ISO 8601 duration format. If not defined, the workflow execution should be given \"unlimited\"\n",
      "amount of time to complete.\n",
      "workflowExecTimeout can have two possibly types, either string or object.\n",
      "If string type, it defines the maximum workflow execution time.\n",
      "If Object type it has the following format:\n",
      "WorkflowExecTimeout Definition\n",
      "| Parameter | Description | Type | Required |\n",
      "| --- | --- | --- | --- |\n",
      "| duration | Timeout duration (ISO 8601 duration format) | string | yes |\n",
      "| interrupt | If false, workflow instance is allowed to finish current execution. If true, current workflow execution is stopped immediately. Default is false  | boolean | no |\n",
      "| runBefore | Name of a workflow state to be executed before workflow instance is terminated | string | no |\n",
      "```json\n",
      "{\n",
      "   \"duration\": \"PT2M\",\n",
      "   \"runBefore\": \"createandsendreport\"\n",
      "}\n",
      "```yaml\n",
      "duration: PT2M\n",
      "runBefore: createandsendreport\n",
      "The duration property defines the time duration of the execution timeout. Once a workflow instance is created,\n",
      "and the amount of the defined time is reached, the workflow instance should be terminated.\n",
      "The interrupt property defines if the currently running instance should be allowed to finish its current\n",
      "execution flow before it needs to be terminated. If set to true, the current instance execution should stop immediately.\n",
      "The runBefore property defines a name of a workflow state to be executed before workflow instance is terminated.\n",
      "States referenced by runBefore (as well as any other states that they transition to) must obey following rules:\n",
      "They should not have any incoming transitions (should not be part of the main workflow control-flow logic)\n",
      "They cannot be states marked for compensation (have their usedForCompensation property set to true)\n",
      "If it is a single state, it must define an end definition, if it transitions to other states,\n",
      "  at last one must define it.\n",
      "They can transition only to states are also not part of the main control flow logic (and are not marked\n",
      "  for compensation).\n",
      "Runtime implementations should raise compile time / parsing exceptions if any of the rules mentioned above are\n",
      "not obeyed in the workflow definition.\n",
      "\n",
      "States Timeout Definition\n",
      "All workflow states can define the timeouts property and can define different timeout\n",
      "settings depending on their state type.\n",
      "Please reference each workflow state definitions for more information on which\n",
      "timeout settings are available for each state type.\n",
      "Workflow states timeouts cannot define the workflowExecTimeout property.\n",
      "Workflow states can set their stateExecTimeout property inside the timeouts definition. \n",
      "The value of this property is a time duration (ISO 8601 duration format).\n",
      "It must be a duration that's greater than zero and defines the total state execution timeout. \n",
      "When this timeout is reached, state execution\n",
      "should be stopped and can be handled as a timeout error in the states onErrors definition.\n",
      "Branch Timeout Definition\n",
      "Parallel states can define the branchExecTimeout property. If defined on the state\n",
      "level, it applies to each branch of the Parallel state. Note that each parallel state branch\n",
      "can overwrite this setting to define its own branch execution timeout.\n",
      "If a branch does not define this timeout property, it should be inherited from it's state definition branch timeout setting.\n",
      "If its state does not define it either, it should be inherited from the top-level workflow branch timeout settings.\n",
      "Event Timeout Definition\n",
      "The Event state timeouts property can be used to\n",
      "specify state specific timeout settings. For event state it can contain the eventTimeout property\n",
      "which is defined using the ISO 8601 data and time format.\n",
      "You can specify for example \"PT15M\" to represent 15 minutes or \"P2DT3H4M\" to represent 2 days, 3 hours and 4 minutes.\n",
      "eventTimeout values should always be represented as durations and not as specific time intervals.\n",
      "The eventTimeout property needs to be described in detail  for Event states as it depends on whether or not the Event state is a workflow starting state or not.\n",
      "If the Event state is a workflow starting state, incoming events may trigger workflow instances. In this case,\n",
      "if the exclusive property is set to true, the eventTimeout property should be ignored.\n",
      "If the exclusive property is set to false, in this case, the defined eventTimeout represents the time\n",
      "between arrival of specified events. To give an example, consider the following:\n",
      "json\n",
      "{\n",
      "\"states\": [\n",
      "{\n",
      "    \"name\": \"ExampleEventState\",\n",
      "    \"type\": \"event\",\n",
      "    \"exclusive\": false,\n",
      "    \"timeouts\": {\n",
      "      \"eventTimeout\": \"PT2M\"\n",
      "    }\n",
      "    \"onEvents\": [\n",
      "        {\n",
      "\"eventRefs\": [\n",
      "                \"ExampleEvent1\",\n",
      "                \"ExampleEvent2\"\n",
      "            ],\n",
      "            \"actions\": [\n",
      "              ...\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"end\": {\n",
      "\"terminate\": true\n",
      "    }\n",
      "}\n",
      "]\n",
      "}\n",
      "The first eventTimeout would start once any of the referenced events are consumed. If the second event does not occur within\n",
      "the defined eventTimeout, no workflow instance should be created.\n",
      "If the event state is not a workflow starting state, the eventTimeout property is relative to the time when the\n",
      "state becomes active. If the defined event conditions (regardless of the value of the exclusive property)\n",
      "are not satisfied within the defined timeout period, the event state should transition to the next state or end the workflow\n",
      "instance in case it is an end state without performing any actions.\n",
      "Workflow Compensation\n",
      "Compensation deals with undoing or reversing the work of one or more states which have\n",
      "already successfully completed. For example, let's say that we have charged a customer $100 for an item\n",
      "purchase. In the case customer laster on decides to cancel this purchase we need to undo it. One way of\n",
      "doing that is to credit the customer $100.\n",
      "It's important to understand that compensation with workflows is not the same as for example rolling back\n",
      "a transaction (a strict undo). Compensating a workflow state which has successfully completed\n",
      "might involve multiple logical steps and thus is part of the overall business logic that must be\n",
      "defined within the workflow itself. To explain this let's use our previous example and say that when our\n",
      "customer made the item purchase, our workflow has sent her/him a confirmation email. In the case, to\n",
      "compensate this purchase, we cannot just \"undo\" the confirmation email sent. Instead, we want to\n",
      "send a second email to the customer which includes purchase cancellation information.\n",
      "Compensation in Serverless Workflow must be explicitly defined by the workflow control flow logic.\n",
      "It cannot be dynamically triggered by initial workflow data, event payloads, results of service invocations, or\n",
      "errors.\n",
      "Defining Compensation\n",
      "Each workflow state can define how it should be compensated via its compensatedBy property.\n",
      "This property references another workflow state (by its unique name) which is responsible for the actual compensation.\n",
      "States referenced by compensatedBy (as well as any other states that they transition to) must obey following rules:\n",
      "They should not have any incoming transitions (should not be part of the main workflow control-flow logic)\n",
      "\n",
      "They cannot be an event state\n",
      "They cannot define an end definition. If they do, it should be ignored\n",
      "\n",
      "They must define the usedForCompensation property and set it to true\n",
      "They can transition only to states which also have their usedForCompensation property set to true\n",
      "\n",
      "They cannot themselves set their compensatedBy property to any state (compensation is not recursive)\n",
      "Runtime implementations should raise compile time / parsing exceptions if any of the rules mentioned above are\n",
      "not obeyed in the workflow definition.\n",
      "Let's take a look at an example workflow state which defines its compensatedBy property, and the compensation\n",
      "state it references:\n",
      "```json\n",
      " {\n",
      " \"states\": [\n",
      "      {\n",
      "          \"name\": \"NewItemPurchase\",\n",
      "          \"type\": \"event\",\n",
      "          \"onEvents\": [\n",
      "            {\n",
      "              \"eventRefs\": [\n",
      "                \"NewPurchase\"\n",
      "],\n",
      "              \"actions\": [\n",
      "                {\n",
      "                  \"functionRef\": {\n",
      "                    \"refName\": \"DebitCustomerFunction\",\n",
      "                    \"arguments\": {\n",
      "\"customerid\": \"${ .purchase.customerid }\",\n",
      "                        \"amount\": \"${ .purchase.amount }\"\n",
      "                    }\n",
      "                  }\n",
      "                },\n",
      "{\n",
      "                  \"functionRef\": {\n",
      "                    \"refName\": \"SendPurchaseConfirmationEmailFunction\",\n",
      "                    \"arguments\": {\n",
      "\"customerid\": \"${ .purchase.customerid }\"\n",
      "                    }\n",
      "                  }\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          ],\n",
      "\"compensatedBy\": \"CancelPurchase\",\n",
      "          \"transition\": \"SomeNextWorkflowState\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"CancelPurchase\",\n",
      "        \"type\": \"operation\",\n",
      "\"usedForCompensation\": true,\n",
      "        \"actions\": [\n",
      "            {\n",
      "              \"functionRef\": {\n",
      "                \"refName\": \"CreditCustomerFunction\",\n",
      "                \"arguments\": {\n",
      "\"customerid\": \"${ .purchase.customerid }\",\n",
      "                    \"amount\": \"${ .purchase.amount }\"\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            {\n",
      "\"functionRef\": {\n",
      "                \"refName\": \"SendPurchaseCancellationEmailFunction\",\n",
      "                \"arguments\": {\n",
      "                    \"customerid\": \"${ .purchase.customerid }\"\n",
      "}\n",
      "              }\n",
      "            }\n",
      "          ]\n",
      "    }\n",
      " ]\n",
      " }\n",
      "```yaml\n",
      "states:\n",
      "- name: NewItemPurchase\n",
      "  type: event\n",
      "  onEvents:\n",
      "  - eventRefs:\n",
      "    - NewPurchase\n",
      "    actions:\n",
      "    - functionRef:\n",
      "        refName: DebitCustomerFunction\n",
      "        arguments:\n",
      "customerid: \"${ .purchase.customerid }\"\n",
      "          amount: \"${ .purchase.amount }\"\n",
      "    - functionRef:\n",
      "        refName: SendPurchaseConfirmationEmailFunction\n",
      "        arguments:\n",
      "customerid: \"${ .purchase.customerid }\"\n",
      "  compensatedBy: CancelPurchase\n",
      "  transition: SomeNextWorkflowState\n",
      "- name: CancelPurchase\n",
      "  type: operation\n",
      "  usedForCompensation: true\n",
      "  actions:\n",
      "- functionRef:\n",
      "      refName: CreditCustomerFunction\n",
      "      arguments:\n",
      "        customerid: \"${ .purchase.customerid }\"\n",
      "        amount: \"${ .purchase.amount }\"\n",
      "  - functionRef:\n",
      "refName: SendPurchaseCancellationEmailFunction\n",
      "      arguments:\n",
      "        customerid: \"${ .purchase.customerid }\"\n",
      "In this example our \"NewItemPurchase\" event state waits for a \"NewPurchase\" event and then\n",
      "debits the customer and sends them a purchase confirmation email. It defines that it's compensated by the\n",
      "\"CancelPurchase\" operation state which performs two actions, namely credits back the\n",
      "purchase amount to customer and sends them a purchase cancellation email.\n",
      "Triggering Compensation\n",
      "\n",
      "As previously mentioned, compensation must be explicitly triggered by the workflows control-flow logic.\n",
      "This can be done via transition and end definitions.\n",
      "Let's take a look at each:\n",
      "\n",
      "Compensation triggered on transition:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"transition\": {\n",
      "      \"compensate\": true,\n",
      "      \"nextState\": \"NextWorkflowState\"\n",
      "  }\n",
      "}\n",
      "```yaml\n",
      "transition:\n",
      "  compensate: true\n",
      "  nextState: NextWorkflowState\n",
      "Transitions can trigger compensations by specifying the compensate property and setting it to true.\n",
      "This means that before the transition is executed (workflow continues its execution to the \"NextWorkflowState\" in this example),\n",
      "workflow compensation must be performed.\n",
      "Compensation triggered by end definition:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"end\": {\n",
      "    \"compensate\": true\n",
      "  }\n",
      "}\n",
      "```yaml\n",
      "end:\n",
      "  compensate: true\n",
      "Compensation Execution Details\n",
      "Now that we have seen how to define and trigger compensation, we need to go into details on how compensation should be executed.\n",
      "Compensation is performed on all already successfully completed states (that define compensatedBy) in reverse order.\n",
      "Compensation is always done in sequential order, and should not be executed in parallel.\n",
      "Let's take a look at the following workflow image:\n",
      "In this example lets say our workflow execution is at the \"End\" state which defines the compensate property to true\n",
      "as shown in the previous section. States with a red border, namely \"A\", \"B\", \"D\" and \"E\" are states which have so far\n",
      "been executed successfully. State \"C\" has not been executed during workflow execution in our example.\n",
      "When workflow execution encounters our \"End\" state, compensation has to be performed. This is done in reverse order:\n",
      "\n",
      "State \"E\" is not compensated as it does not define a compensatedBy state\n",
      "State \"D\" is compensated by executing compensation \"D1\"\n",
      "\n",
      "State \"B\" is compensated by executing \"B1\" and then \"B1-2\"\n",
      "\n",
      "State C is not compensated as it was never active during workflow execution\n",
      "State A is not comped as it does not define a compensatedBy state\n",
      "\n",
      "So if we look just at the workflow execution flow, the same workflow could be seen as:\n",
      "In our example, when compensation triggers,\n",
      "the current workflow data is passed as input to the \"D1\" state, the first compensation state for our example.\n",
      "The states data output is then passed as states data input to \"B1\", and so on.\n",
      "Compensation and Active States\n",
      "In some cases when compensation is triggered, some states such as Parallel and ForEach\n",
      "states can still be \"active\", meaning they still might have some async executions that are being performed.\n",
      "If compensation needs to performed on such still active states, the state execution must be first cancelled.\n",
      "After it is cancelled, compensation should be performed.\n",
      "Unrecoverable errors during compensation\n",
      "States that are marked as usedForCompensation can define error handling via their\n",
      "onErrors property just like any other workflow states. In case of unrecoverable errors during their execution\n",
      "(errors not explicitly handled),\n",
      "workflow execution should be stopped, which is the same behavior as when not using compensation as well.\n",
      "Continuing as a new Execution\n",
      "In some cases our workflows are deployed and executed on runtimes and/or cloud platforms that expose some\n",
      "execution limitations such as finite execution duration, finite number of workflow transitions, etc.\n",
      "Some runtimes, especially when dealing with stateful workflow orchestrations have a finite limit of\n",
      "execution history log sizes, meaning that once a long-running workflow reaches these limits workflow executions is\n",
      "likely to be forced to stop before reaching its completion. This can result in unexpected issues, especially with\n",
      "mission-critical workflows.\n",
      "For those cases, the Serverless Workflow DSL provides a way to explicitly define stopping the current workflow\n",
      "instance execution, and starting a new one (for the same workflow id or a different one).\n",
      "This can be done via the end definitions continueAs property.\n",
      "The end definitions continueAs can be either of type string or object.\n",
      "If string type, it contains the unique workflow id of the workflow that the execution should continue as, for example:\n",
      "json\n",
      "{ \n",
      "  \"end\": {\n",
      "    \"continueAs\": \"myworkflowid\"\n",
      "  }\n",
      "}\n",
      "Defining this should stop the current workflow execution, and continue execution as a new workflow instance of the\n",
      "workflow which defines the workflow id of \"myworkflowid\". The state data where this is define should \n",
      "become the workflow data input of the workflow that is continuing the current workflow execution.\n",
      "Note that any defined produceEvents and compensate definitions should be honored before continueAs is applied.\n",
      "\n",
      "If object type, the continueAs property has the following properties:\n",
      "| Parameter | Description | Type | Required |\n",
      "| --- | --- | --- | --- |\n",
      "| workflowId | Unique id of the workflow to continue execution as. | string | yes |\n",
      "| version | Version of the workflow to continue execution as. | string | no |\n",
      "| data | If string type, a workflow expression which selects parts of the states data output to become the workflow data input of continued execution. If object type, a custom object to become the\n",
      "workflow data input of the continued execution. | string or object | no |\n",
      "| workflowExecTimeout | Workflow execution timeout to be used by the workflow continuing execution. Overwrites any specific settings set by that workflow. | string or object | no |\n",
      "Continuing execution with continueAs can also be used inside sub-workflow executions, which brings its next use case.\n",
      "\n",
      "ContinueAs in sub workflows\n",
      "Workflows can invoke sub-workflows during their execution. In Serverless Workflow DSL, sub-workflows are invoked\n",
      "similarly to other function types via the SubFlowRef Definition\n",
      "in workflow states Action definitions.\n",
      "Just like \"parent\" workflows, sub-workflow can also be long-running, and can run into the same type of runtime/serverless platform\n",
      "limitations as previously discussed. As such they can also use continueAs to stop their current execution and continue it as \n",
      "a new one of the same or different workflow id.\n",
      "Note that when a sub-workflow is invoked it can produce a result that is then merged into the parent workflow state data.\n",
      "This may bring up a question as to what happens when a sub-workflow calls continueAs in terms of what is returned as\n",
      "result to of its invocation by the parent workflow.\n",
      "No matter how many times sub-workflow may use continueAs, to the parent workflow it should be as a single invocation is performed,\n",
      "meaning that the results of the last sub-workflow invocation (triggered by continueAs) should be used as the \n",
      "data returned by the invocation of the sub-workflow to the parent workflow.\n",
      "Workflow Versioning\n",
      "In any application, regardless of size or type, one thing is for sure: changes happen.\n",
      "Versioning your workflow definitions is an important task to consider. Versions indicate\n",
      "changes or updates of your workflow definitions to the associated execution runtimes.\n",
      "There are two places in the workflow definition where versioning can be applied:\n",
      "\n",
      "Top level workflow definition version property.\n",
      "\n",
      "Actions subflowRef version property.\n",
      "The version property must respect the semantic versioning guidelines.\n",
      "\n",
      "Workflow Constants\n",
      "\n",
      "Workflow constants are used to define static, and immutable, data which is available to Workflow Expressions.\n",
      "Constants can be defined via the Workflow top-level \"constants\" property,\n",
      "for example:\n",
      "json\n",
      "\"constants\": {\n",
      "  \"Translations\": {\n",
      "    \"Dog\": {\n",
      "      \"Serbian\": \"pas\",\n",
      "      \"Spanish\": \"perro\",\n",
      "      \"French\": \"chien\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "Constants can only be accessed inside Workflow expressions via the $CONST variable.\n",
      "Runtimes must make $CONST available to expressions as a predefined variable.\n",
      "Here is an example of using constants in Workflow expressions:\n",
      "json\n",
      "{\n",
      "...,\n",
      "\"constants\": {\n",
      "  \"AGE\": {\n",
      "    \"MIN_ADULT\": 18\n",
      "  }\n",
      "},\n",
      "...\n",
      "\"states\":[\n",
      "  {\n",
      "     \"name\":\"CheckApplicant\",\n",
      "     \"type\":\"switch\",\n",
      "     \"dataConditions\": [\n",
      "        {\n",
      "\"name\": \"Applicant is adult\",\n",
      "          \"condition\": \"${ .applicant | .age >= $CONST.AGE.MIN_ADULT }\",\n",
      "          \"transition\": \"ApproveApplication\"\n",
      "        },\n",
      "        {\n",
      "\"name\": \"Applicant is minor\",\n",
      "          \"condition\": \"${ .applicant | .age < $CONST.AGE.MIN_ADULT }\",\n",
      "          \"transition\": \"RejectApplication\"\n",
      "        }\n",
      "     ],\n",
      "     ...\n",
      "  },\n",
      "  ...\n",
      "]\n",
      "}\n",
      "Note that constants can also be used in expression functions,\n",
      "for example:\n",
      "json\n",
      "{\n",
      "\"functions\": [\n",
      "  {\n",
      "    \"name\": \"isAdult\",\n",
      "    \"operation\": \".applicant | .age >= $CONST.AGE.MIN_ADULT\",\n",
      "    \"type\": \"expression\"\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"isMinor\",\n",
      "\"operation\": \".applicant | .age < $CONST.AGE.MIN_ADULT\",\n",
      "    \"type\": \"expression\"\n",
      "  }\n",
      "]\n",
      "}\n",
      "Workflow constants values should only contain static data, meaning that their value should not\n",
      "contain Workflow expressions.\n",
      "Workflow constants data must be immutable.\n",
      "Workflow constants should not have access to Workflow secrets definitions.\n",
      "Workflow Secrets\n",
      "\n",
      "Secrets allow you access sensitive information, such as passwords, OAuth tokens, ssh keys, etc\n",
      "inside your Workflow Expressions.\n",
      "You can define the names of secrets via the Workflow top-level \"secrets\" property,\n",
      "for example:\n",
      "\n",
      "json\n",
      "\"secrets\": [\"MY_PASSWORD\", \"MY_STORAGE_KEY\", \"MY_ACCOUNT\"]\n",
      "If secrets are defined in a Workflow definition, runtimes must assure to provide their values\n",
      "during Workflow execution.\n",
      "Secrets can be used only in Workflow expressions by referencing them via the $SECRETS variable.\n",
      "Runtimes must make $SECRETS available to expressions as a predefined variable.\n",
      "Here is an example on how to use secrets and pass them as arguments to a function invocation:\n",
      "\n",
      "```json\n",
      "\"secrets\": [\"AZURE_STORAGE_ACCOUNT\", \"AZURE_STORAGE_KEY\"],\n",
      "\n",
      "...\n",
      "{\n",
      "  \"refName\": \"uploadToAzure\",\n",
      "    \"arguments\": {\n",
      "      \"account\": \"${ $SECRETS.AZURE_STORAGE_ACCOUNT }\",\n",
      "      \"account-key\": \"${ $SECRETS.AZURE_STORAGE_KEY }\",\n",
      "      ...\n",
      "    }\n",
      "\n",
      "}\n",
      "Note that secrets can also be used in expression functions.\n",
      "\n",
      "Secrets are immutable, meaning that workflow expressions are not allowed to change their values.\n",
      "\n",
      "Workflow Metadata\n",
      "Metadata enables you to enrich the serverless workflow model with information beyond its core definitions.\n",
      "It is intended to be used by clients, such as tools and libraries, as well as users that find this information relevant.\n",
      "Metadata should not affect workflow execution. Implementations may choose to use metadata information or ignore it.\n",
      "Note, however, that using metadata to control workflow execution can lead to vendor-locked implementations that do not comply with the main goals of this specification, which is to be completely\n",
      "vendor-neutral.\n",
      "Metadata includes key/value pairs (string types). Both keys and values are completely arbitrary and non-identifying.\n",
      "\n",
      "Metadata can be added to:\n",
      "\n",
      "Workflow Definition\n",
      "\n",
      "Function definitions\n",
      "Event definitions\n",
      "\n",
      "State definitions\n",
      "\n",
      "Switch state data and event conditions.\n",
      "\n",
      "Here is an example of metadata attached to the core workflow definition:\n",
      "json\n",
      "{\n",
      "  \"id\": \"processSalesOrders\",\n",
      "  \"name\": \"Process Sales Orders\",\n",
      "  \"version\": \"1.0.0\",\n",
      "  \"specVersion\": \"0.8\",\n",
      "  \"start\": \"MyStartingState\",\n",
      "  \"metadata\": {\n",
      "    \"loglevel\": \"Info\",\n",
      "\"environment\": \"Production\",\n",
      "    \"category\": \"Sales\",\n",
      "    \"giturl\": \"github.com/myproject\",\n",
      "    \"author\": \"Author Name\",\n",
      "    \"team\": \"Team Name\",\n",
      "    ...\n",
      "  },\n",
      "  \"states\": [\n",
      "    ...\n",
      "  ]\n",
      "}\n",
      "Some other examples of information that could be recorded in metadata are:\n",
      "\n",
      "UI tooling information such as sizing or scaling factors.\n",
      "Build, release, or image information such as timestamps, release ids, git branches, PR numbers, etc.\n",
      "\n",
      "Logging, monitoring, analytics, or audit repository information.\n",
      "Labels used for organizing/indexing purposes, such as \"release\" \"stable\", \"track\", \"daily\", etc.\n",
      "\n",
      "Workflow Context\n",
      "Similar to Constants and Secrets, workflows expressions can have access to the context information of a running instance via the keyword WORKFLOW.\n",
      "Implementations may use this keyword to give access to any relevant information of the running instance within an expression. For example:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"id\": \"processSalesOrders\",\n",
      "  \"name\": \"Process Sales Orders\",\n",
      "  \"version\": \"1.0.0\",\n",
      "  \"specVersion\": \"0.8\",\n",
      "  \"start\": \"MyStartingState\",\n",
      "  \"functions\": [{\n",
      "    \"name\": \"myFunction\",\n",
      "\"operation\": \"myopenapi.json#myFunction\"\n",
      "  }],\n",
      "  \"states\":[\n",
      "  {\n",
      "     \"name\":\"MyStartingState\",\n",
      "     \"type\":\"operation\",\n",
      "     \"actions\": [{\n",
      "       \"functionRef\": \"myFunction\",\n",
      "       \"args\": {\n",
      "\"order\": \"${ .orderId }\",\n",
      "          \"callerId\": \"${ $WORKFLOW.instanceId  }\"\n",
      "       }\n",
      "     }],\n",
      "     \"end\": true\n",
      "  }] \n",
      "}\n",
      "In this use case, a third-party service may require information from the caller for traceability purposes.\n",
      "The specification doesn't define any specific variable within the WORKFLOW bucket, but it's considered a reserved keyword.\n",
      "\n",
      "Extensions\n",
      "The workflow extension mechanism allows you to enhance your model definitions with additional information useful for\n",
      "things like analytics, rate limiting, logging, simulation, debugging, tracing, etc.\n",
      "Model extensions do no influence control flow logic (workflow execution semantics).\n",
      "They enhance it with extra information that can be consumed by runtime systems or tooling and\n",
      "evaluated with the end goal being overall workflow improvements in terms of time, cost, efficiency, etc.\n",
      "Serverless Workflow specification provides extensions which can be found here.\n",
      "You can define extensions in your workflow definition using its top-level extensions property.\n",
      "For more information about this property, see the extensions property in the\n",
      "Workflow Definition Structure section.\n",
      "Even tho users can define their own extensions, it is encouraged to use the ones provided by the specification.\n",
      "We also encourage users to contribute their extensions to the specification. That way they can be shared\n",
      "with the rest of the community.\n",
      "If you have an idea for a new workflow extension, or would like to enhance an existing one,\n",
      "please open an New Extension Request issue in this repository.\n",
      "\n",
      "Use Cases\n",
      "You can find different Serverless Workflow use cases here.\n",
      "\n",
      "Examples\n",
      "\n",
      "You can find many Serverless Workflow examples here.\n",
      "\n",
      "Comparison to other workflow languages\n",
      "You can find info how the Serverless Workflow language compares with\n",
      "other workflow languages here.\n",
      "\n",
      "References\n",
      "You can find a list of other languages, technologies and specifications related to workflows here.\n",
      "\n",
      "License\n",
      "\n",
      "Serverless Workflow specification operates under the\n",
      "Apache License version 2.0.\n"
     ]
    }
   ],
   "source": [
    "markdown_splitter = MarkdownTextSplitter(chunk_size=200, chunk_overlap=0)\n",
    "docs = markdown_splitter.create_documents([markdown_text[0].page_content])\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae9c9384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.chroma.Chroma at 0xffff6c3322c0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "# create the vectorestore to use as the index\n",
    "db = Chroma.from_documents(docs, embeddings)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0b84f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# expose this index in a retriever interface\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2})\n",
    "# create a chain to answer questions \n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(), chain_type=\"stuff\", retriever=retriever, return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e7de30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'How does operation works?',\n",
       " 'result': ' Operation defines a set of actions to be performed in sequence or in parallel, and once all actions have been performed, a transition to another state can occur.',\n",
       " 'source_documents': [Document(page_content='Depending on the function type, the operation property can be:', metadata={}),\n",
       "  Document(page_content='Operation state defines a set of actions to be performed in sequence or in parallel.\\nOnce all actions have been performed, a transition to another state can occur.', metadata={})]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How does operation works?\"\n",
    "result = qa({\"query\": query})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d9d651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
