# https://www.elastic.co/guide/en/elasticsearch/reference/8.15/docker.html#docker-compose-file
volumes:
  esdata:
    driver: local
  esplugins:
    driver: local

services:
  # =========================
  # Jupiter
  # =========================
  jupyter:
    # https://hub.docker.com/r/jupyter/pyspark-notebook/tags
    image: jupyter/pyspark-notebook:python-3.11.6
    # build: '.'
    ports:
      - 9999:80
      - 8888:8888
      - 7860:7860
    volumes:
      - ./data:/data
      - ./notebooks:/notebooks
    command: "/opt/conda/bin/jupyter notebook --ip=0.0.0.0 --port=8888 --allow-root --notebook-dir=/notebooks --NotebookApp.token='' --NotebookApp.password='' --NotebookApp.allow_origin='*' --NotebookApp.iopub_data_rate_limit='1.0e10' --no-browser"
    user: root
    networks:
      - network
    env_file: .env
    environment:
      - GRANT_SUDO=yes
      - JUPYTER_TOKEN=secret123
      - DB_DRIVER=${DB_DRIVER}
      - DB_HOST=${DB_HOST}
      - DB_PORT=${DB_PORT}
      - APP_DB_NAME=${APP_DB_NAME}
      - APP_DB_USER=${APP_DB_USER}
      - APP_DB_PASSWORD=${APP_DB_PASSWORD}
      - ELASTIC_USER=${ELASTIC_USER:-}
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD:-}

  # =========================
  # Flink
  # =========================
  # https://hub.docker.com/_/flink/tags
  jobmanager:
    image: flink:2.1.0-scala_2.12-java21
    restart: always
    ports:
      - ${JOB_MANAGER_PORT:-28081}:8081
    volumes:
      - $PWD:/workspace
    command: jobmanager
    networks:
      - network
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8081" ]
      interval: 10s
      timeout: 5s
      retries: 5
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager

  taskmanager:
    image: flink:2.1.0-scala_2.12-java21
    restart: always
    depends_on:
      jobmanager:
        condition: service_healthy
    networks:
      - network
    command: taskmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager
      - TASK_MANAGER_NUMBER_OF_TASK_SLOTS=2
    
  # =========================
  # Kafka
  # =========================
  # Debezium Kafka Connect
  kafka-connect:
    image: debezium/connect:2.5
    hostname: kafka-connect
    restart: always
    ports:
      - ${KAFKA_CONNECT_PORT:-8083}:8083
    volumes:
      - ./debezium-connector:/usr/share/java/debezium-connector
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
    networks:
      - network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8083/connectors || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    environment:
      BOOTSTRAP_SERVERS: kafka:29092
      GROUP_ID: connect-cluster
      CONFIG_STORAGE_TOPIC: connect-configs
      OFFSET_STORAGE_TOPIC: connect-offsets
      STATUS_STORAGE_TOPIC: connect-status
      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_PLUGIN_PATH: /kafka/connect

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    hostname: kafka
    restart: always
    ports:
      - "9092:9092"
      - "9093:9093"
    networks:
      - network
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list"]
      interval: 10s
      timeout: 5s
      retries: 5
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:29093'
      KAFKA_LISTENERS: PLAINTEXT://kafka:29092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
      KAFKA_METADATA_LOG_DIRS_CLEANUP_ENABLE: 'true'
      KAFKA_FORMAT_STORAGE_DIRS_ON_STARTUP: 'true'

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    hostname: kafka-ui
    restart: always
    ports:
      - ${KAFKA_UI_PORT:-28080}:8080
    depends_on:
      kafka:
        condition: service_healthy
      kafka-connect:
        condition: service_healthy
    networks:
      - network
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: debezium
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://kafka-connect:8083

  # =========================
  # PostgreSQL
  # =========================
  # https://renzolucioni.com/postgres-docker-compose/
  # https://hub.docker.com/_/postgres?tab=tags&page=1&ordering=last_updated
  postgres:
    image: postgres:${POSTGRESQL_VERSION}
    #container_name: postgres
    hostname: database
    restart: always
    ports:
      - ${DB_PORT:-5432}:5432
    volumes:
      - ./conf/postgres.conf:/etc/postgresql.conf
      - $PWD/db/data:/var/lib/postgresql/data
      - $PWD/db/init:/docker-entrypoint-initdb.d/
      # - $PWD/db/init_sql/schema.sql:/docker-entrypoint-initdb.d/schema.sql
    environment:
      POSTGRES_USER: ${ADMIN_USER:-root}
      POSTGRES_PASSWORD: ${ADMIN_PASSWORD:-admin}
      ## During INIT, allows to bootstrap an empty database for all user creation
      POSTGRES_DB: ${DB_NAME:-postgres}
      APP_DB_SCHEMA: ${APP_DB_SCHEMA:-public}
      APP_DB_NAME: ${APP_DB_NAME:-db}
      APP_DB_USER: ${APP_DB_USER:-admin}
      APP_DB_PASS: ${APP_DB_PASSWORD:-admin}
      # https://www.postgresql.org/docs/current/auth-trust.html
      POSTGRES_HOST_AUTH_METHOD: trust # allow all connections without a password. This is *not* recommended for prod
      ## To modify the storage location. By default /var/lib/postgresql/data
      # PGDATA: "/var/lib/postgresql/data"
    networks:
      - network
    healthcheck:
      test: [ "CMD", "pg_isready", "-q", "-d", "postgres", "-U", "admin" ]
      timeout: 45s
      interval: 10s
      retries: 10
    # Set wal_level to logical to support logical decoding for Debezium
    # POSTGRES_INITDB_ARGS: "--wal_level=logical"
    # command: ["postgres", "-c", "wal_level=logical"]
    command: ["postgres", "-c", "config_file=/etc/postgresql.conf"]

  # =========================
  # ElasticSearch
  # =========================
  # https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html
  # https://github.com/elastic/elasticsearch/blob/main/docs/reference/setup/install/docker/docker-compose.yml
  elasticsearch:
    image: ${ELASTICSEARCH_IMAGE}
    # ----------------------------------
    # UNCOMMENT TO BUILD ES WITH PLUGINS
    # ----------------------------------
    # build:
    #   dockerfile: ./Dockerfile
    #   context: ./
    restart: unless-stopped
    hostname: elasticsearch
    ports:
      - ${ES_PORT:-9200}:9200
    volumes:
      - esdata:/usr/share/elasticsearch/data
      # https://elk-docker.readthedocs.io/#installing-elasticsearch-plugins
      - esplugins:/usr/share/elasticsearch/plugins      
    env_file: .env
    environment:
      # https://www.elastic.co/guide/en/elasticsearch/reference/current/settings.html
      # https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html#docker-prod-prerequisites
      - node.name=${ES_NODE_NAME}
      - discovery.type=single-node
      - 'ES_JAVA_OPTS=-Xms512m -Xmx512m'
      - http.port=9200
      - http.cors.enabled=true
      - http.cors.allow-origin="*"
      - http.cors.allow-headers=X-Requested-With,Content-Type,Content-Length,Authorization
      # - http.cors.allow-credentials=true
      - xpack.security.enabled=false
      - xpack.security.http.ssl.enabled=false
      - xpack.security.transport.ssl.enabled=false
      # - xpack.security.authc.api_key.enabled=false
      # - xpack.license.self_generated.type=trial
      # - ingest.geoip.downloader.enabled=false
      - ELASTIC_USER=${ELASTIC_USER:-}
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD:-}
      - TZ=${TIMEZONE}
      # https://www.elastic.co/guide/en/elasticsearch/reference/8.15/docker.html#_disable_swapping
      - bootstrap.memory_lock=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    mem_limit: ${MEM_LIMIT}
    networks:
      - network
    healthcheck:
      # https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-health.html
      test: [ "CMD", "curl", "--fail", "-u ${ELASTIC_USER}:${ELASTIC_PASSWORD}", "${ELASTICSEARCH_URL}/_cluster/health" ]
      interval: 10s
      timeout: 40s
      retries: 5
      start_period: 40s
    deploy:
      mode: replicated
      replicas: 1

  # dejavu:
  #   image: appbaseio/dejavu:3.6.0
  #   ports:
  #     - "1358:1358"
  #   links:
  #     - elasticsearch
  #   networks:
  #     - network

  # https://www.elastic.co/guide/en/kibana/current/docker.html
  # https://www.elastic.co/guide/en/kibana/current/settings.html
  kibana:
    image: ${KIBANA_IMAGE}
    restart: unless-stopped
    depends_on:
      - elasticsearch
    ports:
      - ${KIBANA_PORT:-5601}:5601
    volumes:
      - ~/data/kibana:/usr/share/kibana/data    
    env_file: .env
    environment:
      # https://www.elastic.co/guide/en/kibana/current/docker.html
      - ELASTICSEARCH_HOSTS=${ELASTICSEARCH_URL}
      # https://www.elastic.co/guide/en/elasticsearch/reference/8.15/configuring-stack-security.html#stack-start-with-security
      - ELASTICSEARCH_USERNAME=${ELASTIC_USER:-}
      - ELASTICSEARCH_PASSWORD=${ELASTIC_PASSWORD:-}
    networks:
      - network
    healthcheck:
      test: ['CMD-SHELL', 'curl -s http://localhost:5601 >/dev/null || exit 1']
      interval: 10s
      timeout: 30s
      retries: 3
    deploy:
      mode: replicated
      replicas: 1

networks:
  network:
    driver: bridge
    # To enable IPv6 uncomment below lines
#    driver_opts:
#        com.docker.network.enable_ipv6: "true"
